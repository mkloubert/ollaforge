// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const hi: TranslationSchema = {
  translation: {
    common: {
      loading: "लोड हो रहा है...",
      error: "एक त्रुटि हुई",
      retry: "पुनः प्रयास करें",
      cancel: "रद्द करें",
      save: "सहेजें",
      delete: "हटाएं",
      create: "बनाएं",
      back: "वापस",
      name: "नाम",
      actions: "क्रियाएं",
      optional: "वैकल्पिक",
      edit: "संपादित करें",
      ok: "ठीक है",
      dismiss: "खारिज करें",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "होम",
      projects: "प्रोजेक्ट्स",
    },
    theme: {
      light: "लाइट",
      dark: "डार्क",
      system: "सिस्टम",
      toggle: "थीम बदलें",
    },
    language: {
      en: "अंग्रेज़ी",
      de: "जर्मन",
      es: "स्पेनिश",
      fr: "फ्रेंच",
      pt: "पुर्तगाली",
      uk: "यूक्रेनी",
      zh: "चीनी",
      ja: "जापानी",
      ko: "कोरियाई",
      ar: "अरबी",
      hi: "हिंदी",
      it: "इतालवी",
      nl: "डच",
      pl: "पोलिश",
      select: "भाषा चुनें",
    },
    api: {
      status: "API स्थिति",
      connected: "कनेक्टेड",
      disconnected: "डिस्कनेक्टेड",
      checking: "जांच हो रही है...",
    },
    huggingface: {
      status: {
        loggedIn: "{{username}} के रूप में लॉग इन",
        loggedOut: "लॉग इन नहीं हैं",
        checking: "जांच हो रही है...",
      },
      changeToken: "टोकन बदलें",
      login: {
        title: "Hugging Face लॉगिन",
        description:
          "गेटेड मॉडल्स तक पहुंचने के लिए अपना Hugging Face एक्सेस टोकन दर्ज करें।",
        tokenLabel: "एक्सेस टोकन",
        tokenPlaceholder: "hf_...",
        help: "गेटेड मॉडल्स डाउनलोड करने के लिए आपको Hugging Face एक्सेस टोकन की आवश्यकता है।",
        getToken: "यहां अपना टोकन प्राप्त करें",
        submit: "लॉगिन",
        submitting: "लॉगिन हो रहा है...",
        success: "सफलतापूर्वक लॉग इन हुए!",
      },
      errors: {
        loginFailed: "लॉगिन विफल। कृपया अपना टोकन जांचें।",
        invalidToken: "अमान्य टोकन फॉर्मेट। टोकन 'hf_' से शुरू होना चाहिए।",
      },
    },
    llmProviders: {
      title: "LLM प्रदाता",
      status: {
        allValid: "सभी प्रदाता कॉन्फ़िगर हैं",
        someInvalid: "कुछ प्रदाता कॉन्फ़िगर नहीं हैं",
        noneConfigured: "कोई प्रदाता कॉन्फ़िगर नहीं है",
        checking: "जांच हो रही है...",
        valid: "मान्य",
        invalid: "कॉन्फ़िगर नहीं",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "{{provider}} कॉन्फ़िगर करें",
        description: "एकीकरण सक्षम करने के लिए अपनी {{provider}} API कुंजी दर्ज करें।",
        tokenLabel: "API कुंजी",
        help: "{{provider}} सुविधाओं का उपयोग करने के लिए आपको API कुंजी की आवश्यकता है।",
        getToken: "यहां अपनी API कुंजी प्राप्त करें",
        submit: "सहेजें",
        submitting: "सहेजा जा रहा है...",
        success: "API कुंजी सफलतापूर्वक सहेजी गई!",
      },
      changeToken: "API कुंजी बदलें",
      errors: {
        loginFailed: "API कुंजी सहेजने में विफल। कृपया अपनी कुंजी जांचें।",
      },
    },
    generateFromSources: {
      title: "स्रोतों से जेनरेट करें",
      button: "स्रोतों से जेनरेट करें",
      buttonDisabled: "कोई LLM प्रदाता कॉन्फ़िगर नहीं",
      sources: {
        title: "डेटा स्रोत",
        uploadFile: "फ़ाइल अपलोड करें",
        uploadHint: "ड्रैग & ड्रॉप करें या अपलोड के लिए क्लिक करें",
        addText: "टेक्स्ट जोड़ें",
        textPlaceholder: "अपना टेक्स्ट यहां पेस्ट करें...",
        empty: "अभी तक कोई स्रोत नहीं जोड़ा गया",
        estimatedTokens: "~{{tokens}} टोकन",
        totalTokens: "कुल: ~{{tokens}} टोकन",
        sourcesCount: "{{count}} स्रोत",
        acceptedFormats: "स्वीकृत: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "टोकन गणना संदर्भ विंडो सीमा ({{limit}} टोकन) से अधिक है",
      },
      llm: {
        selectModel: "मॉडल चुनें...",
        contextInfo: "संदर्भ: {{context}}K टोकन",
        generate: "जेनरेट करें",
        generating: "जेनरेट हो रहा है...",
        progress: "चंक {{current}} को {{total}} में से प्रोसेस किया जा रहा है...",
        targetLanguage: "आउटपुट भाषा",
        languages: {
          auto: "इनपुट जैसी ही",
          en: "अंग्रेज़ी",
          de: "जर्मन",
          es: "स्पेनिश",
          fr: "फ्रेंच",
          pt: "पुर्तगाली",
          uk: "यूक्रेनी",
          zh: "चीनी (सरलीकृत)",
          ja: "जापानी",
          ko: "कोरियाई",
          ar: "अरबी",
          hi: "हिंदी",
          it: "इतालवी",
          nl: "डच",
          pl: "पोलिश",
        },
      },
      results: {
        title: "जेनरेटेड डेटा",
        empty: "बाएं पैनल का उपयोग करके डेटा जेनरेट करें",
        instruction: "निर्देश",
        output: "आउटपुट",
        addRow: "पंक्ति जोड़ें",
        deleteRow: "हटाएं",
        validRows: "{{total}} में से {{valid}} पंक्तियां मान्य",
        generated: "{{count}} ट्रेनिंग डेटा पंक्तियां जेनरेट हुईं",
      },
      save: {
        title: "JSONL के रूप में सहेजें",
        filename: "फ़ाइल नाम",
        save: "सहेजें",
        saving: "सहेजा जा रहा है...",
        success: "फ़ाइल {{filename}} सफलतापूर्वक सहेजी गई",
      },
      errors: {
        emptyCell: "सेल खाली नहीं हो सकता",
        invalidFilename: "अमान्य फ़ाइल नाम",
        noData: "सहेजने के लिए कोई डेटा नहीं",
        invalidRows: "कृपया पहले अमान्य पंक्तियों को ठीक करें",
      },
    },
    projects: {
      title: "प्रोजेक्ट्स",
      empty: "अभी तक कोई प्रोजेक्ट नहीं",
      emptyDescription: "शुरू करने के लिए अपना पहला प्रोजेक्ट बनाएं।",
      createNew: "नया प्रोजेक्ट",
      createTitle: "नया प्रोजेक्ट बनाएं",
      createDescription: "अपने नए प्रोजेक्ट के लिए एक नाम दर्ज करें।",
      namePlaceholder: "मेरा प्रोजेक्ट",
      nameLabel: "प्रोजेक्ट का नाम",
      descriptionLabel: "विवरण",
      descriptionPlaceholder: "आपके प्रोजेक्ट का संक्षिप्त विवरण",
      creating: "बनाया जा रहा है...",
      saving: "सहेजा जा रहा है...",
      openProject: "प्रोजेक्ट खोलें",
      editTitle: "प्रोजेक्ट संपादित करें",
      editDescription: "प्रोजेक्ट का नाम और विवरण अपडेट करें।",
      deleteTitle: "प्रोजेक्ट हटाएं",
      deleteDescription:
        "क्या आप वाकई \"{{name}}\" को हटाना चाहते हैं? यह क्रिया पूर्ववत नहीं की जा सकती।",
      deleting: "हटाया जा रहा है...",
      openFolder: "फ़ोल्डर खोलें",
    },
    project: {
      title: "प्रोजेक्ट",
      backToProjects: "प्रोजेक्ट्स पर वापस जाएं",
      selectModel: "बेस मॉडल",
      selectModelPlaceholder: "एक मॉडल चुनें...",
      targetName: "टारगेट मॉडल नाम",
      targetNamePlaceholder: "एक कस्टम नाम दर्ज करें...",
      configuration: "कॉन्फ़िगरेशन",
      status: "स्थिति",
      tabs: {
        basic: "बेसिक",
        advanced: "एडवांस्ड",
      },
      advancedPlaceholder: "एडवांस्ड सेटिंग्स जल्द आ रही हैं...",
    },
    advancedConfig: {
      helpPanel: {
        title: "एडवांस्ड सेटिंग्स के बारे में",
        description: "ये सेटिंग्स नियंत्रित करती हैं कि आपका मॉडल QLoRA (क्वांटाइज़्ड लो-रैंक एडाप्टेशन) का उपयोग करके कैसे प्रशिक्षित होता है। QLoRA 4-बिट क्वांटाइज़ेशन और लो-रैंक एडाप्टर का उपयोग करके कंज्यूमर हार्डवेयर पर बड़े भाषा मॉडल को फाइन-ट्यून करने में सक्षम बनाता है। डिफ़ॉल्ट मान अधिकांश उपयोग के मामलों के लिए अच्छी तरह काम करते हैं - केवल तभी बदलें जब आप उनके प्रभाव को समझते हों।",
        learnMore: "और जानें",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "QLoRA पेपर",
          lora: "LoRA समझाया गया",
          transformers: "ट्रेनिंग डॉक्यूमेंटेशन",
        },
      },
      trainingParams: {
        title: "ट्रेनिंग पैरामीटर्स",
        numEpochs: "एपोक्स",
        numEpochsHelp: "ट्रेनिंग पास की संख्या। अधिक एपोक्स गुणवत्ता में सुधार कर सकते हैं लेकिन ओवरफिटिंग का जोखिम होता है। अनुशंसित: 1-5।",
        batchSize: "बैच साइज़",
        batchSizeHelp: "प्रति ट्रेनिंग स्टेप सैंपल। बड़े साइज़ तेज़ ट्रेन करते हैं लेकिन अधिक मेमोरी चाहिए। अनुशंसित: 1-8।",
        gradientAccumulation: "ग्रेडिएंट एक्यूमुलेशन",
        gradientAccumulationHelp: "कई स्टेप्स में ग्रेडिएंट जमा करें। कम मेमोरी के साथ बड़े बैच साइज़ का अनुकरण करता है।",
        learningRate: "लर्निंग रेट",
        learningRateHelp: "वेट अपडेट के लिए स्टेप साइज़। बहुत अधिक अस्थिरता पैदा करता है, बहुत कम ट्रेनिंग धीमी करता है। अनुशंसित: 1e-5 से 5e-4।",
        warmupRatio: "वार्मअप रेश्यो",
        warmupRatioHelp: "लर्निंग रेट को धीरे-धीरे बढ़ाने के लिए ट्रेनिंग का अंश। शुरुआती ट्रेनिंग को स्थिर करने में मदद करता है।",
        maxLength: "अधिकतम टोकन लंबाई",
        maxLengthHelp: "ट्रेनिंग के लिए अधिकतम सीक्वेंस लंबाई। लंबे सीक्वेंस को अधिक मेमोरी चाहिए।",
        fp16: "FP16 (आधी सटीकता)",
        fp16Help: "तेज़ ट्रेनिंग के लिए 16-बिट फ्लोटिंग पॉइंट का उपयोग करें। केवल CUDA GPU पर उपलब्ध।",
        optimizer: "ऑप्टिमाइज़र",
        optimizerHelp: "वेट अपडेट करने के लिए एल्गोरिदम। paged_adamw_8bit QLoRA के लिए मेमोरी कुशल है।",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (GPU के लिए अनुशंसित)",
          adamw_torch: "AdamW (CPU के लिए अनुशंसित)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        weightDecay: "वेट डिके",
        weightDecayHelp: "ओवरफिटिंग रोकने के लिए L2 रेगुलराइज़ेशन। उच्च मान अधिक रेगुलराइज़ेशन जोड़ते हैं। अनुशंसित: 0.01।",
        maxGradNorm: "अधिकतम ग्रेडिएंट नॉर्म",
        maxGradNormHelp: "ग्रेडिएंट क्लिपिंग के लिए अधिकतम ग्रेडिएंट नॉर्म। एक्सप्लोडिंग ग्रेडिएंट रोकता है। अनुशंसित: 1.0।",
        lrScheduler: "LR शेड्यूलर",
        lrSchedulerHelp: "लर्निंग रेट शेड्यूलर स्ट्रैटेजी। नियंत्रित करता है कि ट्रेनिंग के दौरान लर्निंग रेट कैसे बदलती है।",
        schedulers: {
          linear: "लीनियर (अनुशंसित)",
          cosine: "कोसाइन",
          constant: "कॉन्स्टेंट",
          polynomial: "पॉलीनोमियल",
        },
        neftuneNoise: "NEFTune नॉइज़ अल्फ़ा",
        neftuneNoiseHelp: "ट्रेनिंग के दौरान एम्बेडिंग में नॉइज़ जोड़ें। जनरलाइज़ेशन में सुधार कर सकता है। 0 = अक्षम, सक्षम होने पर 5-15 अनुशंसित।",
        seed: "रैंडम सीड",
        seedHelp: "पुनरुत्पादनीयता के लिए सीड। ट्रेनिंग रन में समान परिणाम प्राप्त करने के लिए समान सीड का उपयोग करें।",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "fp16 के बजाय bfloat16 सटीकता का उपयोग करें। केवल Ampere+ GPU (RTX 3000+) पर उपलब्ध। fp16 से बेहतर न्यूमेरिकल स्थिरता।",
        loggingSteps: "लॉगिंग स्टेप्स",
        loggingStepsHelp: "हर N स्टेप पर ट्रेनिंग मेट्रिक्स लॉग करें। कम मान अधिक बार अपडेट देते हैं लेकिन ट्रेनिंग धीमी कर सकते हैं।",
        saveStrategy: "सेव स्ट्रैटेजी",
        saveStrategyHelp: "ट्रेनिंग के दौरान मॉडल चेकपॉइंट कब सेव करें।",
        saveStrategies: {
          no: "कोई चेकपॉइंट नहीं",
          epoch: "प्रत्येक एपोक के बाद (अनुशंसित)",
          steps: "हर N स्टेप",
        },
      },
      defaults: {
        showDefaults: "डिफ़ॉल्ट का उपयोग",
        cudaDefault: "GPU डिफ़ॉल्ट: {{value}}",
        cpuDefault: "CPU डिफ़ॉल्ट: {{value}}",
        resetToDefaults: "डिफ़ॉल्ट पर रीसेट करें",
        resetConfirm: "इस सेक्शन के सभी मान उनके डिफ़ॉल्ट पर रीसेट हो जाएंगे।",
      },
      loraParams: {
        title: "LoRA कॉन्फ़िगरेशन",
        rank: "रैंक (r)",
        rankHelp: "लो-रैंक मैट्रिसेस का डाइमेंशन। उच्च मान अधिक जानकारी कैप्चर करते हैं लेकिन अधिक मेमोरी उपयोग करते हैं और ओवरफिटिंग का जोखिम होता है। अनुशंसित: 8-64।",
        alpha: "अल्फ़ा",
        alphaHelp: "LoRA वेट के लिए स्केलिंग फैक्टर। आमतौर पर रैंक का 2x सेट होता है। उच्च मान फाइन-ट्यूनिंग का प्रभाव बढ़ाते हैं।",
        dropout: "ड्रॉपआउट",
        dropoutHelp: "LoRA लेयर्स के लिए ड्रॉपआउट प्रॉबेबिलिटी। ओवरफिटिंग रोकने में मदद करता है। अनुशंसित: 0.05-0.1।",
        targetModules: "टारगेट मॉड्यूल्स",
        targetModulesHelp: "LoRA लागू करने के लिए मॉडल लेयर्स। अधिक मॉड्यूल = अधिक फाइन-ट्यूनिंग क्षमता लेकिन अधिक मेमोरी उपयोग।",
        modules: {
          q_proj: "क्वेरी प्रोजेक्शन (q_proj)",
          k_proj: "की प्रोजेक्शन (k_proj)",
          v_proj: "वैल्यू प्रोजेक्शन (v_proj)",
          o_proj: "आउटपुट प्रोजेक्शन (o_proj)",
          gate_proj: "गेट प्रोजेक्शन (gate_proj)",
          up_proj: "अप प्रोजेक्शन (up_proj)",
          down_proj: "डाउन प्रोजेक्शन (down_proj)",
        },
        bias: "बायस ट्रेनिंग",
        biasHelp: "ट्रेनिंग के दौरान बायस टर्म्स को कैसे हैंडल करें। 'none' बायस फ्रीज़ करता है, 'lora_only' LoRA बायस ट्रेन करता है, 'all' सभी बायस ट्रेन करता है।",
        biasOptions: {
          none: "कोई नहीं (बायस फ्रीज़ करें)",
          lora_only: "केवल LoRA",
          all: "सभी बायस",
        },
        useRslora: "RSLoRA उपयोग करें",
        useRsloraHelp: "रैंक-स्टेबिलाइज़्ड LoRA उच्च रैंक (r >= 64) के लिए ट्रेनिंग स्थिरता और प्रदर्शन में सुधार करता है। बड़ी रैंक के लिए अनुशंसित।",
        useDora: "DoRA उपयोग करें (प्रयोगात्मक)",
        useDoraHelp: "वेट-डिकम्पोज़्ड लो-रैंक एडाप्टेशन फाइन-ट्यूनिंग गुणवत्ता में सुधार कर सकता है। प्रयोगात्मक फीचर, ट्रेनिंग समय बढ़ा सकता है।",
        modulesToSave: "सेव करने के लिए मॉड्यूल्स",
        modulesToSaveHelp: "पूरी तरह से ट्रेन करने के लिए अतिरिक्त मॉड्यूल्स (LoRA के साथ नहीं)। lm_head जैसी आउटपुट लेयर्स ट्रेन करने के लिए उपयोगी।",
        saveModules: {
          lm_head: "लैंग्वेज मॉडल हेड (lm_head)",
          embed_tokens: "टोकन एम्बेडिंग्स (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "क्वांटाइज़ेशन",
        loadIn4bit: "4-बिट में लोड करें",
        loadIn4bitHelp: "कम मेमोरी उपयोग के लिए मॉडल वेट को 4-बिट सटीकता में लोड करें। सीमित GPU मेमोरी पर QLoRA के लिए आवश्यक। केवल CUDA GPU पर उपलब्ध।",
        quantType: "4-बिट क्वांटाइज़ेशन टाइप",
        quantTypeHelp: "4-बिट क्वांटाइज़ेशन के लिए एल्गोरिदम। बेहतर सटीकता के लिए NF4 (Normal Float 4) अनुशंसित है।",
        quantTypes: {
          nf4: "NF4 (अनुशंसित)",
          fp4: "FP4",
        },
        doubleQuant: "डबल क्वांटाइज़ेशन",
        doubleQuantHelp: "मेमोरी और कम करने के लिए सेकेंडरी क्वांटाइज़ेशन लागू करें। महत्वपूर्ण मेमोरी बचत के लिए छोटी सटीकता ट्रेड-ऑफ।",
        computeDtype: "कंप्यूट Dtype",
        computeDtypeHelp: "ट्रेनिंग के दौरान गणना के लिए डेटा टाइप। Ampere+ GPU (RTX 3000+) पर bfloat16 बेहतर न्यूमेरिकल स्थिरता प्रदान करता है।",
        computeDtypes: {
          float16: "Float16 (अनुशंसित)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (पूर्ण सटीकता)",
        },
        outputQuantization: "आउटपुट क्वांटाइज़ेशन",
        outputQuantizationHelp: "अंतिम GGUF मॉडल के लिए क्वांटाइज़ेशन फॉर्मेट। q8_0 साइज़ और गुणवत्ता के बीच अच्छा संतुलन प्रदान करता है।",
        outputTypes: {
          f32: "F32 (पूर्ण सटीकता, सबसे बड़ा)",
          f16: "F16 (आधी सटीकता)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8-बिट, अनुशंसित)",
          auto: "ऑटो (llama.cpp को निर्णय लेने दें)",
        },
        cudaOnly: "ये सेटिंग्स केवल CUDA GPU पर ट्रेनिंग करते समय लागू होती हैं।",
      },
      modelfileParams: {
        title: "Ollama Modelfile",
        temperature: "टेम्परेचर",
        temperatureHelp: "आउटपुट में रैंडमनेस को नियंत्रित करता है। कम मान रिस्पॉन्स को अधिक फोकस्ड और डिटरमिनिस्टिक बनाते हैं, उच्च मान अधिक क्रिएटिव। अनुशंसित: 0.7-0.9।",
        topP: "Top P (न्यूक्लियस सैंपलिंग)",
        topPHelp: "केवल इस मान तक संचयी संभावना वाले टोकन पर विचार करें। कम मान अधिक संभावित टोकन पर फोकस करते हैं। अनुशंसित: 0.9।",
        topK: "Top K",
        topKHelp: "टोकन चयन को K सबसे संभावित विकल्पों तक सीमित करें। कम मान अधिक फोकस्ड हैं। अनुशंसित: 40।",
        system: "सिस्टम प्रॉम्प्ट",
        systemHelp: "निर्देश जो परिभाषित करते हैं कि मॉडल को कैसे व्यवहार करना चाहिए। यह मॉडल का व्यक्तित्व और क्षमताएं सेट करता है।",
        systemPlaceholder: "आप एक सहायक सहायक हैं।",
        stop: "स्टॉप सीक्वेंसेस",
        stopHelp: "सीक्वेंसेस जो मॉडल को जेनरेट करना बंद करने का संकेत देते हैं। कई स्टॉप सीक्वेंसेस जोड़े जा सकते हैं।",
        stopPlaceholder: "एक स्टॉप सीक्वेंस दर्ज करें...",
        stopAdd: "जोड़ें",
        repeatPenalty: "रिपीट पेनल्टी",
        repeatPenaltyHelp: "टोकन दोहराने के लिए पेनल्टी। उच्च मान दोहराव कम करते हैं। अनुशंसित: 1.1।",
        repeatLastN: "रिपीट लास्ट N",
        repeatLastNHelp: "दोहराव के लिए जांचने के लिए टोकन की संख्या। उच्च मान अधिक संदर्भ पर विचार करते हैं। अनुशंसित: 64।",
        numCtx: "कॉन्टेक्स्ट विंडो साइज़",
        numCtxHelp: "इन्फरेंस के लिए अधिकतम संदर्भ लंबाई। बड़ी विंडो अधिक संदर्भ की अनुमति देती हैं लेकिन अधिक मेमोरी उपयोग करती हैं।",
      },
    },
    dataFiles: {
      title: "ट्रेनिंग डेटा",
      empty: "अभी तक कोई डेटा फ़ाइल नहीं",
      dropzone: "JSONL फ़ाइलें यहां ड्रॉप करें या अपलोड के लिए क्लिक करें",
      dropzoneActive: "फ़ाइलें यहां ड्रॉप करें...",
      uploadButton: "फ़ाइल अपलोड करें",
      uploading: "अपलोड हो रहा है...",
      deleteConfirm: "यह फ़ाइल हटाएं?",
      previewRowCount: "कुल {{count}} पंक्तियां",
      previewTruncated: "पहली {{count}} दिखा रहे हैं",
      previewEmpty: "इस फ़ाइल में कोई डेटा पंक्तियां नहीं हैं।",
      previewError: "फ़ाइल सामग्री लोड नहीं हो सकी।",
      invalidRow: "अमान्य पंक्ति",
      showRawContent: "रॉ दिखाएं ({{size}})",
      rawContentTitle: "रॉ कंटेंट - लाइन {{line}}",
      rawContentLength: "{{count}} अक्षर",
      errorCount: "{{count}} अमान्य पंक्ति(यां) मिलीं",
      fileStatus: {
        pending: "प्रोसेस होने की प्रतीक्षा में",
        in_progress: "लोड हो रहा है...",
        completed: "{{loaded}} पंक्तियां लोड हुईं ({{skipped}} स्किप)",
        failed: "लोड विफल",
        skipped: "स्किप किया गया",
      },
      validationErrors: {
        INVALID_JSON: "अमान्य JSON सिंटैक्स",
        NOT_OBJECT: "JSON ऑब्जेक्ट होना चाहिए",
        MISSING_INSTRUCTION: "\"instruction\" फ़ील्ड गायब है",
        MISSING_OUTPUT: "\"output\" फ़ील्ड गायब है",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" स्ट्रिंग होना चाहिए",
        INVALID_OUTPUT_TYPE: "\"output\" स्ट्रिंग होना चाहिए",
      },
    },
    training: {
      title: "ट्रेनिंग",
      startButton: "मॉडल बनाएं",
      cancelButton: "ट्रेनिंग रद्द करें",
      noModel: "कृपया पहले एक मॉडल चुनें",
      noDataFiles: "कृपया कम से कम एक डेटा फ़ाइल जोड़ें",
      readyDescription: "सब कुछ सेट हो गया। अपना मॉडल बनाना शुरू करने के लिए ऊपर बटन पर क्लिक करें।",
      status: {
        idle: "तैयार",
        starting: "शुरू हो रहा है...",
        loading_data: "डेटा लोड हो रहा है...",
        loading_model: "मॉडल लोड हो रहा है...",
        training: "ट्रेनिंग हो रही है...",
        exporting: "मॉडल एक्सपोर्ट हो रहा है...",
        converting: "GGUF में कन्वर्ट हो रहा है...",
        completed: "पूर्ण",
        failed: "विफल",
        cancelled: "रद्द",
      },
      progress: "प्रगति",
      step: "स्टेप {{current}} / {{total}}",
      device: "डिवाइस",
      taskList: "कार्य",
      tasks: {
        detect_device: "कंप्यूट डिवाइस का पता लगाएं",
        import_libraries: "ML लाइब्रेरीज़ इम्पोर्ट करें",
        load_model: "बेस मॉडल लोड करें",
        setup_lora: "LoRA एडाप्टर सेट करें",
        tokenize: "डेटा लोड और टोकनाइज़ करें",
        train: "मॉडल ट्रेन करें",
        merge_lora: "LoRA को बेस मॉडल के साथ मर्ज करें",
        convert_gguf: "GGUF फॉर्मेट में कन्वर्ट करें",
        create_modelfile: "Ollama Modelfile बनाएं",
        register_ollama: "Ollama में मॉडल रजिस्टर करें",
      },
      taskWarnings: "{{count}} अमान्य पंक्ति(यां) स्किप",
      stillWorking: "अभी भी काम हो रहा है...",
      errorTitle: "ट्रेनिंग विफल",
      completed: "ट्रेनिंग पूर्ण",
      completedDescription: "आपका मॉडल सफलतापूर्वक बना। Modelfile के लिए आउटपुट फ़ोल्डर देखें।",
      cancelled: "ट्रेनिंग रद्द की गई।",
    },
    ollama: {
      title: "Ollama इंटीग्रेशन",
      runButton: "Ollama में चलाएं",
      modelName: "मॉडल का नाम",
      running: "टर्मिनल खोल रहे हैं...",
    },
    presets: {
      title: "ट्रेनिंग प्रीसेट्स",
      description: "विभिन्न उपयोग मामलों के लिए अनुकूलित क्विक-स्टार्ट कॉन्फ़िगरेशन। सेटिंग्स लागू करने के लिए एक प्रीसेट चुनें।",
      applyButton: "लागू करें",
      applyConfirmTitle: "प्रीसेट लागू करें?",
      applyConfirmDescription: "यह आपकी वर्तमान ट्रेनिंग, LoRA और क्वांटाइज़ेशन सेटिंग्स को \"{{preset}}\" प्रीसेट मानों से ओवरराइट कर देगा। यह क्रिया पूर्ववत नहीं की जा सकती।",
      recommended: "अनुशंसित",
      allModels: "सभी मॉडल",
      balanced: {
        name: "संतुलित",
        description: "अधिकांश कार्यों के लिए गति और गुणवत्ता का अच्छा संतुलन",
        pros: {
          versatile: "अधिकांश मॉडल और डेटा के साथ अच्छा काम करता है",
          stable: "सिद्ध डिफ़ॉल्ट के साथ स्थिर ट्रेनिंग",
          good_defaults: "प्रयोग के लिए अच्छा शुरुआती बिंदु",
        },
        cons: {
          not_specialized: "विशिष्ट उपयोग मामलों के लिए अनुकूलित नहीं",
          moderate_time: "मध्यम ट्रेनिंग समय",
        },
      },
      chat: {
        name: "चैट / बातचीत",
        description: "संवादात्मक AI और निर्देश पालन के लिए अनुकूलित",
        pros: {
          natural_responses: "अधिक प्राकृतिक संवादात्मक प्रतिक्रियाएं",
          instruction_following: "बेहतर निर्देश पालन",
          diverse_outputs: "अधिक विविध और रचनात्मक आउटपुट",
        },
        cons: {
          more_memory: "अधिक मेमोरी उपयोग",
          longer_training: "लंबा ट्रेनिंग समय",
        },
      },
      code: {
        name: "कोड जेनरेशन",
        description: "प्रोग्रामिंग और कोड कम्पलीशन के लिए अनुकूलित",
        pros: {
          precise_syntax: "सटीक सिंटैक्स लर्निंग",
          low_dropout: "सटीकता के लिए कम ड्रॉपआउट",
          all_modules: "सभी प्रासंगिक लेयर्स को टारगेट करता है",
        },
        cons: {
          more_memory: "अधिक मेमोरी उपयोग",
          slower_training: "धीमी ट्रेनिंग गति",
        },
      },
      fast: {
        name: "तेज़ इटरेशन",
        description: "तेज़ प्रयोग के लिए त्वरित ट्रेनिंग",
        pros: {
          quick_results: "टेस्टिंग के लिए तेज़ परिणाम",
          low_memory: "कम मेमोरी आवश्यकताएं",
          rapid_testing: "तेज़ प्रोटोटाइपिंग के लिए आदर्श",
        },
        cons: {
          lower_quality: "कम गुणवत्ता वाला आउटपुट",
          less_learning: "कम पूर्ण लर्निंग",
        },
      },
      high_quality: {
        name: "उच्च गुणवत्ता",
        description: "ट्रेनिंग समय की कीमत पर अधिकतम गुणवत्ता",
        pros: {
          best_results: "सर्वोत्तम संभव परिणाम",
          thorough_learning: "अधिक एपोक्स पर पूर्ण ट्रेनिंग",
          all_modules: "व्यापक लेयर कवरेज",
        },
        cons: {
          long_training: "लंबा ट्रेनिंग समय",
          high_memory: "उच्च मेमोरी आवश्यकताएं",
          needs_gpu: "शक्तिशाली GPU की आवश्यकता",
        },
      },
      low_memory: {
        name: "कम मेमोरी",
        description: "सीमित हार्डवेयर के लिए न्यूनतम VRAM उपयोग",
        pros: {
          minimal_vram: "न्यूनतम VRAM उपयोग",
          works_on_consumer: "कंज्यूमर GPU पर काम करता है",
          gradient_accumulation: "प्रभावी ग्रेडिएंट एक्यूमुलेशन",
        },
        cons: {
          slower_training: "धीमी ट्रेनिंग गति",
          smaller_rank: "छोटी LoRA रैंक क्षमता सीमित करती है",
        },
      },
      multilingual: {
        name: "बहुभाषी",
        description: "बहुभाषी मॉडल के लिए अनुकूलित",
        pros: {
          language_diversity: "भाषा विविधता बनाए रखता है",
          balanced_learning: "संतुलित क्रॉस-लिंगुअल लर्निंग",
          longer_warmup: "भाषा अनुकूलन के लिए विस्तारित वार्मअप",
        },
        cons: {
          needs_diverse_data: "विविध ट्रेनिंग डेटा की आवश्यकता",
          moderate_time: "मध्यम ट्रेनिंग समय",
        },
      },
      reasoning: {
        name: "रीज़निंग / गणित",
        description: "तार्किक तर्क और गणित के लिए अनुकूलित",
        pros: {
          precise_learning: "सटीक और सावधान लर्निंग",
          low_dropout: "स्थिरता के लिए कम ड्रॉपआउट",
          consistent_outputs: "अधिक सुसंगत आउटपुट",
        },
        cons: {
          more_epochs: "अधिक ट्रेनिंग एपोक्स की आवश्यकता",
          higher_rank: "उच्च रैंक मेमोरी बढ़ाती है",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "इस नाम का प्रोजेक्ट पहले से मौजूद है।",
      ERR_PROJECT_1002: "प्रोजेक्ट नहीं मिला।",
      ERR_PROJECT_1003: "अमान्य प्रोजेक्ट नाम।",
      ERR_PROJECT_1004: "प्रोजेक्ट नाम खाली नहीं हो सकता।",
      ERR_PROJECT_1005: "प्रोजेक्ट बनाने में विफल।",
      ERR_PROJECT_1006: "प्रोजेक्ट हटाने में विफल।",
      ERR_PROJECT_1007: "प्रोजेक्ट अपडेट करने में विफल।",
      ERR_PROJECT_1008: "प्रोजेक्ट फ़ोल्डर खोलने में विफल।",
      ERR_MODEL_2001: "मॉडल कॉन्फ़िगरेशन पढ़ने में विफल।",
      ERR_MODEL_2002: "मॉडल कॉन्फ़िगरेशन लिखने में विफल।",
      ERR_DATA_3001: "डेटा फ़ाइल नहीं मिली।",
      ERR_DATA_3002: "अमान्य फ़ाइल प्रकार। केवल JSONL फ़ाइलें अनुमत हैं।",
      ERR_DATA_3003: "फ़ाइल अपलोड करने में विफल।",
      ERR_DATA_3004: "फ़ाइल हटाने में विफल।",
      ERR_DATA_3005: "डेटा फ़ाइलें पढ़ने में विफल।",
      ERR_TRAINING_4001: "एक ट्रेनिंग जॉब पहले से चल रही है।",
      ERR_TRAINING_4002: "कोई ट्रेनिंग जॉब नहीं चल रही।",
      ERR_TRAINING_4003: "ट्रेनिंग शुरू करने से पहले कृपया डेटा फ़ाइलें जोड़ें।",
      ERR_TRAINING_4004: "एक ट्रेनिंग डेटा फ़ाइल नहीं मिली।",
      ERR_TRAINING_4005: "मॉडल लोड करने में विफल।",
      ERR_TRAINING_4006: "ट्रेनिंग विफल।",
      ERR_TRAINING_4007: "मॉडल एक्सपोर्ट करने में विफल।",
      ERR_TRAINING_4008: "ट्रेनिंग रद्द की गई।",
      ERR_TRAINING_4009: "llama.cpp नहीं मिला। कृपया पहले इंस्टॉल करें।",
      ERR_HF_5001: "Hugging Face में लॉग इन नहीं है।",
      ERR_HF_5002: "Hugging Face लॉगिन विफल।",
      ERR_HF_5003: "अमान्य Hugging Face टोकन।",
      ERR_OLLAMA_6001: "Ollama इंस्टॉल नहीं है।",
      ERR_OLLAMA_6002: "Ollama नहीं चल रहा।",
      ERR_OLLAMA_6003: "Ollama में मॉडल बनाने में विफल।",
      ERR_OLLAMA_6004: "Ollama में मॉडल नहीं मिला।",
      ERR_OLLAMA_6005: "Modelfile नहीं मिली। कृपया पहले मॉडल ट्रेन करें।",
      ERR_OLLAMA_6006: "टर्मिनल खोलने में विफल।",
      ERR_OLLAMA_6007: "कोई बेस मॉडल कॉन्फ़िगर नहीं है। कृपया पहले एक मॉडल चुनें।",
      ERR_LLM_8001: "अमान्य API कुंजी फॉर्मेट।",
      ERR_LLM_8002: "API कुंजी अस्वीकृत। कृपया अपनी कुंजी जांचें।",
      ERR_LLM_8003: "अज्ञात प्रदाता।",
      ERR_LLM_8004: "प्रदाता API तक नहीं पहुंच सके।",
      ERR_LLM_8005: "API कुंजी सहेज नहीं सके।",
      ERR_DATA_SOURCE_9001: "डेटा स्रोत के लिए अमान्य फ़ाइल प्रकार।",
      ERR_DATA_SOURCE_9002: "फ़ाइल बहुत बड़ी है।",
      ERR_DATA_SOURCE_9003: "डेटा स्रोत खाली है।",
      ERR_GENERATION_9101: "LLM प्रदाता कॉन्फ़िगर नहीं है।",
      ERR_GENERATION_9102: "मॉडल उपलब्ध नहीं है।",
      ERR_GENERATION_9103: "टोकन सीमा पार। कृपया छोटे डेटा स्रोत उपयोग करें।",
      ERR_GENERATION_9104: "LLM API के साथ संचार में त्रुटि।",
      ERR_GENERATION_9105: "LLM से अमान्य प्रतिक्रिया।",
      ERR_GENERATION_9106: "रेट लिमिट पार। कृपया प्रतीक्षा करें और पुनः प्रयास करें।",
      ERR_SAVE_9201: "अमान्य फ़ाइल नाम।",
      ERR_SAVE_9202: "फ़ाइल सहेजने में विफल।",
      unknown: "एक अप्रत्याशित त्रुटि हुई।",
    },
    validation: {
      mustBeInteger: "एक पूर्ण संख्या होनी चाहिए",
      mustBeNumber: "एक मान्य संख्या होनी चाहिए",
      mustBeString: "टेक्स्ट होना चाहिए",
      mustBeBoolean: "सही या गलत होना चाहिए",
      mustBeArray: "एक सूची होनी चाहिए",
      mustBeGreaterThan: "{{min}} से अधिक होना चाहिए",
      mustBeAtLeast: "कम से कम {{min}} होना चाहिए",
      mustBeAtMost: "अधिक से अधिक {{max}} होना चाहिए",
      maxLength: "अधिकतम {{maxLength}} अक्षर",
    },
  },
};

export default hi;
