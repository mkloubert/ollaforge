// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const ja: TranslationSchema = {
  translation: {
    common: {
      loading: "読み込み中...",
      error: "エラーが発生しました",
      retry: "再試行",
      cancel: "キャンセル",
      save: "保存",
      delete: "削除",
      create: "作成",
      back: "戻る",
      name: "名前",
      actions: "アクション",
      optional: "任意",
      edit: "編集",
      ok: "OK",
      dismiss: "閉じる",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "ホーム",
      projects: "プロジェクト",
    },
    theme: {
      light: "ライト",
      dark: "ダーク",
      system: "システム",
      toggle: "テーマを切り替え",
    },
    language: {
      en: "英語",
      de: "ドイツ語",
      es: "スペイン語",
      fr: "フランス語",
      pt: "ポルトガル語",
      uk: "ウクライナ語",
      zh: "中国語",
      ja: "日本語",
      ko: "韓国語",
      ar: "アラビア語",
      hi: "ヒンディー語",
      it: "イタリア語",
      nl: "オランダ語",
      pl: "ポーランド語",
      select: "言語を選択",
    },
    api: {
      status: "APIステータス",
      connected: "接続済み",
      disconnected: "未接続",
      checking: "確認中...",
    },
    huggingface: {
      status: {
        loggedIn: "{{username}}としてログイン中",
        loggedOut: "未ログイン",
        checking: "確認中...",
      },
      changeToken: "トークンを変更",
      login: {
        title: "Hugging Face ログイン",
        description: "保護されたモデルにアクセスするには、Hugging Faceアクセストークンを入力してください。",
        tokenLabel: "アクセストークン",
        tokenPlaceholder: "hf_...",
        help: "保護されたモデルをダウンロードするには、Hugging Faceアクセストークンが必要です。",
        getToken: "トークンを取得",
        submit: "ログイン",
        submitting: "ログイン中...",
        success: "ログインに成功しました！",
      },
      errors: {
        loginFailed: "ログインに失敗しました。トークンを確認してください。",
        invalidToken: "トークンの形式が無効です。トークンは 'hf_' で始まる必要があります。",
      },
    },
    llmProviders: {
      title: "LLMプロバイダー",
      status: {
        allValid: "すべてのプロバイダーが設定済み",
        someInvalid: "一部のプロバイダーが未設定",
        noneConfigured: "プロバイダーが設定されていません",
        checking: "確認中...",
        valid: "有効",
        invalid: "未設定",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "{{provider}}を設定",
        description: "{{provider}}のAPIキーを入力して統合を有効にします。",
        tokenLabel: "APIキー",
        help: "{{provider}}の機能を使用するにはAPIキーが必要です。",
        getToken: "APIキーを取得",
        submit: "保存",
        submitting: "保存中...",
        success: "APIキーが正常に保存されました！",
      },
      changeToken: "APIキーを変更",
      errors: {
        loginFailed: "APIキーの保存に失敗しました。キーを確認してください。",
      },
    },
    generateFromSources: {
      title: "ソースから生成",
      button: "ソースから生成",
      buttonDisabled: "LLMプロバイダーが設定されていません",
      sources: {
        title: "データソース",
        uploadFile: "ファイルをアップロード",
        uploadHint: "ドラッグ＆ドロップまたはクリックしてアップロード",
        addText: "テキストを追加",
        textPlaceholder: "ここにテキストを貼り付け...",
        empty: "まだソースが追加されていません",
        estimatedTokens: "約{{tokens}}トークン",
        totalTokens: "合計：約{{tokens}}トークン",
        sourcesCount: "{{count}}件のソース",
        acceptedFormats: "対応形式：.txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "トークン数がコンテキストウィンドウの制限を超えています（{{limit}}トークン）",
      },
      llm: {
        selectModel: "モデルを選択...",
        contextInfo: "コンテキスト：{{context}}Kトークン",
        generate: "生成",
        generating: "生成中...",
        progress: "チャンク{{current}}/{{total}}を処理中...",
        targetLanguage: "出力言語",
        languages: {
          auto: "入力と同じ",
          en: "英語",
          de: "ドイツ語",
          es: "スペイン語",
          fr: "フランス語",
          pt: "ポルトガル語",
          uk: "ウクライナ語",
          zh: "中国語（簡体字）",
          ja: "日本語",
          ko: "韓国語",
          ar: "アラビア語",
          hi: "ヒンディー語",
          it: "イタリア語",
          nl: "オランダ語",
          pl: "ポーランド語",
        },
      },
      results: {
        title: "生成されたデータ",
        empty: "左パネルを使用してデータを生成",
        instruction: "指示",
        output: "出力",
        addRow: "行を追加",
        deleteRow: "削除",
        validRows: "{{valid}}/{{total}}行が有効",
        generated: "{{count}}件のトレーニングデータ行を生成しました",
      },
      save: {
        title: "JSONLとして保存",
        filename: "ファイル名",
        save: "保存",
        saving: "保存中...",
        success: "ファイル{{filename}}が正常に保存されました",
      },
      errors: {
        emptyCell: "セルを空にすることはできません",
        invalidFilename: "無効なファイル名",
        noData: "保存するデータがありません",
        invalidRows: "まず無効な行を修正してください",
      },
    },
    projects: {
      title: "プロジェクト",
      empty: "まだプロジェクトがありません",
      emptyDescription: "最初のプロジェクトを作成して開始しましょう。",
      createNew: "新規プロジェクト",
      createTitle: "新規プロジェクトを作成",
      createDescription: "新しいプロジェクトの名前を入力してください。",
      namePlaceholder: "マイプロジェクト",
      nameLabel: "プロジェクト名",
      descriptionLabel: "説明",
      descriptionPlaceholder: "プロジェクトの簡単な説明",
      creating: "作成中...",
      saving: "保存中...",
      openProject: "プロジェクトを開く",
      editTitle: "プロジェクトを編集",
      editDescription: "プロジェクト名と説明を更新します。",
      deleteTitle: "プロジェクトを削除",
      deleteDescription: "\"{{name}}\"を削除してもよろしいですか？この操作は元に戻せません。",
      deleting: "削除中...",
      openFolder: "フォルダを開く",
    },
    project: {
      title: "プロジェクト",
      backToProjects: "プロジェクト一覧に戻る",
      selectModel: "ベースモデル",
      selectModelPlaceholder: "モデルを選択...",
      targetName: "ターゲットモデル名",
      targetNamePlaceholder: "カスタム名を入力...",
      configuration: "設定",
      status: "ステータス",
      tabs: {
        basic: "基本",
        advanced: "詳細",
      },
      advancedPlaceholder: "詳細設定は近日公開...",
    },
    advancedConfig: {
      helpPanel: {
        title: "詳細設定について",
        description: "これらの設定は、QLoRA（量子化低ランク適応）を使用したモデルのトレーニング方法を制御します。QLoRAは、4ビット量子化と低ランクアダプターを使用して、消費者向けハードウェアで大規模言語モデルの微調整を可能にします。デフォルト値はほとんどのユースケースで適切に機能します。影響を理解している場合にのみ変更してください。",
        learnMore: "詳細",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "QLoRA論文",
          lora: "LoRA解説",
          transformers: "トレーニングドキュメント",
        },
      },
      trainingParams: {
        title: "トレーニングパラメータ",
        numEpochs: "エポック",
        numEpochsHelp: "トレーニングパスの回数。エポックを増やすと品質が向上する可能性がありますが、過学習のリスクがあります。推奨：1-5。",
        batchSize: "バッチサイズ",
        batchSizeHelp: "トレーニングステップごとのサンプル数。大きいサイズはより速くトレーニングできますが、より多くのメモリが必要です。推奨：1-8。",
        gradientAccumulation: "勾配累積",
        gradientAccumulationHelp: "複数のステップで勾配を累積します。より少ないメモリで大きなバッチサイズをシミュレートします。",
        learningRate: "学習率",
        learningRateHelp: "重み更新のステップサイズ。高すぎると不安定になり、低すぎるとトレーニングが遅くなります。推奨：1e-5から5e-4。",
        warmupRatio: "ウォームアップ比率",
        warmupRatioHelp: "学習率を徐々に上げるトレーニングの割合。初期トレーニングの安定化に役立ちます。",
        maxLength: "最大トークン長",
        maxLengthHelp: "トレーニングの最大シーケンス長。長いシーケンスはより多くのメモリを必要とします。",
        fp16: "FP16（半精度）",
        fp16Help: "より高速なトレーニングのために16ビット浮動小数点を使用。CUDA GPUでのみ利用可能。",
        optimizer: "オプティマイザ",
        optimizerHelp: "重み更新のアルゴリズム。paged_adamw_8bitはQLoRAに対してメモリ効率が良い。",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit（GPU推奨）",
          adamw_torch: "AdamW（CPU推奨）",
          adamw_hf: "AdamW（Hugging Face）",
          sgd: "SGD",
        },
        weightDecay: "重み減衰",
        weightDecayHelp: "過学習を防ぐL2正則化。高い値はより多くの正則化を追加します。推奨：0.01。",
        maxGradNorm: "最大勾配ノルム",
        maxGradNormHelp: "勾配クリッピングの最大勾配ノルム。勾配爆発を防ぎます。推奨：1.0。",
        lrScheduler: "LRスケジューラ",
        lrSchedulerHelp: "学習率スケジューラ戦略。トレーニング中の学習率の変化を制御します。",
        schedulers: {
          linear: "線形（推奨）",
          cosine: "コサイン",
          constant: "定数",
          polynomial: "多項式",
        },
        neftuneNoise: "NEFTune Noise Alpha",
        neftuneNoiseHelp: "トレーニング中に埋め込みにノイズを追加。汎化を改善する可能性があります。0=無効、有効時は5-15推奨。",
        seed: "ランダムシード",
        seedHelp: "再現性のためのシード。同じシードを使用すると、トレーニング実行間で同一の結果が得られます。",
        bf16: "BF16（Brain Float 16）",
        bf16Help: "fp16の代わりにbfloat16精度を使用。Ampere+GPU（RTX 3000+）でのみ利用可能。fp16より数値安定性が優れています。",
        loggingSteps: "ログステップ",
        loggingStepsHelp: "Nステップごとにトレーニングメトリクスをログ。低い値はより頻繁な更新を提供しますが、トレーニングが遅くなる可能性があります。",
        saveStrategy: "保存戦略",
        saveStrategyHelp: "トレーニング中にモデルチェックポイントを保存するタイミング。",
        saveStrategies: {
          no: "チェックポイントなし",
          epoch: "各エポック後（推奨）",
          steps: "Nステップごと",
        },
      },
      defaults: {
        showDefaults: "デフォルト値を使用",
        cudaDefault: "GPUデフォルト：{{value}}",
        cpuDefault: "CPUデフォルト：{{value}}",
        resetToDefaults: "デフォルトにリセット",
        resetConfirm: "このセクションのすべての値がデフォルト値にリセットされます。",
      },
      loraParams: {
        title: "LoRA設定",
        rank: "ランク (r)",
        rankHelp: "低ランク行列の次元。高い値はより多くの情報をキャプチャしますが、より多くのメモリを使用し、過学習のリスクがあります。推奨：8-64。",
        alpha: "Alpha",
        alphaHelp: "LoRA重みのスケーリング係数。通常、ランクの2倍に設定します。高い値は微調整の影響を増加させます。",
        dropout: "ドロップアウト",
        dropoutHelp: "LoRAレイヤーのドロップアウト確率。過学習の防止に役立ちます。推奨：0.05-0.1。",
        targetModules: "ターゲットモジュール",
        targetModulesHelp: "LoRAを適用するモデルレイヤー。より多くのモジュール=より多くの微調整能力、ただしメモリ使用量も増加。",
        modules: {
          q_proj: "クエリ投影 (q_proj)",
          k_proj: "キー投影 (k_proj)",
          v_proj: "バリュー投影 (v_proj)",
          o_proj: "出力投影 (o_proj)",
          gate_proj: "ゲート投影 (gate_proj)",
          up_proj: "アップ投影 (up_proj)",
          down_proj: "ダウン投影 (down_proj)",
        },
        bias: "バイアストレーニング",
        biasHelp: "トレーニング中のバイアス項の処理方法。'none'はバイアスを凍結、'lora_only'はLoRAバイアスをトレーニング、'all'はすべてのバイアスをトレーニング。",
        biasOptions: {
          none: "なし（バイアスを凍結）",
          lora_only: "LoRAのみ",
          all: "すべてのバイアス",
        },
        useRslora: "RSLoRAを使用",
        useRsloraHelp: "Rank-Stabilized LoRAは高ランク（r >= 64）でのトレーニング安定性とパフォーマンスを向上させます。大きなランクに推奨。",
        useDora: "DoRAを使用（実験的）",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptationは微調整品質を向上させる可能性があります。実験的機能、トレーニング時間が増加する可能性があります。",
        modulesToSave: "保存するモジュール",
        modulesToSaveHelp: "完全にトレーニングする追加モジュール（LoRAではなく）。lm_headなどの出力レイヤーのトレーニングに便利。",
        saveModules: {
          lm_head: "言語モデルヘッド (lm_head)",
          embed_tokens: "トークン埋め込み (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "量子化",
        loadIn4bit: "4ビットで読み込み",
        loadIn4bitHelp: "メモリ使用量を削減するために4ビット精度でモデル重みを読み込みます。限られたGPUメモリでQLoRAに必要。CUDA GPUでのみ利用可能。",
        quantType: "4ビット量子化タイプ",
        quantTypeHelp: "4ビット量子化のアルゴリズム。NF4（Normal Float 4）はより良い精度のために推奨。",
        quantTypes: {
          nf4: "NF4（推奨）",
          fp4: "FP4",
        },
        doubleQuant: "二重量子化",
        doubleQuantHelp: "メモリをさらに削減するために二次量子化を適用。小さな精度のトレードオフで大幅なメモリ節約。",
        computeDtype: "計算データ型",
        computeDtypeHelp: "トレーニング中の計算のデータ型。bfloat16はAmpere+GPU（RTX 3000+）でより良い数値安定性を提供。",
        computeDtypes: {
          float16: "Float16（推奨）",
          bfloat16: "BFloat16（RTX 3000+）",
          float32: "Float32（フル精度）",
        },
        outputQuantization: "出力量子化",
        outputQuantizationHelp: "最終GGUFモデルの量子化形式。q8_0はサイズと品質のバランスが良い。",
        outputTypes: {
          f32: "F32（フル精度、最大）",
          f16: "F16（半精度）",
          bf16: "BF16（brain float 16）",
          q8_0: "Q8_0（8ビット、推奨）",
          auto: "自動（llama.cppに任せる）",
        },
        cudaOnly: "これらの設定はCUDA GPUでトレーニングする場合にのみ適用されます。",
      },
      modelfileParams: {
        title: "Ollama Modelfile",
        temperature: "温度",
        temperatureHelp: "出力のランダム性を制御します。低い値はより集中的で決定論的な応答を生成し、高い値はより創造的になります。推奨：0.7-0.9。",
        topP: "Top P（核サンプリング）",
        topPHelp: "累積確率がこの値までのトークンのみを考慮。低い値はより可能性の高いトークンに集中します。推奨：0.9。",
        topK: "Top K",
        topKHelp: "トークン選択を最も可能性の高いK個のオプションに制限。低い値はより集中的。推奨：40。",
        system: "システムプロンプト",
        systemHelp: "モデルの動作を定義する指示。モデルの個性と能力を設定します。",
        systemPlaceholder: "あなたは親切なアシスタントです。",
        stop: "停止シーケンス",
        stopHelp: "モデルに生成停止を通知するシーケンス。複数の停止シーケンスを追加可能。",
        stopPlaceholder: "停止シーケンスを入力...",
        stopAdd: "追加",
        repeatPenalty: "繰り返しペナルティ",
        repeatPenaltyHelp: "トークンの繰り返しに対するペナルティ。高い値は繰り返しを減少させます。推奨：1.1。",
        repeatLastN: "最後のNを繰り返しチェック",
        repeatLastNHelp: "繰り返しをチェックするトークン数。高い値はより多くのコンテキストを考慮します。推奨：64。",
        numCtx: "コンテキストウィンドウサイズ",
        numCtxHelp: "推論の最大コンテキスト長。大きなウィンドウはより多くのコンテキストを許可しますが、より多くのメモリを使用します。",
      },
    },
    dataFiles: {
      title: "トレーニングデータ",
      empty: "まだデータファイルがありません",
      dropzone: "JSONLファイルをここにドロップするかクリックしてアップロード",
      dropzoneActive: "ここにファイルをドロップ...",
      uploadButton: "ファイルをアップロード",
      uploading: "アップロード中...",
      deleteConfirm: "このファイルを削除しますか？",
      previewRowCount: "合計{{count}}行",
      previewTruncated: "最初の{{count}}行を表示",
      previewEmpty: "このファイルにはデータ行がありません。",
      previewError: "ファイルの内容を読み込めませんでした。",
      invalidRow: "無効な行",
      showRawContent: "生データを表示（{{size}}）",
      rawContentTitle: "生データ - 行{{line}}",
      rawContentLength: "{{count}}文字",
      errorCount: "{{count}}件の無効な行が見つかりました",
      fileStatus: {
        pending: "処理待ち",
        in_progress: "読み込み中...",
        completed: "{{loaded}}行読み込み（{{skipped}}件スキップ）",
        failed: "読み込み失敗",
        skipped: "スキップ",
      },
      validationErrors: {
        INVALID_JSON: "無効なJSON構文",
        NOT_OBJECT: "JSONオブジェクトである必要があります",
        MISSING_INSTRUCTION: "\"instruction\"フィールドがありません",
        MISSING_OUTPUT: "\"output\"フィールドがありません",
        INVALID_INSTRUCTION_TYPE: "\"instruction\"は文字列である必要があります",
        INVALID_OUTPUT_TYPE: "\"output\"は文字列である必要があります",
      },
    },
    training: {
      title: "トレーニング",
      startButton: "モデルを作成",
      cancelButton: "トレーニングをキャンセル",
      noModel: "まずモデルを選択してください",
      noDataFiles: "少なくとも1つのデータファイルを追加してください",
      readyDescription: "準備完了です。上のボタンをクリックしてモデルの作成を開始してください。",
      status: {
        idle: "準備完了",
        starting: "開始中...",
        loading_data: "データ読み込み中...",
        loading_model: "モデル読み込み中...",
        training: "トレーニング中...",
        exporting: "モデルエクスポート中...",
        converting: "GGUFに変換中...",
        completed: "完了",
        failed: "失敗",
        cancelled: "キャンセル",
      },
      progress: "進捗",
      step: "ステップ{{current}}/{{total}}",
      device: "デバイス",
      taskList: "タスク",
      tasks: {
        detect_device: "計算デバイスを検出",
        import_libraries: "MLライブラリをインポート",
        load_model: "ベースモデルを読み込み",
        setup_lora: "LoRAアダプターを設定",
        tokenize: "データを読み込みトークン化",
        train: "モデルをトレーニング",
        merge_lora: "LoRAをベースモデルにマージ",
        convert_gguf: "GGUF形式に変換",
        create_modelfile: "Ollama Modelfileを作成",
        register_ollama: "Ollamaにモデルを登録",
      },
      taskWarnings: "{{count}}件の無効な行をスキップしました",
      stillWorking: "まだ処理中...",
      errorTitle: "トレーニング失敗",
      completed: "トレーニング完了",
      completedDescription: "モデルが正常に作成されました。出力フォルダでModelfileを確認してください。",
      cancelled: "トレーニングがキャンセルされました。",
    },
    ollama: {
      title: "Ollama統合",
      runButton: "Ollamaで実行",
      modelName: "モデル名",
      running: "ターミナルを開いています...",
    },
    presets: {
      title: "トレーニングプリセット",
      description: "様々なユースケースに最適化されたクイックスタート設定。プリセットを選択してその設定を適用します。",
      applyButton: "適用",
      applyConfirmTitle: "プリセットを適用しますか？",
      applyConfirmDescription: "現在のトレーニング、LoRA、量子化設定が「{{preset}}」プリセットの値で上書きされます。この操作は元に戻せません。",
      recommended: "推奨",
      allModels: "すべてのモデル",
      balanced: {
        name: "バランス",
        description: "ほとんどのタスクに対する速度と品質の良いバランス",
        pros: {
          versatile: "ほとんどのモデルとデータで適切に動作",
          stable: "実証済みのデフォルト値で安定したトレーニング",
          good_defaults: "実験のための良い出発点",
        },
        cons: {
          not_specialized: "特定のユースケースに最適化されていない",
          moderate_time: "中程度のトレーニング時間",
        },
      },
      chat: {
        name: "チャット/会話",
        description: "会話AIと指示遵守に最適化",
        pros: {
          natural_responses: "より自然な会話応答",
          instruction_following: "より良い指示遵守",
          diverse_outputs: "より多様で創造的な出力",
        },
        cons: {
          more_memory: "より多くのメモリ使用",
          longer_training: "より長いトレーニング時間",
        },
      },
      code: {
        name: "コード生成",
        description: "プログラミングとコード補完に最適化",
        pros: {
          precise_syntax: "正確な構文学習",
          low_dropout: "精度のための低ドロップアウト",
          all_modules: "すべての関連レイヤーを対象",
        },
        cons: {
          more_memory: "より多くのメモリ使用",
          slower_training: "より遅いトレーニング速度",
        },
      },
      fast: {
        name: "高速イテレーション",
        description: "迅速な実験のための高速トレーニング",
        pros: {
          quick_results: "テスト用の迅速な結果",
          low_memory: "低いメモリ要件",
          rapid_testing: "迅速なプロトタイピングに最適",
        },
        cons: {
          lower_quality: "低い出力品質",
          less_learning: "より浅い学習",
        },
      },
      high_quality: {
        name: "高品質",
        description: "トレーニング時間を犠牲にした最高品質",
        pros: {
          best_results: "可能な限り最高の結果",
          thorough_learning: "より多くのエポックでの徹底的なトレーニング",
          all_modules: "包括的なレイヤーカバレッジ",
        },
        cons: {
          long_training: "長いトレーニング時間",
          high_memory: "高いメモリ要件",
          needs_gpu: "強力なGPUが必要",
        },
      },
      low_memory: {
        name: "低メモリ",
        description: "限られたハードウェア用の最小VRAM使用",
        pros: {
          minimal_vram: "最小限のVRAM使用",
          works_on_consumer: "コンシューマGPUで動作",
          gradient_accumulation: "効果的な勾配累積",
        },
        cons: {
          slower_training: "より遅いトレーニング速度",
          smaller_rank: "小さいLoRAランクが容量を制限",
        },
      },
      multilingual: {
        name: "多言語",
        description: "多言語モデルに最適化",
        pros: {
          language_diversity: "言語の多様性を保持",
          balanced_learning: "バランスの取れたクロス言語学習",
          longer_warmup: "言語適応のための延長ウォームアップ",
        },
        cons: {
          needs_diverse_data: "多様なトレーニングデータが必要",
          moderate_time: "中程度のトレーニング時間",
        },
      },
      reasoning: {
        name: "推論/数学",
        description: "論理的推論と数学に最適化",
        pros: {
          precise_learning: "正確で慎重な学習",
          low_dropout: "一貫性のための低ドロップアウト",
          consistent_outputs: "より一貫した出力",
        },
        cons: {
          more_epochs: "より多くのトレーニングエポックが必要",
          higher_rank: "高いランクがメモリを増加",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "この名前のプロジェクトは既に存在します。",
      ERR_PROJECT_1002: "プロジェクトが見つかりません。",
      ERR_PROJECT_1003: "無効なプロジェクト名です。",
      ERR_PROJECT_1004: "プロジェクト名を空にすることはできません。",
      ERR_PROJECT_1005: "プロジェクトの作成に失敗しました。",
      ERR_PROJECT_1006: "プロジェクトの削除に失敗しました。",
      ERR_PROJECT_1007: "プロジェクトの更新に失敗しました。",
      ERR_PROJECT_1008: "プロジェクトフォルダを開けませんでした。",
      ERR_MODEL_2001: "モデル設定の読み取りに失敗しました。",
      ERR_MODEL_2002: "モデル設定の書き込みに失敗しました。",
      ERR_DATA_3001: "データファイルが見つかりません。",
      ERR_DATA_3002: "無効なファイルタイプです。JSONLファイルのみ許可されています。",
      ERR_DATA_3003: "ファイルのアップロードに失敗しました。",
      ERR_DATA_3004: "ファイルの削除に失敗しました。",
      ERR_DATA_3005: "データファイルの読み取りに失敗しました。",
      ERR_TRAINING_4001: "トレーニングジョブは既に実行中です。",
      ERR_TRAINING_4002: "実行中のトレーニングジョブがありません。",
      ERR_TRAINING_4003: "トレーニングを開始する前にデータファイルを追加してください。",
      ERR_TRAINING_4004: "トレーニングデータファイルが見つかりませんでした。",
      ERR_TRAINING_4005: "モデルの読み込みに失敗しました。",
      ERR_TRAINING_4006: "トレーニングに失敗しました。",
      ERR_TRAINING_4007: "モデルのエクスポートに失敗しました。",
      ERR_TRAINING_4008: "トレーニングがキャンセルされました。",
      ERR_TRAINING_4009: "llama.cppが見つかりません。まずインストールしてください。",
      ERR_HF_5001: "Hugging Faceにログインしていません。",
      ERR_HF_5002: "Hugging Faceへのログインに失敗しました。",
      ERR_HF_5003: "無効なHugging Faceトークンです。",
      ERR_OLLAMA_6001: "Ollamaがインストールされていません。",
      ERR_OLLAMA_6002: "Ollamaが実行されていません。",
      ERR_OLLAMA_6003: "Ollamaでのモデル作成に失敗しました。",
      ERR_OLLAMA_6004: "Ollamaでモデルが見つかりません。",
      ERR_OLLAMA_6005: "Modelfileが見つかりません。まずモデルをトレーニングしてください。",
      ERR_OLLAMA_6006: "ターミナルを開けませんでした。",
      ERR_OLLAMA_6007: "ベースモデルが設定されていません。まずモデルを選択してください。",
      ERR_LLM_8001: "無効なAPIキー形式です。",
      ERR_LLM_8002: "APIキーが拒否されました。キーを確認してください。",
      ERR_LLM_8003: "不明なプロバイダーです。",
      ERR_LLM_8004: "プロバイダーAPIに接続できませんでした。",
      ERR_LLM_8005: "APIキーを保存できませんでした。",
      ERR_DATA_SOURCE_9001: "データソースのファイルタイプが無効です。",
      ERR_DATA_SOURCE_9002: "ファイルが大きすぎます。",
      ERR_DATA_SOURCE_9003: "データソースが空です。",
      ERR_GENERATION_9101: "LLMプロバイダーが設定されていません。",
      ERR_GENERATION_9102: "モデルが利用できません。",
      ERR_GENERATION_9103: "トークン制限を超えました。より小さいデータソースを使用してください。",
      ERR_GENERATION_9104: "LLM APIとの通信エラーです。",
      ERR_GENERATION_9105: "LLMからの無効な応答です。",
      ERR_GENERATION_9106: "レート制限を超えました。しばらく待ってから再試行してください。",
      ERR_SAVE_9201: "無効なファイル名です。",
      ERR_SAVE_9202: "ファイルの保存に失敗しました。",
      unknown: "予期しないエラーが発生しました。",
    },
    validation: {
      mustBeInteger: "整数である必要があります",
      mustBeNumber: "有効な数値である必要があります",
      mustBeString: "テキストである必要があります",
      mustBeBoolean: "true または false である必要があります",
      mustBeArray: "リストである必要があります",
      mustBeGreaterThan: "{{min}}より大きい必要があります",
      mustBeAtLeast: "{{min}}以上である必要があります",
      mustBeAtMost: "{{max}}以下である必要があります",
      maxLength: "最大{{maxLength}}文字",
    },
  },
};

export default ja;
