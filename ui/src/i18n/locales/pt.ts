// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const pt: TranslationSchema = {
  translation: {
    common: {
      loading: "Carregando...",
      error: "Ocorreu um erro",
      retry: "Tentar novamente",
      cancel: "Cancelar",
      save: "Salvar",
      delete: "Excluir",
      create: "Criar",
      back: "Voltar",
      name: "Nome",
      actions: "Ações",
      optional: "opcional",
      edit: "Editar",
      ok: "OK",
      dismiss: "Fechar",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "Início",
      projects: "Projetos",
    },
    theme: {
      light: "Claro",
      dark: "Escuro",
      system: "Sistema",
      toggle: "Alternar tema",
    },
    language: {
      en: "Inglês",
      de: "Alemão",
      es: "Espanhol",
      fr: "Francês",
      pt: "Português",
      uk: "Ucraniano",
      zh: "Chinês",
      ja: "Japonês",
      ko: "Coreano",
      ar: "Árabe",
      hi: "Hindi",
      it: "Italiano",
      nl: "Holandês",
      pl: "Polonês",
      select: "Selecionar idioma",
    },
    api: {
      status: "Status da API",
      connected: "Conectado",
      disconnected: "Desconectado",
      checking: "Verificando...",
    },
    huggingface: {
      status: {
        loggedIn: "Conectado como {{username}}",
        loggedOut: "Não conectado",
        checking: "Verificando...",
      },
      changeToken: "Alterar token",
      login: {
        title: "Login no Hugging Face",
        description:
          "Digite seu token de acesso do Hugging Face para acessar modelos protegidos.",
        tokenLabel: "Token de acesso",
        tokenPlaceholder: "hf_...",
        help: "Você precisa de um token de acesso do Hugging Face para baixar modelos protegidos.",
        getToken: "Obtenha seu token aqui",
        submit: "Entrar",
        submitting: "Entrando...",
        success: "Login realizado com sucesso!",
      },
      errors: {
        loginFailed: "Falha no login. Por favor, verifique seu token.",
        invalidToken: "Formato de token inválido. O token deve começar com 'hf_'.",
      },
    },
    llmProviders: {
      title: "Provedores LLM",
      status: {
        allValid: "Todos os provedores configurados",
        someInvalid: "Alguns provedores não configurados",
        noneConfigured: "Nenhum provedor configurado",
        checking: "Verificando...",
        valid: "Válido",
        invalid: "Não configurado",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "Configurar {{provider}}",
        description: "Digite sua chave API do {{provider}} para habilitar a integração.",
        tokenLabel: "Chave API",
        help: "Você precisa de uma chave API para usar os recursos do {{provider}}.",
        getToken: "Obtenha sua chave API aqui",
        submit: "Salvar",
        submitting: "Salvando...",
        success: "Chave API salva com sucesso!",
      },
      changeToken: "Alterar chave API",
      errors: {
        loginFailed: "Falha ao salvar a chave API. Por favor, verifique sua chave.",
      },
    },
    generateFromSources: {
      title: "Gerar a partir de fontes",
      button: "Gerar a partir de fontes",
      buttonDisabled: "Nenhum provedor LLM configurado",
      sources: {
        title: "Fontes de dados",
        uploadFile: "Enviar arquivo",
        uploadHint: "Arraste e solte ou clique para enviar",
        addText: "Adicionar texto",
        textPlaceholder: "Cole seu texto aqui...",
        empty: "Nenhuma fonte adicionada ainda",
        estimatedTokens: "~{{tokens}} tokens",
        totalTokens: "Total: ~{{tokens}} tokens",
        sourcesCount: "{{count}} fonte(s)",
        acceptedFormats: "Aceitos: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "A contagem de tokens excede o limite da janela de contexto ({{limit}} tokens)",
      },
      llm: {
        selectModel: "Selecionar modelo...",
        contextInfo: "Contexto: {{context}}K tokens",
        generate: "Gerar",
        generating: "Gerando...",
        progress: "Processando fragmento {{current}} de {{total}}...",
        targetLanguage: "Idioma de saída",
        languages: {
          auto: "Mesmo que a entrada",
          en: "Inglês",
          de: "Alemão",
          es: "Espanhol",
          fr: "Francês",
          pt: "Português",
          uk: "Ucraniano",
          zh: "Chinês (Simplificado)",
          ja: "Japonês",
          ko: "Coreano",
          ar: "Árabe",
          hi: "Hindi",
          it: "Italiano",
          nl: "Holandês",
          pl: "Polonês",
        },
      },
      results: {
        title: "Dados gerados",
        empty: "Gere dados usando o painel esquerdo",
        instruction: "Instrução",
        output: "Saída",
        addRow: "Adicionar linha",
        deleteRow: "Excluir",
        validRows: "{{valid}} de {{total}} linhas válidas",
        generated: "{{count}} linhas de dados de treinamento geradas",
      },
      save: {
        title: "Salvar como JSONL",
        filename: "Nome do arquivo",
        save: "Salvar",
        saving: "Salvando...",
        success: "Arquivo {{filename}} salvo com sucesso",
      },
      errors: {
        emptyCell: "A célula não pode estar vazia",
        invalidFilename: "Nome de arquivo inválido",
        noData: "Nenhum dado para salvar",
        invalidRows: "Por favor, corrija primeiro as linhas inválidas",
      },
    },
    projects: {
      title: "Projetos",
      empty: "Nenhum projeto ainda",
      emptyDescription: "Crie seu primeiro projeto para começar.",
      createNew: "Novo projeto",
      createTitle: "Criar novo projeto",
      createDescription: "Digite um nome para seu novo projeto.",
      namePlaceholder: "Meu projeto",
      nameLabel: "Nome do projeto",
      descriptionLabel: "Descrição",
      descriptionPlaceholder: "Uma breve descrição do seu projeto",
      creating: "Criando...",
      saving: "Salvando...",
      openProject: "Abrir projeto",
      editTitle: "Editar projeto",
      editDescription: "Atualize o nome e a descrição do projeto.",
      deleteTitle: "Excluir projeto",
      deleteDescription:
        "Tem certeza de que deseja excluir \"{{name}}\"? Esta ação não pode ser desfeita.",
      deleting: "Excluindo...",
      openFolder: "Abrir pasta",
    },
    project: {
      title: "Projeto",
      backToProjects: "Voltar aos projetos",
      selectModel: "Modelo base",
      selectModelPlaceholder: "Selecionar um modelo...",
      targetName: "Nome do modelo alvo",
      targetNamePlaceholder: "Digite um nome personalizado...",
      configuration: "Configuração",
      status: "Status",
      tabs: {
        basic: "Básico",
        advanced: "Avançado",
      },
      advancedPlaceholder: "Configurações avançadas em breve...",
    },
    advancedConfig: {
      helpPanel: {
        title: "Sobre as configurações avançadas",
        description: "Essas configurações controlam como seu modelo é treinado usando QLoRA (Quantized Low-Rank Adaptation). O QLoRA permite o ajuste fino de grandes modelos de linguagem em hardware de consumo usando quantização de 4 bits e adaptadores de baixo rank. Os valores padrão funcionam bem para a maioria dos casos de uso - altere-os apenas se você entender seu impacto.",
        learnMore: "Saiba mais",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "Artigo QLoRA",
          lora: "LoRA explicado",
          transformers: "Documentação de treinamento",
        },
      },
      trainingParams: {
        title: "Parâmetros de treinamento",
        numEpochs: "Épocas",
        numEpochsHelp: "Número de passagens de treinamento. Mais épocas podem melhorar a qualidade, mas arriscam overfitting. Recomendado: 1-5.",
        batchSize: "Tamanho do lote",
        batchSizeHelp: "Amostras por etapa de treinamento. Tamanhos maiores treinam mais rápido, mas precisam de mais memória. Recomendado: 1-8.",
        gradientAccumulation: "Acumulação de gradiente",
        gradientAccumulationHelp: "Acumula gradientes em várias etapas. Simula um tamanho de lote maior com menos memória.",
        learningRate: "Taxa de aprendizado",
        learningRateHelp: "Tamanho do passo para atualizações de pesos. Muito alto causa instabilidade, muito baixo desacelera o treinamento. Recomendado: 1e-5 a 5e-4.",
        warmupRatio: "Proporção de aquecimento",
        warmupRatioHelp: "Fração do treinamento para aumentar gradualmente a taxa de aprendizado. Ajuda a estabilizar o treinamento inicial.",
        maxLength: "Comprimento máximo de tokens",
        maxLengthHelp: "Comprimento máximo de sequência para treinamento. Sequências mais longas precisam de mais memória.",
        fp16: "FP16 (Meia precisão)",
        fp16Help: "Use ponto flutuante de 16 bits para treinamento mais rápido. Disponível apenas em GPUs CUDA.",
        optimizer: "Otimizador",
        optimizerHelp: "Algoritmo para atualização de pesos. paged_adamw_8bit é eficiente em memória para QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (recomendado para GPU)",
          adamw_torch: "AdamW (recomendado para CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        weightDecay: "Decaimento de peso",
        weightDecayHelp: "Regularização L2 para prevenir overfitting. Valores mais altos adicionam mais regularização. Recomendado: 0.01.",
        maxGradNorm: "Norma máxima do gradiente",
        maxGradNormHelp: "Norma máxima do gradiente para clipping. Previne gradientes explosivos. Recomendado: 1.0.",
        lrScheduler: "Agendador LR",
        lrSchedulerHelp: "Estratégia do agendador de taxa de aprendizado. Controla como a taxa de aprendizado muda durante o treinamento.",
        schedulers: {
          linear: "Linear (recomendado)",
          cosine: "Cosseno",
          constant: "Constante",
          polynomial: "Polinomial",
        },
        neftuneNoise: "NEFTune Noise Alpha",
        neftuneNoiseHelp: "Adiciona ruído aos embeddings durante o treinamento. Pode melhorar a generalização. 0 = desativado, 5-15 recomendado quando ativado.",
        seed: "Semente aleatória",
        seedHelp: "Semente para reprodutibilidade. Use a mesma semente para obter resultados idênticos entre execuções de treinamento.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "Use precisão bfloat16 em vez de fp16. Disponível apenas em GPUs Ampere+ (RTX 3000+). Melhor estabilidade numérica que fp16.",
        loggingSteps: "Etapas de log",
        loggingStepsHelp: "Registra métricas de treinamento a cada N etapas. Valores mais baixos dão atualizações mais frequentes, mas podem desacelerar o treinamento.",
        saveStrategy: "Estratégia de salvamento",
        saveStrategyHelp: "Quando salvar checkpoints do modelo durante o treinamento.",
        saveStrategies: {
          no: "Sem checkpoints",
          epoch: "Após cada época (recomendado)",
          steps: "A cada N etapas",
        },
      },
      defaults: {
        showDefaults: "Usando valores padrão",
        cudaDefault: "Padrão GPU: {{value}}",
        cpuDefault: "Padrão CPU: {{value}}",
        resetToDefaults: "Redefinir para padrões",
        resetConfirm: "Todos os valores nesta seção serão redefinidos para seus valores padrão.",
      },
      loraParams: {
        title: "Configuração LoRA",
        rank: "Rank (r)",
        rankHelp: "Dimensão das matrizes de baixo rank. Valores mais altos capturam mais informações, mas usam mais memória e arriscam overfitting. Recomendado: 8-64.",
        alpha: "Alpha",
        alphaHelp: "Fator de escala para pesos LoRA. Tipicamente definido como 2x o rank. Valores mais altos aumentam o impacto do ajuste fino.",
        dropout: "Dropout",
        dropoutHelp: "Probabilidade de dropout para camadas LoRA. Ajuda a prevenir overfitting. Recomendado: 0.05-0.1.",
        targetModules: "Módulos alvo",
        targetModulesHelp: "Camadas do modelo às quais aplicar LoRA. Mais módulos = mais capacidade de ajuste fino, mas mais uso de memória.",
        modules: {
          q_proj: "Projeção de consulta (q_proj)",
          k_proj: "Projeção de chave (k_proj)",
          v_proj: "Projeção de valor (v_proj)",
          o_proj: "Projeção de saída (o_proj)",
          gate_proj: "Projeção de porta (gate_proj)",
          up_proj: "Projeção para cima (up_proj)",
          down_proj: "Projeção para baixo (down_proj)",
        },
        bias: "Treinamento de viés",
        biasHelp: "Como lidar com termos de viés durante o treinamento. 'none' congela vieses, 'lora_only' treina vieses LoRA, 'all' treina todos os vieses.",
        biasOptions: {
          none: "Nenhum (congelar vieses)",
          lora_only: "Apenas LoRA",
          all: "Todos os vieses",
        },
        useRslora: "Usar RSLoRA",
        useRsloraHelp: "Rank-Stabilized LoRA melhora a estabilidade do treinamento e o desempenho para ranks mais altos (r >= 64). Recomendado para ranks grandes.",
        useDora: "Usar DoRA (Experimental)",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptation pode melhorar a qualidade do ajuste fino. Recurso experimental, pode aumentar o tempo de treinamento.",
        modulesToSave: "Módulos a salvar",
        modulesToSaveHelp: "Módulos adicionais para treinar completamente (não com LoRA). Útil para treinar camadas de saída como lm_head.",
        saveModules: {
          lm_head: "Cabeça do modelo de linguagem (lm_head)",
          embed_tokens: "Embeddings de tokens (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "Quantização",
        loadIn4bit: "Carregar em 4 bits",
        loadIn4bitHelp: "Carrega pesos do modelo em precisão de 4 bits para uso reduzido de memória. Necessário para QLoRA em memória GPU limitada. Disponível apenas em GPUs CUDA.",
        quantType: "Tipo de quantização 4 bits",
        quantTypeHelp: "Algoritmo para quantização de 4 bits. NF4 (Normal Float 4) é recomendado para melhor precisão.",
        quantTypes: {
          nf4: "NF4 (recomendado)",
          fp4: "FP4",
        },
        doubleQuant: "Quantização dupla",
        doubleQuantHelp: "Aplica quantização secundária para reduzir ainda mais a memória. Pequena troca de precisão por economia significativa de memória.",
        computeDtype: "Tipo de dados de computação",
        computeDtypeHelp: "Tipo de dados para cálculos durante o treinamento. bfloat16 oferece melhor estabilidade numérica em GPUs Ampere+ (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (recomendado)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (precisão total)",
        },
        outputQuantization: "Quantização de saída",
        outputQuantizationHelp: "Formato de quantização para o modelo GGUF final. q8_0 oferece bom equilíbrio entre tamanho e qualidade.",
        outputTypes: {
          f32: "F32 (precisão total, maior)",
          f16: "F16 (meia precisão)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8 bits, recomendado)",
          auto: "Auto (deixar llama.cpp decidir)",
        },
        cudaOnly: "Essas configurações se aplicam apenas ao treinar em uma GPU CUDA.",
      },
      modelfileParams: {
        title: "Modelfile do Ollama",
        temperature: "Temperatura",
        temperatureHelp: "Controla a aleatoriedade na saída. Valores mais baixos tornam as respostas mais focadas e determinísticas, valores mais altos mais criativos. Recomendado: 0.7-0.9.",
        topP: "Top P (Amostragem por núcleo)",
        topPHelp: "Considera apenas tokens com probabilidade cumulativa até este valor. Valores mais baixos focam em tokens mais prováveis. Recomendado: 0.9.",
        topK: "Top K",
        topKHelp: "Limita a seleção de tokens às K opções mais prováveis. Valores mais baixos são mais focados. Recomendado: 40.",
        system: "Prompt do sistema",
        systemHelp: "Instruções que definem como o modelo deve se comportar. Isso define a personalidade e as capacidades do modelo.",
        systemPlaceholder: "Você é um assistente útil.",
        stop: "Sequências de parada",
        stopHelp: "Sequências que sinalizam ao modelo para parar de gerar. Várias sequências de parada podem ser adicionadas.",
        stopPlaceholder: "Digite uma sequência de parada...",
        stopAdd: "Adicionar",
        repeatPenalty: "Penalidade de repetição",
        repeatPenaltyHelp: "Penalidade por repetir tokens. Valores mais altos reduzem a repetição. Recomendado: 1.1.",
        repeatLastN: "Repetir últimos N",
        repeatLastNHelp: "Número de tokens a verificar para repetição. Valores mais altos consideram mais contexto. Recomendado: 64.",
        numCtx: "Tamanho da janela de contexto",
        numCtxHelp: "Comprimento máximo do contexto para inferência. Janelas maiores permitem mais contexto, mas usam mais memória.",
      },
    },
    dataFiles: {
      title: "Dados de treinamento",
      empty: "Nenhum arquivo de dados ainda",
      dropzone: "Solte arquivos JSONL aqui ou clique para enviar",
      dropzoneActive: "Solte os arquivos aqui...",
      uploadButton: "Enviar arquivo",
      uploading: "Enviando...",
      deleteConfirm: "Excluir este arquivo?",
      previewRowCount: "{{count}} linhas no total",
      previewTruncated: "mostrando as primeiras {{count}}",
      previewEmpty: "Este arquivo não contém linhas de dados.",
      previewError: "Não foi possível carregar o conteúdo do arquivo.",
      invalidRow: "Linha inválida",
      showRawContent: "Mostrar bruto ({{size}})",
      rawContentTitle: "Conteúdo bruto - Linha {{line}}",
      rawContentLength: "{{count}} caracteres",
      errorCount: "{{count}} linha(s) inválida(s) encontrada(s)",
      fileStatus: {
        pending: "Aguardando processamento",
        in_progress: "Carregando...",
        completed: "{{loaded}} linhas carregadas ({{skipped}} ignoradas)",
        failed: "Falha ao carregar",
        skipped: "Ignorado",
      },
      validationErrors: {
        INVALID_JSON: "Sintaxe JSON inválida",
        NOT_OBJECT: "Deve ser um objeto JSON",
        MISSING_INSTRUCTION: "Campo \"instruction\" ausente",
        MISSING_OUTPUT: "Campo \"output\" ausente",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" deve ser uma string",
        INVALID_OUTPUT_TYPE: "\"output\" deve ser uma string",
      },
    },
    training: {
      title: "Treinamento",
      startButton: "Criar modelo",
      cancelButton: "Cancelar treinamento",
      noModel: "Por favor, selecione um modelo primeiro",
      noDataFiles: "Por favor, adicione pelo menos um arquivo de dados",
      readyDescription: "Tudo está configurado. Clique no botão acima para começar a criar seu modelo.",
      status: {
        idle: "Pronto",
        starting: "Iniciando...",
        loading_data: "Carregando dados...",
        loading_model: "Carregando modelo...",
        training: "Treinando...",
        exporting: "Exportando modelo...",
        converting: "Convertendo para GGUF...",
        completed: "Concluído",
        failed: "Falhou",
        cancelled: "Cancelado",
      },
      progress: "Progresso",
      step: "Etapa {{current}} de {{total}}",
      device: "Dispositivo",
      taskList: "Tarefas",
      tasks: {
        detect_device: "Detectar dispositivo de computação",
        import_libraries: "Importar bibliotecas ML",
        load_model: "Carregar modelo base",
        setup_lora: "Configurar adaptador LoRA",
        tokenize: "Carregar e tokenizar dados",
        train: "Treinar modelo",
        merge_lora: "Mesclar LoRA com modelo base",
        convert_gguf: "Converter para formato GGUF",
        create_modelfile: "Criar Modelfile do Ollama",
        register_ollama: "Registrar modelo no Ollama",
      },
      taskWarnings: "{{count}} linha(s) inválida(s) ignorada(s)",
      stillWorking: "Ainda trabalhando...",
      errorTitle: "Falha no treinamento",
      completed: "Treinamento concluído",
      completedDescription: "Seu modelo foi criado com sucesso. Verifique a pasta de saída para o Modelfile.",
      cancelled: "O treinamento foi cancelado.",
    },
    ollama: {
      title: "Integração Ollama",
      runButton: "Executar no Ollama",
      modelName: "Nome do modelo",
      running: "Abrindo terminal...",
    },
    presets: {
      title: "Predefinições de treinamento",
      description: "Configurações de início rápido otimizadas para diferentes casos de uso. Selecione uma predefinição para aplicar suas configurações.",
      applyButton: "Aplicar",
      applyConfirmTitle: "Aplicar predefinição?",
      applyConfirmDescription: "Isso substituirá suas configurações atuais de treinamento, LoRA e quantização pelos valores da predefinição \"{{preset}}\". Esta ação não pode ser desfeita.",
      recommended: "Recomendado",
      allModels: "Todos os modelos",
      balanced: {
        name: "Equilibrado",
        description: "Bom equilíbrio entre velocidade e qualidade para a maioria das tarefas",
        pros: {
          versatile: "Funciona bem com a maioria dos modelos e dados",
          stable: "Treinamento estável com padrões comprovados",
          good_defaults: "Bom ponto de partida para experimentação",
        },
        cons: {
          not_specialized: "Não otimizado para casos de uso específicos",
          moderate_time: "Tempo de treinamento moderado",
        },
      },
      chat: {
        name: "Chat / Conversa",
        description: "Otimizado para IA conversacional e seguimento de instruções",
        pros: {
          natural_responses: "Respostas conversacionais mais naturais",
          instruction_following: "Melhor seguimento de instruções",
          diverse_outputs: "Saídas mais diversas e criativas",
        },
        cons: {
          more_memory: "Maior uso de memória",
          longer_training: "Tempo de treinamento mais longo",
        },
      },
      code: {
        name: "Geração de código",
        description: "Otimizado para programação e completamento de código",
        pros: {
          precise_syntax: "Aprendizado preciso de sintaxe",
          low_dropout: "Baixo dropout para precisão",
          all_modules: "Mira em todas as camadas relevantes",
        },
        cons: {
          more_memory: "Maior uso de memória",
          slower_training: "Velocidade de treinamento mais lenta",
        },
      },
      fast: {
        name: "Iteração rápida",
        description: "Treinamento rápido para experimentação rápida",
        pros: {
          quick_results: "Resultados rápidos para testes",
          low_memory: "Menores requisitos de memória",
          rapid_testing: "Ideal para prototipagem rápida",
        },
        cons: {
          lower_quality: "Menor qualidade de saída",
          less_learning: "Aprendizado menos profundo",
        },
      },
      high_quality: {
        name: "Alta qualidade",
        description: "Qualidade máxima ao custo do tempo de treinamento",
        pros: {
          best_results: "Melhores resultados possíveis",
          thorough_learning: "Treinamento completo ao longo de mais épocas",
          all_modules: "Cobertura completa de camadas",
        },
        cons: {
          long_training: "Tempo de treinamento longo",
          high_memory: "Altos requisitos de memória",
          needs_gpu: "Requer GPU potente",
        },
      },
      low_memory: {
        name: "Pouca memória",
        description: "Uso mínimo de VRAM para hardware limitado",
        pros: {
          minimal_vram: "Uso mínimo de VRAM",
          works_on_consumer: "Funciona em GPUs de consumo",
          gradient_accumulation: "Acumulação de gradiente eficaz",
        },
        cons: {
          slower_training: "Velocidade de treinamento mais lenta",
          smaller_rank: "Rank LoRA menor limita a capacidade",
        },
      },
      multilingual: {
        name: "Multilíngue",
        description: "Otimizado para modelos multilíngues",
        pros: {
          language_diversity: "Preserva a diversidade linguística",
          balanced_learning: "Aprendizado equilibrado entre idiomas",
          longer_warmup: "Aquecimento estendido para adaptação linguística",
        },
        cons: {
          needs_diverse_data: "Requer dados de treinamento diversos",
          moderate_time: "Tempo de treinamento moderado",
        },
      },
      reasoning: {
        name: "Raciocínio / Matemática",
        description: "Otimizado para raciocínio lógico e matemática",
        pros: {
          precise_learning: "Aprendizado preciso e cuidadoso",
          low_dropout: "Baixo dropout para consistência",
          consistent_outputs: "Saídas mais consistentes",
        },
        cons: {
          more_epochs: "Mais épocas de treinamento necessárias",
          higher_rank: "Rank mais alto aumenta a memória",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "Já existe um projeto com este nome.",
      ERR_PROJECT_1002: "Projeto não encontrado.",
      ERR_PROJECT_1003: "Nome de projeto inválido.",
      ERR_PROJECT_1004: "O nome do projeto não pode estar vazio.",
      ERR_PROJECT_1005: "Falha ao criar o projeto.",
      ERR_PROJECT_1006: "Falha ao excluir o projeto.",
      ERR_PROJECT_1007: "Falha ao atualizar o projeto.",
      ERR_PROJECT_1008: "Falha ao abrir a pasta do projeto.",
      ERR_MODEL_2001: "Falha ao ler a configuração de modelos.",
      ERR_MODEL_2002: "Falha ao gravar a configuração de modelos.",
      ERR_DATA_3001: "Arquivo de dados não encontrado.",
      ERR_DATA_3002: "Tipo de arquivo inválido. Apenas arquivos JSONL são permitidos.",
      ERR_DATA_3003: "Falha ao enviar o arquivo.",
      ERR_DATA_3004: "Falha ao excluir o arquivo.",
      ERR_DATA_3005: "Falha ao ler os arquivos de dados.",
      ERR_TRAINING_4001: "Um trabalho de treinamento já está em execução.",
      ERR_TRAINING_4002: "Nenhum trabalho de treinamento em execução.",
      ERR_TRAINING_4003: "Por favor, adicione arquivos de dados antes de iniciar o treinamento.",
      ERR_TRAINING_4004: "Um arquivo de dados de treinamento não foi encontrado.",
      ERR_TRAINING_4005: "Falha ao carregar o modelo.",
      ERR_TRAINING_4006: "O treinamento falhou.",
      ERR_TRAINING_4007: "Falha ao exportar o modelo.",
      ERR_TRAINING_4008: "O treinamento foi cancelado.",
      ERR_TRAINING_4009: "llama.cpp não foi encontrado. Por favor, instale-o primeiro.",
      ERR_HF_5001: "Não conectado ao Hugging Face.",
      ERR_HF_5002: "Falha no login do Hugging Face.",
      ERR_HF_5003: "Token do Hugging Face inválido.",
      ERR_OLLAMA_6001: "Ollama não está instalado.",
      ERR_OLLAMA_6002: "Ollama não está em execução.",
      ERR_OLLAMA_6003: "Falha ao criar o modelo no Ollama.",
      ERR_OLLAMA_6004: "Modelo não encontrado no Ollama.",
      ERR_OLLAMA_6005: "Modelfile não encontrado. Por favor, treine o modelo primeiro.",
      ERR_OLLAMA_6006: "Falha ao abrir o terminal.",
      ERR_OLLAMA_6007: "Nenhum modelo base configurado. Por favor, selecione um modelo primeiro.",
      ERR_LLM_8001: "Formato de chave API inválido.",
      ERR_LLM_8002: "Chave API rejeitada. Por favor, verifique sua chave.",
      ERR_LLM_8003: "Provedor desconhecido.",
      ERR_LLM_8004: "Não foi possível alcançar a API do provedor.",
      ERR_LLM_8005: "Não foi possível salvar a chave API.",
      ERR_DATA_SOURCE_9001: "Tipo de arquivo inválido para fonte de dados.",
      ERR_DATA_SOURCE_9002: "O arquivo é muito grande.",
      ERR_DATA_SOURCE_9003: "A fonte de dados está vazia.",
      ERR_GENERATION_9101: "O provedor LLM não está configurado.",
      ERR_GENERATION_9102: "O modelo não está disponível.",
      ERR_GENERATION_9103: "Limite de tokens excedido. Por favor, use fontes de dados menores.",
      ERR_GENERATION_9104: "Erro ao se comunicar com a API LLM.",
      ERR_GENERATION_9105: "Resposta inválida do LLM.",
      ERR_GENERATION_9106: "Limite de taxa excedido. Por favor, aguarde e tente novamente.",
      ERR_SAVE_9201: "Nome de arquivo inválido.",
      ERR_SAVE_9202: "Falha ao salvar o arquivo.",
      unknown: "Ocorreu um erro inesperado.",
    },
    validation: {
      mustBeInteger: "Deve ser um número inteiro",
      mustBeNumber: "Deve ser um número válido",
      mustBeString: "Deve ser texto",
      mustBeBoolean: "Deve ser verdadeiro ou falso",
      mustBeArray: "Deve ser uma lista",
      mustBeGreaterThan: "Deve ser maior que {{min}}",
      mustBeAtLeast: "Deve ser pelo menos {{min}}",
      mustBeAtMost: "Deve ser no máximo {{max}}",
      maxLength: "Máximo de {{maxLength}} caracteres",
    },
  },
};

export default pt;
