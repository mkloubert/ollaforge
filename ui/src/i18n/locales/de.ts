// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const de: TranslationSchema = {
  translation: {
    common: {
      loading: "Laden...",
      error: "Ein Fehler ist aufgetreten",
      retry: "Erneut versuchen",
      cancel: "Abbrechen",
      save: "Speichern",
      delete: "Löschen",
      create: "Erstellen",
      back: "Zurück",
      name: "Name",
      actions: "Aktionen",
      optional: "optional",
      edit: "Bearbeiten",
      ok: "OK",
      dismiss: "Schließen",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "Startseite",
      projects: "Projekte",
    },
    theme: {
      light: "Hell",
      dark: "Dunkel",
      system: "System",
      toggle: "Design wechseln",
    },
    language: {
      en: "Englisch",
      de: "Deutsch",
      select: "Sprache auswählen",
    },
    api: {
      status: "API-Status",
      connected: "Verbunden",
      disconnected: "Nicht verbunden",
      checking: "Prüfe...",
    },
    huggingface: {
      status: {
        loggedIn: "Angemeldet als {{username}}",
        loggedOut: "Nicht angemeldet",
        checking: "Prüfe...",
      },
      changeToken: "Token ändern",
      login: {
        title: "Hugging Face Login",
        description:
          "Gib deinen Hugging Face Access Token ein, um auf geschützte Modelle zuzugreifen.",
        tokenLabel: "Access Token",
        tokenPlaceholder: "hf_...",
        help: "Du benötigst einen Hugging Face Access Token, um geschützte Modelle herunterzuladen.",
        getToken: "Token hier holen",
        submit: "Anmelden",
        submitting: "Melde an...",
        success: "Erfolgreich angemeldet!",
      },
      errors: {
        loginFailed: "Anmeldung fehlgeschlagen. Bitte überprüfe deinen Token.",
        invalidToken: "Ungültiges Token-Format. Token muss mit 'hf_' beginnen.",
      },
    },
    projects: {
      title: "Projekte",
      empty: "Noch keine Projekte",
      emptyDescription: "Erstelle dein erstes Projekt, um loszulegen.",
      createNew: "Neues Projekt",
      createTitle: "Neues Projekt erstellen",
      createDescription: "Gib einen Namen für dein neues Projekt ein.",
      namePlaceholder: "Mein Projekt",
      nameLabel: "Projektname",
      descriptionLabel: "Beschreibung",
      descriptionPlaceholder: "Eine kurze Beschreibung deines Projekts",
      creating: "Erstelle...",
      saving: "Speichere...",
      openProject: "Projekt öffnen",
      editTitle: "Projekt bearbeiten",
      editDescription: "Aktualisiere den Projektnamen und die Beschreibung.",
      deleteTitle: "Projekt löschen",
      deleteDescription:
        "Bist du sicher, dass du \"{{name}}\" löschen möchtest? Diese Aktion kann nicht rückgängig gemacht werden.",
      deleting: "Lösche...",
    },
    project: {
      title: "Projekt",
      backToProjects: "Zurück zu Projekten",
      selectModel: "Basis-Modell",
      selectModelPlaceholder: "Modell auswählen...",
      targetName: "Ziel-Modellname",
      targetNamePlaceholder: "Eigenen Namen eingeben...",
      configuration: "Konfiguration",
      status: "Status",
      tabs: {
        basic: "Basis",
        advanced: "Erweitert",
      },
      advancedPlaceholder: "Erweiterte Einstellungen folgen...",
    },
    advancedConfig: {
      helpPanel: {
        title: "Über die erweiterten Einstellungen",
        description: "Diese Einstellungen steuern, wie dein Modell mit QLoRA (Quantized Low-Rank Adaptation) trainiert wird. QLoRA ermöglicht das Fine-Tuning großer Sprachmodelle auf Consumer-Hardware durch 4-Bit-Quantisierung und Low-Rank-Adapter. Die Standardwerte funktionieren für die meisten Anwendungsfälle gut - ändere sie nur, wenn du ihre Auswirkungen verstehst.",
        learnMore: "Mehr erfahren",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "QLoRA-Paper",
          lora: "LoRA erklärt",
          transformers: "Training-Dokumentation",
        },
      },
      trainingParams: {
        title: "Trainingsparameter",
        numEpochs: "Epochen",
        numEpochsHelp: "Anzahl der Trainingsdurchläufe. Mehr Epochen können die Qualität verbessern, riskieren aber Overfitting. Empfohlen: 1-5.",
        batchSize: "Batch-Größe",
        batchSizeHelp: "Samples pro Trainingsschritt. Größere Werte trainieren schneller, brauchen aber mehr Speicher. Empfohlen: 1-8.",
        gradientAccumulation: "Gradienten-Akkumulation",
        gradientAccumulationHelp: "Akkumuliere Gradienten über mehrere Schritte. Simuliert größere Batch-Größe mit weniger Speicher.",
        learningRate: "Lernrate",
        learningRateHelp: "Schrittgröße für Gewichtsaktualisierungen. Zu hoch verursacht Instabilität, zu niedrig verlangsamt das Training. Empfohlen: 1e-5 bis 5e-4.",
        warmupRatio: "Warmup-Anteil",
        warmupRatioHelp: "Anteil des Trainings, um die Lernrate schrittweise zu erhöhen. Stabilisiert das frühe Training.",
        maxLength: "Max. Token-Länge",
        maxLengthHelp: "Maximale Sequenzlänge für das Training. Längere Sequenzen benötigen mehr Speicher.",
        fp16: "FP16 (Halbe Präzision)",
        fp16Help: "Nutze 16-Bit-Gleitkommazahlen für schnelleres Training. Nur auf CUDA-GPUs verfügbar.",
        optimizer: "Optimierer",
        optimizerHelp: "Algorithmus zur Gewichtsaktualisierung. paged_adamw_8bit ist speichereffizient für QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (empfohlen für GPU)",
          adamw_torch: "AdamW (empfohlen für CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        // Extended training parameters
        weightDecay: "Gewichtszerfall",
        weightDecayHelp: "L2-Regularisierung gegen Overfitting. Höhere Werte verstärken die Regularisierung. Empfohlen: 0.01.",
        maxGradNorm: "Max. Gradienten-Norm",
        maxGradNormHelp: "Maximale Gradienten-Norm für Gradient Clipping. Verhindert explodierende Gradienten. Empfohlen: 1.0.",
        lrScheduler: "LR-Scheduler",
        lrSchedulerHelp: "Lernraten-Scheduler-Strategie. Steuert, wie sich die Lernrate während des Trainings ändert.",
        schedulers: {
          linear: "Linear (empfohlen)",
          cosine: "Kosinus",
          constant: "Konstant",
          polynomial: "Polynomial",
        },
        neftuneNoise: "NEFTune Noise Alpha",
        neftuneNoiseHelp: "Füge Rauschen zu Embeddings während des Trainings hinzu. Kann die Generalisierung verbessern. 0 = deaktiviert, 5-15 empfohlen wenn aktiviert.",
        seed: "Zufalls-Seed",
        seedHelp: "Seed für Reproduzierbarkeit. Nutze denselben Seed für identische Ergebnisse bei Trainingsläufen.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "Nutze bfloat16-Präzision statt fp16. Nur auf Ampere+ GPUs (RTX 3000+) verfügbar. Bessere numerische Stabilität als fp16.",
        loggingSteps: "Logging-Schritte",
        loggingStepsHelp: "Protokolliere Trainingsmetriken alle N Schritte. Niedrigere Werte geben häufigere Updates, können aber das Training verlangsamen.",
        saveStrategy: "Speicher-Strategie",
        saveStrategyHelp: "Wann Modell-Checkpoints während des Trainings gespeichert werden sollen.",
        saveStrategies: {
          no: "Keine Checkpoints",
          epoch: "Nach jeder Epoche (empfohlen)",
          steps: "Alle N Schritte",
        },
      },
      defaults: {
        showDefaults: "Nutze Standardwerte",
        cudaDefault: "GPU-Standard: {{value}}",
        cpuDefault: "CPU-Standard: {{value}}",
        resetToDefaults: "Auf Standard zurücksetzen",
        resetConfirm: "Alle Werte in diesem Bereich werden auf die Standardwerte zurückgesetzt.",
      },
      loraParams: {
        title: "LoRA-Konfiguration",
        rank: "Rang (r)",
        rankHelp: "Dimension der Low-Rank-Matrizen. Höhere Werte erfassen mehr Informationen, brauchen aber mehr Speicher und riskieren Overfitting. Empfohlen: 8-64.",
        alpha: "Alpha",
        alphaHelp: "Skalierungsfaktor für LoRA-Gewichte. Typischerweise 2x der Rang. Höhere Werte verstärken den Einfluss des Fine-Tunings.",
        dropout: "Dropout",
        dropoutHelp: "Dropout-Wahrscheinlichkeit für LoRA-Schichten. Hilft gegen Overfitting. Empfohlen: 0.05-0.1.",
        targetModules: "Ziel-Module",
        targetModulesHelp: "Modell-Schichten, auf die LoRA angewendet wird. Mehr Module = mehr Fine-Tuning-Kapazität, aber mehr Speicherverbrauch.",
        modules: {
          q_proj: "Query-Projektion (q_proj)",
          k_proj: "Key-Projektion (k_proj)",
          v_proj: "Value-Projektion (v_proj)",
          o_proj: "Output-Projektion (o_proj)",
          gate_proj: "Gate-Projektion (gate_proj)",
          up_proj: "Up-Projektion (up_proj)",
          down_proj: "Down-Projektion (down_proj)",
        },
        // Advanced LoRA parameters
        bias: "Bias-Training",
        biasHelp: "Wie Bias-Terme beim Training behandelt werden. 'none' friert Biases ein, 'lora_only' trainiert LoRA-Biases, 'all' trainiert alle Biases.",
        biasOptions: {
          none: "Keine (Biases einfrieren)",
          lora_only: "Nur LoRA",
          all: "Alle Biases",
        },
        useRslora: "RSLoRA verwenden",
        useRsloraHelp: "Rank-Stabilized LoRA verbessert die Trainingsstabilität bei höheren Rängen (r >= 64). Empfohlen für große Ränge.",
        useDora: "DoRA verwenden (Experimentell)",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptation kann die Fine-Tuning-Qualität verbessern. Experimentell, kann die Trainingszeit erhöhen.",
        modulesToSave: "Module zum Speichern",
        modulesToSaveHelp: "Zusätzliche Module, die vollständig trainiert werden (nicht mit LoRA). Nützlich für Output-Schichten wie lm_head.",
        saveModules: {
          lm_head: "Sprachmodell-Kopf (lm_head)",
          embed_tokens: "Token-Embeddings (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "Quantisierung",
        loadIn4bit: "In 4-Bit laden",
        loadIn4bitHelp: "Lade Modellgewichte in 4-Bit-Präzision für reduzierten Speicherverbrauch. Erforderlich für QLoRA bei begrenztem GPU-Speicher. Nur auf CUDA-GPUs verfügbar.",
        quantType: "4-Bit-Quantisierungstyp",
        quantTypeHelp: "Algorithmus für 4-Bit-Quantisierung. NF4 (Normal Float 4) wird für bessere Genauigkeit empfohlen.",
        quantTypes: {
          nf4: "NF4 (empfohlen)",
          fp4: "FP4",
        },
        doubleQuant: "Doppelte Quantisierung",
        doubleQuantHelp: "Wende sekundäre Quantisierung an, um Speicher weiter zu reduzieren. Kleiner Genauigkeitsverlust für erhebliche Speichereinsparung.",
        computeDtype: "Berechnungs-Dtype",
        computeDtypeHelp: "Datentyp für Berechnungen während des Trainings. bfloat16 bietet bessere numerische Stabilität auf Ampere+ GPUs (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (empfohlen)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (volle Präzision)",
        },
        outputQuantization: "Ausgabe-Quantisierung",
        outputQuantizationHelp: "Quantisierungsformat für das finale GGUF-Modell. q8_0 bietet gute Balance zwischen Größe und Qualität.",
        outputTypes: {
          f32: "F32 (volle Präzision, größte)",
          f16: "F16 (halbe Präzision)",
          bf16: "BF16 (Brain Float 16)",
          q8_0: "Q8_0 (8-Bit, empfohlen)",
          auto: "Auto (llama.cpp entscheidet)",
        },
        cudaOnly: "Diese Einstellungen gelten nur beim Training auf einer CUDA-GPU.",
      },
      modelfileParams: {
        title: "Ollama Modelfile",
        temperature: "Temperatur",
        temperatureHelp: "Steuert die Zufälligkeit der Ausgabe. Niedrigere Werte machen Antworten fokussierter und deterministischer, höhere Werte kreativer. Empfohlen: 0.7-0.9.",
        topP: "Top P (Nucleus Sampling)",
        topPHelp: "Berücksichtigt nur Token mit kumulativer Wahrscheinlichkeit bis zu diesem Wert. Niedrigere Werte fokussieren auf wahrscheinlichere Token. Empfohlen: 0.9.",
        topK: "Top K",
        topKHelp: "Begrenzt die Token-Auswahl auf die K wahrscheinlichsten Optionen. Niedrigere Werte sind fokussierter. Empfohlen: 40.",
        system: "System-Prompt",
        systemHelp: "Anweisungen, die definieren, wie sich das Modell verhalten soll. Dies legt die Persönlichkeit und Fähigkeiten des Modells fest.",
        systemPlaceholder: "Du bist ein hilfreicher Assistent.",
        stop: "Stopp-Sequenzen",
        stopHelp: "Sequenzen, die dem Modell signalisieren, die Generierung zu beenden. Mehrere Stopp-Sequenzen können hinzugefügt werden.",
        stopPlaceholder: "Stopp-Sequenz eingeben...",
        stopAdd: "Hinzufügen",
        repeatPenalty: "Wiederholungsstrafe",
        repeatPenaltyHelp: "Strafe für die Wiederholung von Token. Höhere Werte reduzieren Wiederholungen. Empfohlen: 1.1.",
        repeatLastN: "Letzten N überprüfen",
        repeatLastNHelp: "Anzahl der Token, die auf Wiederholung geprüft werden. Höhere Werte berücksichtigen mehr Kontext. Empfohlen: 64.",
        numCtx: "Kontextfenstergröße",
        numCtxHelp: "Maximale Kontextlänge für Inferenz. Größere Fenster erlauben mehr Kontext, verbrauchen aber mehr Speicher.",
      },
    },
    dataFiles: {
      title: "Trainingsdaten",
      empty: "Noch keine Dateien",
      dropzone: "JSONL-Dateien hierher ziehen oder klicken zum Hochladen",
      dropzoneActive: "Dateien hier ablegen...",
      uploadButton: "Datei hochladen",
      uploading: "Wird hochgeladen...",
      deleteConfirm: "Diese Datei löschen?",
      previewRowCount: "{{count}} Zeilen insgesamt",
      previewTruncated: "zeige erste {{count}}",
      previewEmpty: "Diese Datei enthält keine Datenzeilen.",
      previewError: "Dateiinhalt konnte nicht geladen werden.",
      invalidRow: "Ungültige Zeile",
      showRawContent: "Roh anzeigen ({{size}})",
      rawContentTitle: "Rohinhalt - Zeile {{line}}",
      rawContentLength: "{{count}} Zeichen",
      errorCount: "{{count}} ungültige Zeile(n) gefunden",
      fileStatus: {
        pending: "Wartet auf Verarbeitung",
        in_progress: "Wird geladen...",
        completed: "{{loaded}} Zeilen geladen ({{skipped}} übersprungen)",
        failed: "Laden fehlgeschlagen",
        skipped: "Übersprungen",
      },
      validationErrors: {
        INVALID_JSON: "Ungültige JSON-Syntax",
        NOT_OBJECT: "Muss ein JSON-Objekt sein",
        MISSING_INSTRUCTION: "Feld \"instruction\" fehlt",
        MISSING_OUTPUT: "Feld \"output\" fehlt",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" muss ein String sein",
        INVALID_OUTPUT_TYPE: "\"output\" muss ein String sein",
      },
    },
    training: {
      title: "Training",
      startButton: "Modell erstellen",
      cancelButton: "Training abbrechen",
      noModel: "Bitte wähle zuerst ein Modell aus",
      noDataFiles: "Bitte füge mindestens eine Datei hinzu",
      readyDescription: "Alles ist eingerichtet. Klicke auf den Button oben, um dein Modell zu erstellen.",
      status: {
        idle: "Bereit",
        starting: "Wird gestartet...",
        loading_data: "Lade Daten...",
        loading_model: "Lade Modell...",
        training: "Trainiere...",
        exporting: "Exportiere Modell...",
        converting: "Konvertiere zu GGUF...",
        completed: "Abgeschlossen",
        failed: "Fehlgeschlagen",
        cancelled: "Abgebrochen",
      },
      progress: "Fortschritt",
      step: "Schritt {{current}} von {{total}}",
      device: "Gerät",
      taskList: "Aufgaben",
      tasks: {
        detect_device: "Rechengerät erkennen",
        import_libraries: "ML-Bibliotheken importieren",
        load_model: "Basismodell laden",
        setup_lora: "LoRA-Adapter einrichten",
        tokenize: "Daten laden und tokenisieren",
        train: "Modell trainieren",
        merge_lora: "LoRA mit Basismodell zusammenführen",
        convert_gguf: "In GGUF-Format konvertieren",
        create_modelfile: "Ollama-Modelfile erstellen",
      },
      taskWarnings: "{{count}} ungültige Zeile(n) übersprungen",
      errorTitle: "Training fehlgeschlagen",
      completed: "Training abgeschlossen",
      completedDescription: "Dein Modell wurde erfolgreich erstellt. Prüfe den Output-Ordner für das Modelfile.",
      cancelled: "Training wurde abgebrochen.",
    },
    ollama: {
      title: "Ollama-Integration",
      createButton: "In Ollama erstellen",
      runButton: "In Ollama ausführen",
      modelName: "Modellname",
      creating: "Erstelle Modell...",
      running: "Öffne Terminal...",
    },
    errors: {
      ERR_PROJECT_1001: "Ein Projekt mit diesem Namen existiert bereits.",
      ERR_PROJECT_1002: "Projekt nicht gefunden.",
      ERR_PROJECT_1003: "Ungültiger Projektname.",
      ERR_PROJECT_1004: "Projektname darf nicht leer sein.",
      ERR_PROJECT_1005: "Projekt konnte nicht erstellt werden.",
      ERR_PROJECT_1006: "Projekt konnte nicht gelöscht werden.",
      ERR_PROJECT_1007: "Projekt konnte nicht aktualisiert werden.",
      ERR_MODEL_2001: "Modellkonfiguration konnte nicht gelesen werden.",
      ERR_MODEL_2002: "Modellkonfiguration konnte nicht geschrieben werden.",
      ERR_DATA_3001: "Datei nicht gefunden.",
      ERR_DATA_3002: "Ungültiger Dateityp. Nur JSONL-Dateien sind erlaubt.",
      ERR_DATA_3003: "Datei konnte nicht hochgeladen werden.",
      ERR_DATA_3004: "Datei konnte nicht gelöscht werden.",
      ERR_DATA_3005: "Dateien konnten nicht geladen werden.",
      ERR_TRAINING_4001: "Ein Training läuft bereits.",
      ERR_TRAINING_4002: "Es läuft kein Training.",
      ERR_TRAINING_4003: "Bitte füge Trainingsdaten hinzu.",
      ERR_TRAINING_4004: "Eine Trainingsdatei wurde nicht gefunden.",
      ERR_TRAINING_4005: "Modell konnte nicht geladen werden.",
      ERR_TRAINING_4006: "Training fehlgeschlagen.",
      ERR_TRAINING_4007: "Modell konnte nicht exportiert werden.",
      ERR_TRAINING_4008: "Training wurde abgebrochen.",
      ERR_TRAINING_4009: "llama.cpp wurde nicht gefunden. Bitte installiere es zuerst.",
      ERR_HF_5001: "Nicht bei Hugging Face angemeldet.",
      ERR_HF_5002: "Hugging Face Anmeldung fehlgeschlagen.",
      ERR_HF_5003: "Ungültiger Hugging Face Token.",
      ERR_OLLAMA_6001: "Ollama ist nicht installiert.",
      ERR_OLLAMA_6002: "Ollama läuft nicht.",
      ERR_OLLAMA_6003: "Modell konnte nicht in Ollama erstellt werden.",
      ERR_OLLAMA_6004: "Modell in Ollama nicht gefunden.",
      ERR_OLLAMA_6005: "Modelfile nicht gefunden. Bitte trainiere das Modell zuerst.",
      ERR_OLLAMA_6006: "Terminal konnte nicht geöffnet werden.",
      ERR_OLLAMA_6007: "Kein Basismodell konfiguriert. Bitte wähle zuerst ein Modell aus.",
      unknown: "Ein unerwarteter Fehler ist aufgetreten.",
    },
    validation: {
      mustBeInteger: "Muss eine ganze Zahl sein",
      mustBeNumber: "Muss eine gültige Zahl sein",
      mustBeString: "Muss Text sein",
      mustBeBoolean: "Muss wahr oder falsch sein",
      mustBeArray: "Muss eine Liste sein",
      mustBeGreaterThan: "Muss größer als {{min}} sein",
      mustBeAtLeast: "Muss mindestens {{min}} sein",
      mustBeAtMost: "Darf höchstens {{max}} sein",
      maxLength: "Maximal {{maxLength}} Zeichen",
    },
  },
};

export default de;
