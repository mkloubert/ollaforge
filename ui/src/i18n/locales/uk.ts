// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const uk: TranslationSchema = {
  translation: {
    common: {
      loading: "Завантаження...",
      error: "Сталася помилка",
      retry: "Повторити",
      cancel: "Скасувати",
      save: "Зберегти",
      delete: "Видалити",
      create: "Створити",
      back: "Назад",
      name: "Назва",
      actions: "Дії",
      optional: "необов'язково",
      edit: "Редагувати",
      ok: "OK",
      dismiss: "Закрити",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "Головна",
      projects: "Проєкти",
    },
    theme: {
      light: "Світла",
      dark: "Темна",
      system: "Система",
      toggle: "Змінити тему",
    },
    language: {
      en: "Англійська",
      de: "Німецька",
      es: "Іспанська",
      fr: "Французька",
      pt: "Португальська",
      uk: "Українська",
      zh: "Китайська",
      ja: "Японська",
      ko: "Корейська",
      ar: "Арабська",
      hi: "Гінді",
      it: "Італійська",
      nl: "Нідерландська",
      pl: "Польська",
      select: "Вибрати мову",
    },
    api: {
      status: "Статус API",
      connected: "Підключено",
      disconnected: "Відключено",
      checking: "Перевірка...",
    },
    huggingface: {
      status: {
        loggedIn: "Увійшли як {{username}}",
        loggedOut: "Не авторизовано",
        checking: "Перевірка...",
      },
      changeToken: "Змінити токен",
      login: {
        title: "Вхід у Hugging Face",
        description:
          "Введіть токен доступу Hugging Face для доступу до захищених моделей.",
        tokenLabel: "Токен доступу",
        tokenPlaceholder: "hf_...",
        help: "Вам потрібен токен доступу Hugging Face для завантаження захищених моделей.",
        getToken: "Отримайте токен тут",
        submit: "Увійти",
        submitting: "Вхід...",
        success: "Успішно авторизовано!",
      },
      errors: {
        loginFailed: "Помилка входу. Перевірте свій токен.",
        invalidToken: "Невірний формат токена. Токен повинен починатися з 'hf_'.",
      },
    },
    llmProviders: {
      title: "Провайдери LLM",
      status: {
        allValid: "Усі провайдери налаштовані",
        someInvalid: "Деякі провайдери не налаштовані",
        noneConfigured: "Жоден провайдер не налаштований",
        checking: "Перевірка...",
        valid: "Дійсний",
        invalid: "Не налаштовано",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "Налаштувати {{provider}}",
        description: "Введіть API-ключ {{provider}} для активації інтеграції.",
        tokenLabel: "API-ключ",
        help: "Вам потрібен API-ключ для використання функцій {{provider}}.",
        getToken: "Отримайте API-ключ тут",
        submit: "Зберегти",
        submitting: "Збереження...",
        success: "API-ключ успішно збережено!",
      },
      changeToken: "Змінити API-ключ",
      errors: {
        loginFailed: "Не вдалося зберегти API-ключ. Перевірте свій ключ.",
      },
    },
    generateFromSources: {
      title: "Генерувати з джерел",
      button: "Генерувати з джерел",
      buttonDisabled: "Провайдер LLM не налаштований",
      sources: {
        title: "Джерела даних",
        uploadFile: "Завантажити файл",
        uploadHint: "Перетягніть або натисніть для завантаження",
        addText: "Додати текст",
        textPlaceholder: "Вставте текст сюди...",
        empty: "Джерела ще не додано",
        estimatedTokens: "~{{tokens}} токенів",
        totalTokens: "Всього: ~{{tokens}} токенів",
        sourcesCount: "{{count}} джерело(а)",
        acceptedFormats: "Прийнятні: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "Кількість токенів перевищує ліміт контекстного вікна ({{limit}} токенів)",
      },
      llm: {
        selectModel: "Вибрати модель...",
        contextInfo: "Контекст: {{context}}K токенів",
        generate: "Генерувати",
        generating: "Генерація...",
        progress: "Обробка фрагмента {{current}} з {{total}}...",
        targetLanguage: "Мова виводу",
        languages: {
          auto: "Як вхідні дані",
          en: "Англійська",
          de: "Німецька",
          es: "Іспанська",
          fr: "Французька",
          pt: "Португальська",
          uk: "Українська",
          zh: "Китайська (спрощена)",
          ja: "Японська",
          ko: "Корейська",
          ar: "Арабська",
          hi: "Гінді",
          it: "Італійська",
          nl: "Нідерландська",
          pl: "Польська",
        },
      },
      results: {
        title: "Згенеровані дані",
        empty: "Згенеруйте дані за допомогою лівої панелі",
        instruction: "Інструкція",
        output: "Вивід",
        addRow: "Додати рядок",
        deleteRow: "Видалити",
        validRows: "{{valid}} з {{total}} рядків дійсні",
        generated: "Згенеровано {{count}} рядків навчальних даних",
      },
      save: {
        title: "Зберегти як JSONL",
        filename: "Назва файлу",
        save: "Зберегти",
        saving: "Збереження...",
        success: "Файл {{filename}} успішно збережено",
      },
      errors: {
        emptyCell: "Клітинка не може бути порожньою",
        invalidFilename: "Невірна назва файлу",
        noData: "Немає даних для збереження",
        invalidRows: "Спочатку виправте недійсні рядки",
      },
    },
    projects: {
      title: "Проєкти",
      empty: "Проєктів поки немає",
      emptyDescription: "Створіть свій перший проєкт, щоб почати.",
      createNew: "Новий проєкт",
      createTitle: "Створити новий проєкт",
      createDescription: "Введіть назву для нового проєкту.",
      namePlaceholder: "Мій проєкт",
      nameLabel: "Назва проєкту",
      descriptionLabel: "Опис",
      descriptionPlaceholder: "Короткий опис вашого проєкту",
      creating: "Створення...",
      saving: "Збереження...",
      openProject: "Відкрити проєкт",
      editTitle: "Редагувати проєкт",
      editDescription: "Оновіть назву та опис проєкту.",
      deleteTitle: "Видалити проєкт",
      deleteDescription:
        "Ви впевнені, що хочете видалити \"{{name}}\"? Цю дію неможливо скасувати.",
      deleting: "Видалення...",
      openFolder: "Відкрити папку",
    },
    project: {
      title: "Проєкт",
      backToProjects: "Назад до проєктів",
      selectModel: "Базова модель",
      selectModelPlaceholder: "Вибрати модель...",
      targetName: "Назва цільової моделі",
      targetNamePlaceholder: "Введіть власну назву...",
      configuration: "Конфігурація",
      status: "Статус",
      tabs: {
        basic: "Основні",
        advanced: "Розширені",
      },
      advancedPlaceholder: "Розширені налаштування незабаром...",
    },
    advancedConfig: {
      helpPanel: {
        title: "Про розширені налаштування",
        description: "Ці налаштування контролюють, як ваша модель навчається за допомогою QLoRA (Quantized Low-Rank Adaptation). QLoRA дозволяє тонке налаштування великих мовних моделей на споживчому обладнанні за допомогою 4-бітної квантизації та адаптерів низького рангу. Значення за замовчуванням добре працюють для більшості випадків - змінюйте їх лише якщо розумієте їх вплив.",
        learnMore: "Дізнатися більше",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "Стаття QLoRA",
          lora: "LoRA пояснення",
          transformers: "Документація з навчання",
        },
      },
      trainingParams: {
        title: "Параметри навчання",
        numEpochs: "Епохи",
        numEpochsHelp: "Кількість проходів навчання. Більше епох може покращити якість, але ризикує перенавчанням. Рекомендовано: 1-5.",
        batchSize: "Розмір батчу",
        batchSizeHelp: "Зразки на крок навчання. Більші розміри навчаються швидше, але потребують більше пам'яті. Рекомендовано: 1-8.",
        gradientAccumulation: "Накопичення градієнтів",
        gradientAccumulationHelp: "Накопичує градієнти за кілька кроків. Імітує більший розмір батчу з меншою пам'яттю.",
        learningRate: "Швидкість навчання",
        learningRateHelp: "Розмір кроку для оновлення ваг. Занадто високий викликає нестабільність, занадто низький сповільнює навчання. Рекомендовано: 1e-5 до 5e-4.",
        warmupRatio: "Співвідношення прогріву",
        warmupRatioHelp: "Частка навчання для поступового збільшення швидкості навчання. Допомагає стабілізувати раннє навчання.",
        maxLength: "Максимальна довжина токенів",
        maxLengthHelp: "Максимальна довжина послідовності для навчання. Довші послідовності потребують більше пам'яті.",
        fp16: "FP16 (Половинна точність)",
        fp16Help: "Використовуйте 16-бітну плаваючу точку для швидшого навчання. Доступно лише на CUDA GPU.",
        optimizer: "Оптимізатор",
        optimizerHelp: "Алгоритм для оновлення ваг. paged_adamw_8bit ефективний для пам'яті QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (рекомендовано для GPU)",
          adamw_torch: "AdamW (рекомендовано для CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        weightDecay: "Затухання ваг",
        weightDecayHelp: "L2 регуляризація для запобігання перенавчанню. Вищі значення додають більше регуляризації. Рекомендовано: 0.01.",
        maxGradNorm: "Максимальна норма градієнта",
        maxGradNormHelp: "Максимальна норма градієнта для обрізки. Запобігає вибуховим градієнтам. Рекомендовано: 1.0.",
        lrScheduler: "Планувальник LR",
        lrSchedulerHelp: "Стратегія планувальника швидкості навчання. Контролює, як змінюється швидкість навчання під час тренування.",
        schedulers: {
          linear: "Лінійний (рекомендовано)",
          cosine: "Косинусний",
          constant: "Постійний",
          polynomial: "Поліноміальний",
        },
        neftuneNoise: "NEFTune Noise Alpha",
        neftuneNoiseHelp: "Додає шум до ембедингів під час навчання. Може покращити узагальнення. 0 = вимкнено, 5-15 рекомендовано коли увімкнено.",
        seed: "Випадкове насіння",
        seedHelp: "Насіння для відтворюваності. Використовуйте те саме насіння для ідентичних результатів між запусками.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "Використовуйте точність bfloat16 замість fp16. Доступно лише на GPU Ampere+ (RTX 3000+). Краща числова стабільність ніж fp16.",
        loggingSteps: "Кроки логування",
        loggingStepsHelp: "Логувати метрики навчання кожні N кроків. Нижчі значення дають частіші оновлення, але можуть сповільнити навчання.",
        saveStrategy: "Стратегія збереження",
        saveStrategyHelp: "Коли зберігати контрольні точки моделі під час навчання.",
        saveStrategies: {
          no: "Без контрольних точок",
          epoch: "Після кожної епохи (рекомендовано)",
          steps: "Кожні N кроків",
        },
      },
      defaults: {
        showDefaults: "Використовуються значення за замовчуванням",
        cudaDefault: "За замовчуванням GPU: {{value}}",
        cpuDefault: "За замовчуванням CPU: {{value}}",
        resetToDefaults: "Скинути до значень за замовчуванням",
        resetConfirm: "Усі значення в цьому розділі будуть скинуті до значень за замовчуванням.",
      },
      loraParams: {
        title: "Конфігурація LoRA",
        rank: "Ранг (r)",
        rankHelp: "Розмірність матриць низького рангу. Вищі значення захоплюють більше інформації, але використовують більше пам'яті та ризикують перенавчанням. Рекомендовано: 8-64.",
        alpha: "Альфа",
        alphaHelp: "Масштабний коефіцієнт для ваг LoRA. Зазвичай встановлюється на 2x рангу. Вищі значення збільшують вплив тонкого налаштування.",
        dropout: "Dropout",
        dropoutHelp: "Ймовірність dropout для шарів LoRA. Допомагає запобігти перенавчанню. Рекомендовано: 0.05-0.1.",
        targetModules: "Цільові модулі",
        targetModulesHelp: "Шари моделі, до яких застосовувати LoRA. Більше модулів = більше ємності тонкого налаштування, але більше використання пам'яті.",
        modules: {
          q_proj: "Проєкція запиту (q_proj)",
          k_proj: "Проєкція ключа (k_proj)",
          v_proj: "Проєкція значення (v_proj)",
          o_proj: "Проєкція виводу (o_proj)",
          gate_proj: "Проєкція воріт (gate_proj)",
          up_proj: "Проєкція вгору (up_proj)",
          down_proj: "Проєкція вниз (down_proj)",
        },
        bias: "Навчання зміщення",
        biasHelp: "Як обробляти терміни зміщення під час навчання. 'none' заморожує зміщення, 'lora_only' навчає зміщення LoRA, 'all' навчає всі зміщення.",
        biasOptions: {
          none: "Немає (заморозити зміщення)",
          lora_only: "Лише LoRA",
          all: "Усі зміщення",
        },
        useRslora: "Використовувати RSLoRA",
        useRsloraHelp: "Rank-Stabilized LoRA покращує стабільність навчання та продуктивність для вищих рангів (r >= 64). Рекомендовано для великих рангів.",
        useDora: "Використовувати DoRA (Експериментально)",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptation може покращити якість тонкого налаштування. Експериментальна функція, може збільшити час навчання.",
        modulesToSave: "Модулі для збереження",
        modulesToSaveHelp: "Додаткові модулі для повного навчання (не з LoRA). Корисно для навчання вихідних шарів як lm_head.",
        saveModules: {
          lm_head: "Голова мовної моделі (lm_head)",
          embed_tokens: "Ембединги токенів (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "Квантизація",
        loadIn4bit: "Завантажити в 4 біти",
        loadIn4bitHelp: "Завантажує ваги моделі в 4-бітній точності для зменшеного використання пам'яті. Потрібно для QLoRA на обмеженій пам'яті GPU. Доступно лише на CUDA GPU.",
        quantType: "Тип 4-бітної квантизації",
        quantTypeHelp: "Алгоритм для 4-бітної квантизації. NF4 (Normal Float 4) рекомендується для кращої точності.",
        quantTypes: {
          nf4: "NF4 (рекомендовано)",
          fp4: "FP4",
        },
        doubleQuant: "Подвійна квантизація",
        doubleQuantHelp: "Застосовує вторинну квантизацію для подальшого зменшення пам'яті. Невелика втрата точності за значну економію пам'яті.",
        computeDtype: "Тип даних обчислень",
        computeDtypeHelp: "Тип даних для обчислень під час навчання. bfloat16 пропонує кращу числову стабільність на GPU Ampere+ (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (рекомендовано)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (повна точність)",
        },
        outputQuantization: "Вихідна квантизація",
        outputQuantizationHelp: "Формат квантизації для фінальної моделі GGUF. q8_0 пропонує хороший баланс між розміром та якістю.",
        outputTypes: {
          f32: "F32 (повна точність, найбільший)",
          f16: "F16 (половинна точність)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8 біт, рекомендовано)",
          auto: "Авто (дозволити llama.cpp вирішити)",
        },
        cudaOnly: "Ці налаштування застосовуються лише при навчанні на CUDA GPU.",
      },
      modelfileParams: {
        title: "Modelfile Ollama",
        temperature: "Температура",
        temperatureHelp: "Контролює випадковість у виводі. Нижчі значення роблять відповіді більш сфокусованими та детерміністичними, вищі значення більш креативними. Рекомендовано: 0.7-0.9.",
        topP: "Top P (Вибірка ядра)",
        topPHelp: "Розглядає лише токени з кумулятивною ймовірністю до цього значення. Нижчі значення фокусуються на більш ймовірних токенах. Рекомендовано: 0.9.",
        topK: "Top K",
        topKHelp: "Обмежує вибір токенів до K найбільш ймовірних варіантів. Нижчі значення більш сфокусовані. Рекомендовано: 40.",
        system: "Системний промпт",
        systemHelp: "Інструкції, що визначають, як модель повинна поводитися. Це встановлює особистість та можливості моделі.",
        systemPlaceholder: "Ви корисний помічник.",
        stop: "Послідовності зупинки",
        stopHelp: "Послідовності, які сигналізують моделі зупинити генерацію. Можна додати кілька послідовностей зупинки.",
        stopPlaceholder: "Введіть послідовність зупинки...",
        stopAdd: "Додати",
        repeatPenalty: "Штраф за повторення",
        repeatPenaltyHelp: "Штраф за повторення токенів. Вищі значення зменшують повторення. Рекомендовано: 1.1.",
        repeatLastN: "Повторити останні N",
        repeatLastNHelp: "Кількість токенів для перевірки на повторення. Вищі значення враховують більше контексту. Рекомендовано: 64.",
        numCtx: "Розмір контекстного вікна",
        numCtxHelp: "Максимальна довжина контексту для інференції. Більші вікна дозволяють більше контексту, але використовують більше пам'яті.",
      },
    },
    dataFiles: {
      title: "Навчальні дані",
      empty: "Файлів даних поки немає",
      dropzone: "Перетягніть файли JSONL сюди або натисніть для завантаження",
      dropzoneActive: "Відпустіть файли тут...",
      uploadButton: "Завантажити файл",
      uploading: "Завантаження...",
      deleteConfirm: "Видалити цей файл?",
      previewRowCount: "{{count}} рядків всього",
      previewTruncated: "показано перших {{count}}",
      previewEmpty: "Цей файл не містить рядків даних.",
      previewError: "Не вдалося завантажити вміст файлу.",
      invalidRow: "Недійсний рядок",
      showRawContent: "Показати сирий ({{size}})",
      rawContentTitle: "Сирий вміст - Рядок {{line}}",
      rawContentLength: "{{count}} символів",
      errorCount: "Знайдено {{count}} недійсних рядків",
      fileStatus: {
        pending: "Очікує обробки",
        in_progress: "Завантаження...",
        completed: "Завантажено {{loaded}} рядків ({{skipped}} пропущено)",
        failed: "Не вдалося завантажити",
        skipped: "Пропущено",
      },
      validationErrors: {
        INVALID_JSON: "Невірний синтаксис JSON",
        NOT_OBJECT: "Має бути об'єктом JSON",
        MISSING_INSTRUCTION: "Відсутнє поле \"instruction\"",
        MISSING_OUTPUT: "Відсутнє поле \"output\"",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" має бути рядком",
        INVALID_OUTPUT_TYPE: "\"output\" має бути рядком",
      },
    },
    training: {
      title: "Навчання",
      startButton: "Створити модель",
      cancelButton: "Скасувати навчання",
      noModel: "Спочатку виберіть модель",
      noDataFiles: "Додайте принаймні один файл даних",
      readyDescription: "Все налаштовано. Натисніть кнопку вище, щоб почати створення моделі.",
      status: {
        idle: "Готово",
        starting: "Запуск...",
        loading_data: "Завантаження даних...",
        loading_model: "Завантаження моделі...",
        training: "Навчання...",
        exporting: "Експорт моделі...",
        converting: "Конвертація в GGUF...",
        completed: "Завершено",
        failed: "Невдача",
        cancelled: "Скасовано",
      },
      progress: "Прогрес",
      step: "Крок {{current}} з {{total}}",
      device: "Пристрій",
      taskList: "Завдання",
      tasks: {
        detect_device: "Виявлення обчислювального пристрою",
        import_libraries: "Імпорт ML бібліотек",
        load_model: "Завантаження базової моделі",
        setup_lora: "Налаштування адаптера LoRA",
        tokenize: "Завантаження та токенізація даних",
        train: "Навчання моделі",
        merge_lora: "Об'єднання LoRA з базовою моделлю",
        convert_gguf: "Конвертація у формат GGUF",
        create_modelfile: "Створення Modelfile Ollama",
        register_ollama: "Реєстрація моделі в Ollama",
      },
      taskWarnings: "{{count}} недійсних рядків пропущено",
      stillWorking: "Все ще працює...",
      errorTitle: "Навчання невдале",
      completed: "Навчання завершено",
      completedDescription: "Вашу модель успішно створено. Перевірте папку виводу для Modelfile.",
      cancelled: "Навчання було скасовано.",
    },
    ollama: {
      title: "Інтеграція Ollama",
      runButton: "Запустити в Ollama",
      modelName: "Назва моделі",
      running: "Відкриття терміналу...",
    },
    presets: {
      title: "Пресети навчання",
      description: "Конфігурації швидкого старту, оптимізовані для різних випадків використання. Виберіть пресет для застосування його налаштувань.",
      applyButton: "Застосувати",
      applyConfirmTitle: "Застосувати пресет?",
      applyConfirmDescription: "Це перезапише ваші поточні налаштування навчання, LoRA та квантизації значеннями пресету \"{{preset}}\". Цю дію неможливо скасувати.",
      recommended: "Рекомендовано",
      allModels: "Усі моделі",
      balanced: {
        name: "Збалансований",
        description: "Хороший баланс швидкості та якості для більшості завдань",
        pros: {
          versatile: "Добре працює з більшістю моделей і даних",
          stable: "Стабільне навчання з перевіреними значеннями за замовчуванням",
          good_defaults: "Хороша відправна точка для експериментів",
        },
        cons: {
          not_specialized: "Не оптимізовано для специфічних випадків використання",
          moderate_time: "Помірний час навчання",
        },
      },
      chat: {
        name: "Чат / Розмова",
        description: "Оптимізовано для розмовного AI та виконання інструкцій",
        pros: {
          natural_responses: "Більш природні розмовні відповіді",
          instruction_following: "Краще виконання інструкцій",
          diverse_outputs: "Більш різноманітні та креативні виводи",
        },
        cons: {
          more_memory: "Вище використання пам'яті",
          longer_training: "Довший час навчання",
        },
      },
      code: {
        name: "Генерація коду",
        description: "Оптимізовано для програмування та завершення коду",
        pros: {
          precise_syntax: "Точне вивчення синтаксису",
          low_dropout: "Низький dropout для точності",
          all_modules: "Націлено на всі відповідні шари",
        },
        cons: {
          more_memory: "Вище використання пам'яті",
          slower_training: "Повільніша швидкість навчання",
        },
      },
      fast: {
        name: "Швидка ітерація",
        description: "Швидке навчання для швидких експериментів",
        pros: {
          quick_results: "Швидкі результати для тестування",
          low_memory: "Нижчі вимоги до пам'яті",
          rapid_testing: "Ідеально для швидкого прототипування",
        },
        cons: {
          lower_quality: "Нижча якість виводу",
          less_learning: "Менш ретельне навчання",
        },
      },
      high_quality: {
        name: "Висока якість",
        description: "Максимальна якість ціною часу навчання",
        pros: {
          best_results: "Найкращі можливі результати",
          thorough_learning: "Ретельне навчання протягом більше епох",
          all_modules: "Повне покриття шарів",
        },
        cons: {
          long_training: "Довгий час навчання",
          high_memory: "Високі вимоги до пам'яті",
          needs_gpu: "Потрібен потужний GPU",
        },
      },
      low_memory: {
        name: "Мало пам'яті",
        description: "Мінімальне використання VRAM для обмеженого обладнання",
        pros: {
          minimal_vram: "Мінімальне використання VRAM",
          works_on_consumer: "Працює на споживчих GPU",
          gradient_accumulation: "Ефективне накопичення градієнтів",
        },
        cons: {
          slower_training: "Повільніша швидкість навчання",
          smaller_rank: "Менший ранг LoRA обмежує ємність",
        },
      },
      multilingual: {
        name: "Багатомовний",
        description: "Оптимізовано для багатомовних моделей",
        pros: {
          language_diversity: "Зберігає мовне різноманіття",
          balanced_learning: "Збалансоване крос-лінгвальне навчання",
          longer_warmup: "Розширений прогрів для мовної адаптації",
        },
        cons: {
          needs_diverse_data: "Потребує різноманітних навчальних даних",
          moderate_time: "Помірний час навчання",
        },
      },
      reasoning: {
        name: "Міркування / Математика",
        description: "Оптимізовано для логічного міркування та математики",
        pros: {
          precise_learning: "Точне та ретельне навчання",
          low_dropout: "Низький dropout для послідовності",
          consistent_outputs: "Більш послідовні виводи",
        },
        cons: {
          more_epochs: "Потрібно більше епох навчання",
          higher_rank: "Вищий ранг збільшує пам'ять",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "Проєкт з такою назвою вже існує.",
      ERR_PROJECT_1002: "Проєкт не знайдено.",
      ERR_PROJECT_1003: "Невірна назва проєкту.",
      ERR_PROJECT_1004: "Назва проєкту не може бути порожньою.",
      ERR_PROJECT_1005: "Не вдалося створити проєкт.",
      ERR_PROJECT_1006: "Не вдалося видалити проєкт.",
      ERR_PROJECT_1007: "Не вдалося оновити проєкт.",
      ERR_PROJECT_1008: "Не вдалося відкрити папку проєкту.",
      ERR_MODEL_2001: "Не вдалося прочитати конфігурацію моделей.",
      ERR_MODEL_2002: "Не вдалося записати конфігурацію моделей.",
      ERR_DATA_3001: "Файл даних не знайдено.",
      ERR_DATA_3002: "Невірний тип файлу. Дозволені лише файли JSONL.",
      ERR_DATA_3003: "Не вдалося завантажити файл.",
      ERR_DATA_3004: "Не вдалося видалити файл.",
      ERR_DATA_3005: "Не вдалося прочитати файли даних.",
      ERR_TRAINING_4001: "Завдання навчання вже виконується.",
      ERR_TRAINING_4002: "Немає запущеного завдання навчання.",
      ERR_TRAINING_4003: "Додайте файли даних перед початком навчання.",
      ERR_TRAINING_4004: "Файл навчальних даних не знайдено.",
      ERR_TRAINING_4005: "Не вдалося завантажити модель.",
      ERR_TRAINING_4006: "Навчання невдале.",
      ERR_TRAINING_4007: "Не вдалося експортувати модель.",
      ERR_TRAINING_4008: "Навчання було скасовано.",
      ERR_TRAINING_4009: "llama.cpp не знайдено. Спочатку встановіть його.",
      ERR_HF_5001: "Не авторизовано в Hugging Face.",
      ERR_HF_5002: "Помилка входу в Hugging Face.",
      ERR_HF_5003: "Невірний токен Hugging Face.",
      ERR_OLLAMA_6001: "Ollama не встановлено.",
      ERR_OLLAMA_6002: "Ollama не запущено.",
      ERR_OLLAMA_6003: "Не вдалося створити модель в Ollama.",
      ERR_OLLAMA_6004: "Модель не знайдено в Ollama.",
      ERR_OLLAMA_6005: "Modelfile не знайдено. Спочатку навчіть модель.",
      ERR_OLLAMA_6006: "Не вдалося відкрити термінал.",
      ERR_OLLAMA_6007: "Базова модель не налаштована. Спочатку виберіть модель.",
      ERR_LLM_8001: "Невірний формат API-ключа.",
      ERR_LLM_8002: "API-ключ відхилено. Перевірте свій ключ.",
      ERR_LLM_8003: "Невідомий провайдер.",
      ERR_LLM_8004: "Не вдалося досягти API провайдера.",
      ERR_LLM_8005: "Не вдалося зберегти API-ключ.",
      ERR_DATA_SOURCE_9001: "Невірний тип файлу для джерела даних.",
      ERR_DATA_SOURCE_9002: "Файл занадто великий.",
      ERR_DATA_SOURCE_9003: "Джерело даних порожнє.",
      ERR_GENERATION_9101: "Провайдер LLM не налаштований.",
      ERR_GENERATION_9102: "Модель недоступна.",
      ERR_GENERATION_9103: "Ліміт токенів перевищено. Використовуйте менші джерела даних.",
      ERR_GENERATION_9104: "Помилка зв'язку з API LLM.",
      ERR_GENERATION_9105: "Невірна відповідь від LLM.",
      ERR_GENERATION_9106: "Ліміт запитів перевищено. Зачекайте і спробуйте знову.",
      ERR_SAVE_9201: "Невірна назва файлу.",
      ERR_SAVE_9202: "Не вдалося зберегти файл.",
      unknown: "Сталася неочікувана помилка.",
    },
    validation: {
      mustBeInteger: "Має бути цілим числом",
      mustBeNumber: "Має бути дійсним числом",
      mustBeString: "Має бути текстом",
      mustBeBoolean: "Має бути true або false",
      mustBeArray: "Має бути списком",
      mustBeGreaterThan: "Має бути більше ніж {{min}}",
      mustBeAtLeast: "Має бути принаймні {{min}}",
      mustBeAtMost: "Має бути не більше {{max}}",
      maxLength: "Максимум {{maxLength}} символів",
    },
  },
};

export default uk;
