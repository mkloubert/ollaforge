// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const ar: TranslationSchema = {
  translation: {
    common: {
      loading: "جار التحميل...",
      error: "حدث خطأ",
      retry: "إعادة المحاولة",
      cancel: "إلغاء",
      save: "حفظ",
      delete: "حذف",
      create: "إنشاء",
      back: "رجوع",
      name: "الاسم",
      actions: "الإجراءات",
      optional: "اختياري",
      edit: "تحرير",
      ok: "موافق",
      dismiss: "إغلاق",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "الرئيسية",
      projects: "المشاريع",
    },
    theme: {
      light: "فاتح",
      dark: "داكن",
      system: "النظام",
      toggle: "تبديل السمة",
    },
    language: {
      en: "الإنجليزية",
      de: "الألمانية",
      es: "الإسبانية",
      fr: "الفرنسية",
      pt: "البرتغالية",
      uk: "الأوكرانية",
      zh: "الصينية",
      ja: "اليابانية",
      ko: "الكورية",
      ar: "العربية",
      hi: "الهندية",
      it: "الإيطالية",
      nl: "الهولندية",
      pl: "البولندية",
      select: "اختر اللغة",
    },
    api: {
      status: "حالة API",
      connected: "متصل",
      disconnected: "غير متصل",
      checking: "جار التحقق...",
    },
    huggingface: {
      status: {
        loggedIn: "تم تسجيل الدخول كـ {{username}}",
        loggedOut: "لم يتم تسجيل الدخول",
        checking: "جار التحقق...",
      },
      changeToken: "تغيير الرمز",
      login: {
        title: "تسجيل دخول Hugging Face",
        description:
          "أدخل رمز الوصول الخاص بك من Hugging Face للوصول إلى النماذج المحمية.",
        tokenLabel: "رمز الوصول",
        tokenPlaceholder: "hf_...",
        help: "تحتاج إلى رمز وصول من Hugging Face لتنزيل النماذج المحمية.",
        getToken: "احصل على الرمز من هنا",
        submit: "تسجيل الدخول",
        submitting: "جار تسجيل الدخول...",
        success: "تم تسجيل الدخول بنجاح!",
      },
      errors: {
        loginFailed: "فشل تسجيل الدخول. يرجى التحقق من الرمز.",
        invalidToken: "صيغة الرمز غير صحيحة. يجب أن يبدأ الرمز بـ 'hf_'.",
      },
    },
    llmProviders: {
      title: "مزودو LLM",
      status: {
        allValid: "تم تكوين جميع المزودين",
        someInvalid: "بعض المزودين غير مكونين",
        noneConfigured: "لم يتم تكوين أي مزود",
        checking: "جار التحقق...",
        valid: "صالح",
        invalid: "غير مكون",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "تكوين {{provider}}",
        description: "أدخل مفتاح API الخاص بـ {{provider}} لتفعيل التكامل.",
        tokenLabel: "مفتاح API",
        help: "تحتاج إلى مفتاح API لاستخدام ميزات {{provider}}.",
        getToken: "احصل على مفتاح API من هنا",
        submit: "حفظ",
        submitting: "جار الحفظ...",
        success: "تم حفظ مفتاح API بنجاح!",
      },
      changeToken: "تغيير مفتاح API",
      errors: {
        loginFailed: "فشل حفظ مفتاح API. يرجى التحقق من المفتاح.",
      },
    },
    generateFromSources: {
      title: "توليد من المصادر",
      button: "توليد من المصادر",
      buttonDisabled: "لم يتم تكوين أي مزود LLM",
      sources: {
        title: "مصادر البيانات",
        uploadFile: "رفع ملف",
        uploadHint: "اسحب وأفلت أو انقر للرفع",
        addText: "إضافة نص",
        textPlaceholder: "الصق النص هنا...",
        empty: "لم تتم إضافة أي مصادر بعد",
        estimatedTokens: "~{{tokens}} رمز",
        totalTokens: "المجموع: ~{{tokens}} رمز",
        sourcesCount: "{{count}} مصدر(مصادر)",
        acceptedFormats: "المقبولة: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "عدد الرموز يتجاوز حد نافذة السياق ({{limit}} رمز)",
      },
      llm: {
        selectModel: "اختر النموذج...",
        contextInfo: "السياق: {{context}}K رمز",
        generate: "توليد",
        generating: "جار التوليد...",
        progress: "معالجة الجزء {{current}} من {{total}}...",
        targetLanguage: "لغة الإخراج",
        languages: {
          auto: "نفس لغة الإدخال",
          en: "الإنجليزية",
          de: "الألمانية",
          es: "الإسبانية",
          fr: "الفرنسية",
          pt: "البرتغالية",
          uk: "الأوكرانية",
          zh: "الصينية (المبسطة)",
          ja: "اليابانية",
          ko: "الكورية",
          ar: "العربية",
          hi: "الهندية",
          it: "الإيطالية",
          nl: "الهولندية",
          pl: "البولندية",
        },
      },
      results: {
        title: "البيانات المُولدة",
        empty: "قم بتوليد البيانات باستخدام اللوحة اليسرى",
        instruction: "التعليمات",
        output: "المخرجات",
        addRow: "إضافة صف",
        deleteRow: "حذف",
        validRows: "{{valid}} من {{total}} صف صالح",
        generated: "تم توليد {{count}} صف من بيانات التدريب",
      },
      save: {
        title: "حفظ كـ JSONL",
        filename: "اسم الملف",
        save: "حفظ",
        saving: "جار الحفظ...",
        success: "تم حفظ الملف {{filename}} بنجاح",
      },
      errors: {
        emptyCell: "لا يمكن أن تكون الخلية فارغة",
        invalidFilename: "اسم ملف غير صالح",
        noData: "لا توجد بيانات للحفظ",
        invalidRows: "يرجى إصلاح الصفوف غير الصالحة أولاً",
      },
    },
    projects: {
      title: "المشاريع",
      empty: "لا توجد مشاريع بعد",
      emptyDescription: "أنشئ مشروعك الأول للبدء.",
      createNew: "مشروع جديد",
      createTitle: "إنشاء مشروع جديد",
      createDescription: "أدخل اسماً لمشروعك الجديد.",
      namePlaceholder: "مشروعي",
      nameLabel: "اسم المشروع",
      descriptionLabel: "الوصف",
      descriptionPlaceholder: "وصف موجز لمشروعك",
      creating: "جار الإنشاء...",
      saving: "جار الحفظ...",
      openProject: "فتح المشروع",
      editTitle: "تحرير المشروع",
      editDescription: "تحديث اسم المشروع والوصف.",
      deleteTitle: "حذف المشروع",
      deleteDescription:
        "هل أنت متأكد من حذف \"{{name}}\"؟ لا يمكن التراجع عن هذا الإجراء.",
      deleting: "جار الحذف...",
      openFolder: "فتح المجلد",
    },
    project: {
      title: "المشروع",
      backToProjects: "العودة إلى المشاريع",
      selectModel: "النموذج الأساسي",
      selectModelPlaceholder: "اختر نموذجاً...",
      targetName: "اسم النموذج المستهدف",
      targetNamePlaceholder: "أدخل اسماً مخصصاً...",
      configuration: "التكوين",
      status: "الحالة",
      tabs: {
        basic: "أساسي",
        advanced: "متقدم",
      },
      advancedPlaceholder: "الإعدادات المتقدمة قادمة قريباً...",
    },
    advancedConfig: {
      helpPanel: {
        title: "حول الإعدادات المتقدمة",
        description: "تتحكم هذه الإعدادات في كيفية تدريب نموذجك باستخدام QLoRA (التكيف منخفض الرتبة الكمي). يتيح QLoRA ضبط النماذج اللغوية الكبيرة على أجهزة المستهلك باستخدام التكميم 4 بت والمحولات منخفضة الرتبة. القيم الافتراضية تعمل بشكل جيد لمعظم الحالات - قم بتغييرها فقط إذا كنت تفهم تأثيرها.",
        learnMore: "معرفة المزيد",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "ورقة QLoRA",
          lora: "شرح LoRA",
          transformers: "وثائق التدريب",
        },
      },
      trainingParams: {
        title: "معلمات التدريب",
        numEpochs: "الحقب",
        numEpochsHelp: "عدد مرات التدريب. المزيد من الحقب يمكن أن يحسن الجودة لكنه يخاطر بالإفراط في التلاؤم. الموصى به: 1-5.",
        batchSize: "حجم الدفعة",
        batchSizeHelp: "عينات لكل خطوة تدريب. الأحجام الأكبر تتدرب أسرع لكنها تحتاج ذاكرة أكثر. الموصى به: 1-8.",
        gradientAccumulation: "تراكم التدرج",
        gradientAccumulationHelp: "تراكم التدرجات على خطوات متعددة. يحاكي حجم دفعة أكبر مع ذاكرة أقل.",
        learningRate: "معدل التعلم",
        learningRateHelp: "حجم الخطوة لتحديثات الأوزان. مرتفع جداً يسبب عدم الاستقرار، منخفض جداً يبطئ التدريب. الموصى به: 1e-5 إلى 5e-4.",
        warmupRatio: "نسبة التسخين",
        warmupRatioHelp: "جزء من التدريب لزيادة معدل التعلم تدريجياً. يساعد على استقرار التدريب المبكر.",
        maxLength: "الحد الأقصى لطول الرمز",
        maxLengthHelp: "الحد الأقصى لطول التسلسل للتدريب. التسلسلات الأطول تحتاج ذاكرة أكثر.",
        fp16: "FP16 (نصف الدقة)",
        fp16Help: "استخدام النقطة العائمة 16 بت للتدريب الأسرع. متاح فقط على وحدات معالجة CUDA.",
        optimizer: "المحسن",
        optimizerHelp: "خوارزمية لتحديث الأوزان. paged_adamw_8bit كفؤ في الذاكرة لـ QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (موصى به لـ GPU)",
          adamw_torch: "AdamW (موصى به لـ CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        weightDecay: "تناقص الأوزان",
        weightDecayHelp: "تنظيم L2 لمنع الإفراط في التلاؤم. القيم الأعلى تضيف المزيد من التنظيم. الموصى به: 0.01.",
        maxGradNorm: "الحد الأقصى لمعيار التدرج",
        maxGradNormHelp: "الحد الأقصى لمعيار التدرج لقص التدرج. يمنع انفجار التدرجات. الموصى به: 1.0.",
        lrScheduler: "جدولة معدل التعلم",
        lrSchedulerHelp: "استراتيجية جدولة معدل التعلم. يتحكم في كيفية تغير معدل التعلم أثناء التدريب.",
        schedulers: {
          linear: "خطي (موصى به)",
          cosine: "جيب التمام",
          constant: "ثابت",
          polynomial: "متعدد الحدود",
        },
        neftuneNoise: "ألفا ضوضاء NEFTune",
        neftuneNoiseHelp: "إضافة ضوضاء للتضمينات أثناء التدريب. يمكن أن يحسن التعميم. 0 = معطل، 5-15 موصى به عند التفعيل.",
        seed: "بذرة عشوائية",
        seedHelp: "بذرة للتكرار. استخدم نفس البذرة للحصول على نتائج متطابقة عبر عمليات التدريب.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "استخدام دقة bfloat16 بدلاً من fp16. متاح فقط على وحدات Ampere+ (RTX 3000+). استقرار عددي أفضل من fp16.",
        loggingSteps: "خطوات التسجيل",
        loggingStepsHelp: "تسجيل مقاييس التدريب كل N خطوة. القيم الأقل تعطي تحديثات أكثر تكراراً لكن قد تبطئ التدريب.",
        saveStrategy: "استراتيجية الحفظ",
        saveStrategyHelp: "متى يتم حفظ نقاط تفتيش النموذج أثناء التدريب.",
        saveStrategies: {
          no: "بدون نقاط تفتيش",
          epoch: "بعد كل حقبة (موصى به)",
          steps: "كل N خطوة",
        },
      },
      defaults: {
        showDefaults: "استخدام الافتراضيات",
        cudaDefault: "افتراضي GPU: {{value}}",
        cpuDefault: "افتراضي CPU: {{value}}",
        resetToDefaults: "إعادة تعيين للافتراضيات",
        resetConfirm: "سيتم إعادة تعيين جميع القيم في هذا القسم إلى افتراضياتها.",
      },
      loraParams: {
        title: "تكوين LoRA",
        rank: "الرتبة (r)",
        rankHelp: "بُعد المصفوفات منخفضة الرتبة. القيم الأعلى تلتقط معلومات أكثر لكنها تستخدم ذاكرة أكثر وتخاطر بالإفراط في التلاؤم. الموصى به: 8-64.",
        alpha: "ألفا",
        alphaHelp: "عامل التحجيم لأوزان LoRA. عادةً يتم تعيينه إلى ضعف الرتبة. القيم الأعلى تزيد تأثير الضبط الدقيق.",
        dropout: "الإسقاط",
        dropoutHelp: "احتمال الإسقاط لطبقات LoRA. يساعد على منع الإفراط في التلاؤم. الموصى به: 0.05-0.1.",
        targetModules: "الوحدات المستهدفة",
        targetModulesHelp: "طبقات النموذج لتطبيق LoRA عليها. المزيد من الوحدات = المزيد من سعة الضبط الدقيق لكن استخدام ذاكرة أكثر.",
        modules: {
          q_proj: "إسقاط الاستعلام (q_proj)",
          k_proj: "إسقاط المفتاح (k_proj)",
          v_proj: "إسقاط القيمة (v_proj)",
          o_proj: "إسقاط المخرجات (o_proj)",
          gate_proj: "إسقاط البوابة (gate_proj)",
          up_proj: "الإسقاط الصاعد (up_proj)",
          down_proj: "الإسقاط الهابط (down_proj)",
        },
        bias: "تدريب الانحياز",
        biasHelp: "كيفية التعامل مع حدود الانحياز أثناء التدريب. 'بدون' يجمد الانحيازات، 'LoRA فقط' يدرب انحيازات LoRA، 'الكل' يدرب جميع الانحيازات.",
        biasOptions: {
          none: "بدون (تجميد الانحيازات)",
          lora_only: "LoRA فقط",
          all: "جميع الانحيازات",
        },
        useRslora: "استخدام RSLoRA",
        useRsloraHelp: "LoRA المستقر بالرتبة يحسن استقرار التدريب والأداء للرتب الأعلى (r >= 64). موصى به للرتب الكبيرة.",
        useDora: "استخدام DoRA (تجريبي)",
        useDoraHelp: "التكيف منخفض الرتبة المتحلل بالأوزان يمكن أن يحسن جودة الضبط الدقيق. ميزة تجريبية، قد تزيد وقت التدريب.",
        modulesToSave: "الوحدات للحفظ",
        modulesToSaveHelp: "وحدات إضافية للتدريب الكامل (ليس مع LoRA). مفيد لتدريب طبقات المخرجات مثل lm_head.",
        saveModules: {
          lm_head: "رأس نموذج اللغة (lm_head)",
          embed_tokens: "تضمينات الرموز (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "التكميم",
        loadIn4bit: "تحميل في 4 بت",
        loadIn4bitHelp: "تحميل أوزان النموذج بدقة 4 بت لتقليل استخدام الذاكرة. مطلوب لـ QLoRA على ذاكرة GPU المحدودة. متاح فقط على وحدات CUDA.",
        quantType: "نوع التكميم 4 بت",
        quantTypeHelp: "خوارزمية للتكميم 4 بت. NF4 (Normal Float 4) موصى به لدقة أفضل.",
        quantTypes: {
          nf4: "NF4 (موصى به)",
          fp4: "FP4",
        },
        doubleQuant: "التكميم المزدوج",
        doubleQuantHelp: "تطبيق تكميم ثانوي لتقليل الذاكرة أكثر. مقايضة دقة صغيرة لتوفير ذاكرة كبير.",
        computeDtype: "نوع بيانات الحساب",
        computeDtypeHelp: "نوع البيانات للحسابات أثناء التدريب. bfloat16 يوفر استقراراً عددياً أفضل على وحدات Ampere+ (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (موصى به)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (دقة كاملة)",
        },
        outputQuantization: "تكميم المخرجات",
        outputQuantizationHelp: "تنسيق التكميم لنموذج GGUF النهائي. q8_0 يوفر توازناً جيداً بين الحجم والجودة.",
        outputTypes: {
          f32: "F32 (دقة كاملة، الأكبر)",
          f16: "F16 (نصف الدقة)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8 بت، موصى به)",
          auto: "تلقائي (دع llama.cpp يقرر)",
        },
        cudaOnly: "هذه الإعدادات تنطبق فقط عند التدريب على وحدة CUDA GPU.",
      },
      modelfileParams: {
        title: "ملف نموذج Ollama",
        temperature: "درجة الحرارة",
        temperatureHelp: "يتحكم في العشوائية في المخرجات. القيم الأقل تجعل الاستجابات أكثر تركيزاً وحتمية، القيم الأعلى أكثر إبداعاً. الموصى به: 0.7-0.9.",
        topP: "Top P (أخذ العينات النووية)",
        topPHelp: "النظر فقط في الرموز ذات الاحتمال التراكمي حتى هذه القيمة. القيم الأقل تركز على الرموز الأكثر احتمالاً. الموصى به: 0.9.",
        topK: "Top K",
        topKHelp: "تقييد اختيار الرموز لأكثر K خيارات احتمالاً. القيم الأقل أكثر تركيزاً. الموصى به: 40.",
        system: "موجه النظام",
        systemHelp: "تعليمات تحدد كيف يجب أن يتصرف النموذج. هذا يحدد شخصية النموذج وقدراته.",
        systemPlaceholder: "أنت مساعد مفيد.",
        stop: "تسلسلات الإيقاف",
        stopHelp: "تسلسلات تشير للنموذج بالتوقف عن التوليد. يمكن إضافة عدة تسلسلات إيقاف.",
        stopPlaceholder: "أدخل تسلسل إيقاف...",
        stopAdd: "إضافة",
        repeatPenalty: "عقوبة التكرار",
        repeatPenaltyHelp: "عقوبة لتكرار الرموز. القيم الأعلى تقلل التكرار. الموصى به: 1.1.",
        repeatLastN: "تكرار آخر N",
        repeatLastNHelp: "عدد الرموز للتحقق من التكرار. القيم الأعلى تأخذ سياقاً أكثر بعين الاعتبار. الموصى به: 64.",
        numCtx: "حجم نافذة السياق",
        numCtxHelp: "الحد الأقصى لطول السياق للاستدلال. النوافذ الأكبر تسمح بسياق أكثر لكنها تستخدم ذاكرة أكثر.",
      },
    },
    dataFiles: {
      title: "بيانات التدريب",
      empty: "لا توجد ملفات بيانات بعد",
      dropzone: "أسقط ملفات JSONL هنا أو انقر للرفع",
      dropzoneActive: "أسقط الملفات هنا...",
      uploadButton: "رفع ملف",
      uploading: "جار الرفع...",
      deleteConfirm: "حذف هذا الملف؟",
      previewRowCount: "{{count}} صف إجمالي",
      previewTruncated: "عرض أول {{count}}",
      previewEmpty: "هذا الملف لا يحتوي على صفوف بيانات.",
      previewError: "تعذر تحميل محتوى الملف.",
      invalidRow: "صف غير صالح",
      showRawContent: "عرض الخام ({{size}})",
      rawContentTitle: "المحتوى الخام - السطر {{line}}",
      rawContentLength: "{{count}} حرف",
      errorCount: "تم العثور على {{count}} صف(صفوف) غير صالح",
      fileStatus: {
        pending: "في انتظار المعالجة",
        in_progress: "جار التحميل...",
        completed: "تم تحميل {{loaded}} صف (تم تخطي {{skipped}})",
        failed: "فشل التحميل",
        skipped: "تم التخطي",
      },
      validationErrors: {
        INVALID_JSON: "صيغة JSON غير صالحة",
        NOT_OBJECT: "يجب أن يكون كائن JSON",
        MISSING_INSTRUCTION: "حقل \"instruction\" مفقود",
        MISSING_OUTPUT: "حقل \"output\" مفقود",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" يجب أن يكون نصاً",
        INVALID_OUTPUT_TYPE: "\"output\" يجب أن يكون نصاً",
      },
    },
    training: {
      title: "التدريب",
      startButton: "إنشاء النموذج",
      cancelButton: "إلغاء التدريب",
      noModel: "يرجى اختيار نموذج أولاً",
      noDataFiles: "يرجى إضافة ملف بيانات واحد على الأقل",
      readyDescription: "كل شيء جاهز. انقر على الزر أعلاه لبدء إنشاء النموذج.",
      status: {
        idle: "جاهز",
        starting: "جار البدء...",
        loading_data: "جار تحميل البيانات...",
        loading_model: "جار تحميل النموذج...",
        training: "جار التدريب...",
        exporting: "جار تصدير النموذج...",
        converting: "جار التحويل إلى GGUF...",
        completed: "مكتمل",
        failed: "فشل",
        cancelled: "تم الإلغاء",
      },
      progress: "التقدم",
      step: "الخطوة {{current}} من {{total}}",
      device: "الجهاز",
      taskList: "المهام",
      tasks: {
        detect_device: "اكتشاف جهاز الحساب",
        import_libraries: "استيراد مكتبات ML",
        load_model: "تحميل النموذج الأساسي",
        setup_lora: "إعداد محول LoRA",
        tokenize: "تحميل وترميز البيانات",
        train: "تدريب النموذج",
        merge_lora: "دمج LoRA مع النموذج الأساسي",
        convert_gguf: "التحويل إلى تنسيق GGUF",
        create_modelfile: "إنشاء ملف نموذج Ollama",
        register_ollama: "تسجيل النموذج في Ollama",
      },
      taskWarnings: "تم تخطي {{count}} صف(صفوف) غير صالح",
      stillWorking: "لا يزال يعمل...",
      errorTitle: "فشل التدريب",
      completed: "اكتمل التدريب",
      completedDescription: "تم إنشاء النموذج بنجاح. تحقق من مجلد المخرجات لملف النموذج.",
      cancelled: "تم إلغاء التدريب.",
    },
    ollama: {
      title: "تكامل Ollama",
      runButton: "تشغيل في Ollama",
      modelName: "اسم النموذج",
      running: "جار فتح الطرفية...",
    },
    presets: {
      title: "إعدادات التدريب المسبقة",
      description: "تكوينات بدء سريع محسنة لحالات استخدام مختلفة. اختر إعداداً مسبقاً لتطبيق إعداداته.",
      applyButton: "تطبيق",
      applyConfirmTitle: "تطبيق الإعداد المسبق؟",
      applyConfirmDescription: "سيؤدي هذا إلى استبدال إعدادات التدريب وLoRA والتكميم الحالية بقيم الإعداد المسبق \"{{preset}}\". لا يمكن التراجع عن هذا الإجراء.",
      recommended: "موصى به",
      allModels: "جميع النماذج",
      balanced: {
        name: "متوازن",
        description: "توازن جيد بين السرعة والجودة لمعظم المهام",
        pros: {
          versatile: "يعمل بشكل جيد مع معظم النماذج والبيانات",
          stable: "تدريب مستقر مع افتراضيات مجربة",
          good_defaults: "نقطة بداية جيدة للتجريب",
        },
        cons: {
          not_specialized: "غير محسن لحالات استخدام محددة",
          moderate_time: "وقت تدريب معتدل",
        },
      },
      chat: {
        name: "محادثة / حوار",
        description: "محسن للذكاء الاصطناعي الحواري واتباع التعليمات",
        pros: {
          natural_responses: "استجابات حوارية أكثر طبيعية",
          instruction_following: "اتباع أفضل للتعليمات",
          diverse_outputs: "مخرجات أكثر تنوعاً وإبداعاً",
        },
        cons: {
          more_memory: "استخدام ذاكرة أعلى",
          longer_training: "وقت تدريب أطول",
        },
      },
      code: {
        name: "توليد الكود",
        description: "محسن للبرمجة وإكمال الكود",
        pros: {
          precise_syntax: "تعلم دقيق للصيغة",
          low_dropout: "إسقاط منخفض للدقة",
          all_modules: "يستهدف جميع الطبقات ذات الصلة",
        },
        cons: {
          more_memory: "استخدام ذاكرة أعلى",
          slower_training: "سرعة تدريب أبطأ",
        },
      },
      fast: {
        name: "تكرار سريع",
        description: "تدريب سريع للتجريب السريع",
        pros: {
          quick_results: "نتائج سريعة للاختبار",
          low_memory: "متطلبات ذاكرة أقل",
          rapid_testing: "مثالي للنماذج الأولية السريعة",
        },
        cons: {
          lower_quality: "جودة مخرجات أقل",
          less_learning: "تعلم أقل شمولاً",
        },
      },
      high_quality: {
        name: "جودة عالية",
        description: "أقصى جودة على حساب وقت التدريب",
        pros: {
          best_results: "أفضل النتائج الممكنة",
          thorough_learning: "تدريب شامل على المزيد من الحقب",
          all_modules: "تغطية شاملة للطبقات",
        },
        cons: {
          long_training: "وقت تدريب طويل",
          high_memory: "متطلبات ذاكرة عالية",
          needs_gpu: "يتطلب GPU قوي",
        },
      },
      low_memory: {
        name: "ذاكرة منخفضة",
        description: "استخدام VRAM محدود للأجهزة المحدودة",
        pros: {
          minimal_vram: "استخدام VRAM أدنى",
          works_on_consumer: "يعمل على بطاقات المستهلك",
          gradient_accumulation: "تراكم تدرج فعال",
        },
        cons: {
          slower_training: "سرعة تدريب أبطأ",
          smaller_rank: "رتبة LoRA أصغر تحد من السعة",
        },
      },
      multilingual: {
        name: "متعدد اللغات",
        description: "محسن للنماذج متعددة اللغات",
        pros: {
          language_diversity: "يحافظ على تنوع اللغات",
          balanced_learning: "تعلم متوازن عبر اللغات",
          longer_warmup: "تسخين ممتد لتكيف اللغة",
        },
        cons: {
          needs_diverse_data: "يتطلب بيانات تدريب متنوعة",
          moderate_time: "وقت تدريب معتدل",
        },
      },
      reasoning: {
        name: "المنطق / الرياضيات",
        description: "محسن للتفكير المنطقي والرياضيات",
        pros: {
          precise_learning: "تعلم دقيق وحذر",
          low_dropout: "إسقاط منخفض للاتساق",
          consistent_outputs: "مخرجات أكثر اتساقاً",
        },
        cons: {
          more_epochs: "المزيد من حقب التدريب مطلوبة",
          higher_rank: "رتبة أعلى تزيد الذاكرة",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "يوجد مشروع بهذا الاسم بالفعل.",
      ERR_PROJECT_1002: "المشروع غير موجود.",
      ERR_PROJECT_1003: "اسم المشروع غير صالح.",
      ERR_PROJECT_1004: "لا يمكن أن يكون اسم المشروع فارغاً.",
      ERR_PROJECT_1005: "فشل إنشاء المشروع.",
      ERR_PROJECT_1006: "فشل حذف المشروع.",
      ERR_PROJECT_1007: "فشل تحديث المشروع.",
      ERR_PROJECT_1008: "فشل فتح مجلد المشروع.",
      ERR_MODEL_2001: "فشل قراءة تكوين النماذج.",
      ERR_MODEL_2002: "فشل كتابة تكوين النماذج.",
      ERR_DATA_3001: "ملف البيانات غير موجود.",
      ERR_DATA_3002: "نوع ملف غير صالح. فقط ملفات JSONL مسموحة.",
      ERR_DATA_3003: "فشل رفع الملف.",
      ERR_DATA_3004: "فشل حذف الملف.",
      ERR_DATA_3005: "فشل قراءة ملفات البيانات.",
      ERR_TRAINING_4001: "توجد عملية تدريب قيد التشغيل بالفعل.",
      ERR_TRAINING_4002: "لا توجد عملية تدريب قيد التشغيل.",
      ERR_TRAINING_4003: "يرجى إضافة ملفات بيانات قبل بدء التدريب.",
      ERR_TRAINING_4004: "ملف بيانات التدريب غير موجود.",
      ERR_TRAINING_4005: "فشل تحميل النموذج.",
      ERR_TRAINING_4006: "فشل التدريب.",
      ERR_TRAINING_4007: "فشل تصدير النموذج.",
      ERR_TRAINING_4008: "تم إلغاء التدريب.",
      ERR_TRAINING_4009: "llama.cpp غير موجود. يرجى تثبيته أولاً.",
      ERR_HF_5001: "لم يتم تسجيل الدخول إلى Hugging Face.",
      ERR_HF_5002: "فشل تسجيل الدخول إلى Hugging Face.",
      ERR_HF_5003: "رمز Hugging Face غير صالح.",
      ERR_OLLAMA_6001: "Ollama غير مثبت.",
      ERR_OLLAMA_6002: "Ollama غير قيد التشغيل.",
      ERR_OLLAMA_6003: "فشل إنشاء النموذج في Ollama.",
      ERR_OLLAMA_6004: "النموذج غير موجود في Ollama.",
      ERR_OLLAMA_6005: "ملف النموذج غير موجود. يرجى تدريب النموذج أولاً.",
      ERR_OLLAMA_6006: "فشل فتح الطرفية.",
      ERR_OLLAMA_6007: "لم يتم تكوين نموذج أساسي. يرجى اختيار نموذج أولاً.",
      ERR_LLM_8001: "صيغة مفتاح API غير صالحة.",
      ERR_LLM_8002: "تم رفض مفتاح API. يرجى التحقق من المفتاح.",
      ERR_LLM_8003: "مزود غير معروف.",
      ERR_LLM_8004: "تعذر الوصول إلى API المزود.",
      ERR_LLM_8005: "تعذر حفظ مفتاح API.",
      ERR_DATA_SOURCE_9001: "نوع ملف غير صالح لمصدر البيانات.",
      ERR_DATA_SOURCE_9002: "الملف كبير جداً.",
      ERR_DATA_SOURCE_9003: "مصدر البيانات فارغ.",
      ERR_GENERATION_9101: "مزود LLM غير مكون.",
      ERR_GENERATION_9102: "النموذج غير متاح.",
      ERR_GENERATION_9103: "تم تجاوز حد الرموز. يرجى استخدام مصادر بيانات أصغر.",
      ERR_GENERATION_9104: "خطأ في التواصل مع API LLM.",
      ERR_GENERATION_9105: "استجابة غير صالحة من LLM.",
      ERR_GENERATION_9106: "تم تجاوز حد المعدل. يرجى الانتظار والمحاولة مرة أخرى.",
      ERR_SAVE_9201: "اسم ملف غير صالح.",
      ERR_SAVE_9202: "فشل حفظ الملف.",
      unknown: "حدث خطأ غير متوقع.",
    },
    validation: {
      mustBeInteger: "يجب أن يكون رقماً صحيحاً",
      mustBeNumber: "يجب أن يكون رقماً صالحاً",
      mustBeString: "يجب أن يكون نصاً",
      mustBeBoolean: "يجب أن يكون صحيحاً أو خاطئاً",
      mustBeArray: "يجب أن تكون قائمة",
      mustBeGreaterThan: "يجب أن يكون أكبر من {{min}}",
      mustBeAtLeast: "يجب أن يكون على الأقل {{min}}",
      mustBeAtMost: "يجب أن يكون على الأكثر {{max}}",
      maxLength: "الحد الأقصى {{maxLength}} حرف",
    },
  },
};

export default ar;
