// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const es: TranslationSchema = {
  translation: {
    common: {
      loading: "Cargando...",
      error: "Se produjo un error",
      retry: "Reintentar",
      cancel: "Cancelar",
      save: "Guardar",
      delete: "Eliminar",
      create: "Crear",
      back: "Volver",
      name: "Nombre",
      actions: "Acciones",
      optional: "opcional",
      edit: "Editar",
      ok: "OK",
      dismiss: "Cerrar",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "Inicio",
      projects: "Proyectos",
    },
    theme: {
      light: "Claro",
      dark: "Oscuro",
      system: "Sistema",
      toggle: "Cambiar tema",
    },
    language: {
      en: "Inglés",
      de: "Alemán",
      es: "Español",
      fr: "Francés",
      pt: "Portugués",
      uk: "Ucraniano",
      zh: "Chino",
      ja: "Japonés",
      ko: "Coreano",
      ar: "Árabe",
      hi: "Hindi",
      it: "Italiano",
      nl: "Neerlandés",
      pl: "Polaco",
      select: "Seleccionar idioma",
    },
    api: {
      status: "Estado de la API",
      connected: "Conectado",
      disconnected: "Desconectado",
      checking: "Verificando...",
    },
    huggingface: {
      status: {
        loggedIn: "Conectado como {{username}}",
        loggedOut: "No conectado",
        checking: "Verificando...",
      },
      changeToken: "Cambiar token",
      login: {
        title: "Inicio de sesión en Hugging Face",
        description:
          "Ingresa tu token de acceso de Hugging Face para acceder a modelos protegidos.",
        tokenLabel: "Token de acceso",
        tokenPlaceholder: "hf_...",
        help: "Necesitas un token de acceso de Hugging Face para descargar modelos protegidos.",
        getToken: "Obtén tu token aquí",
        submit: "Iniciar sesión",
        submitting: "Iniciando sesión...",
        success: "¡Sesión iniciada correctamente!",
      },
      errors: {
        loginFailed: "Error de inicio de sesión. Por favor verifica tu token.",
        invalidToken: "Formato de token inválido. El token debe comenzar con 'hf_'.",
      },
    },
    llmProviders: {
      title: "Proveedores LLM",
      status: {
        allValid: "Todos los proveedores configurados",
        someInvalid: "Algunos proveedores no configurados",
        noneConfigured: "Ningún proveedor configurado",
        checking: "Verificando...",
        valid: "Válido",
        invalid: "No configurado",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "Configurar {{provider}}",
        description: "Ingresa tu clave API de {{provider}} para habilitar la integración.",
        tokenLabel: "Clave API",
        help: "Necesitas una clave API para usar las funciones de {{provider}}.",
        getToken: "Obtén tu clave API aquí",
        submit: "Guardar",
        submitting: "Guardando...",
        success: "¡Clave API guardada correctamente!",
      },
      changeToken: "Cambiar clave API",
      errors: {
        loginFailed: "Error al guardar la clave API. Por favor verifica tu clave.",
      },
    },
    generateFromSources: {
      title: "Generar desde fuentes",
      button: "Generar desde fuentes",
      buttonDisabled: "Ningún proveedor LLM configurado",
      sources: {
        title: "Fuentes de datos",
        uploadFile: "Subir archivo",
        uploadHint: "Arrastra y suelta o haz clic para subir",
        addText: "Agregar texto",
        textPlaceholder: "Pega tu texto aquí...",
        empty: "Aún no hay fuentes agregadas",
        estimatedTokens: "~{{tokens}} tokens",
        totalTokens: "Total: ~{{tokens}} tokens",
        sourcesCount: "{{count}} fuente(s)",
        acceptedFormats: "Aceptados: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "El conteo de tokens excede el límite de la ventana de contexto ({{limit}} tokens)",
      },
      llm: {
        selectModel: "Seleccionar modelo...",
        contextInfo: "Contexto: {{context}}K tokens",
        generate: "Generar",
        generating: "Generando...",
        progress: "Procesando fragmento {{current}} de {{total}}...",
        targetLanguage: "Idioma de salida",
        languages: {
          auto: "Igual que la entrada",
          en: "Inglés",
          de: "Alemán",
          es: "Español",
          fr: "Francés",
          pt: "Portugués",
          uk: "Ucraniano",
          zh: "Chino (Simplificado)",
          ja: "Japonés",
          ko: "Coreano",
          ar: "Árabe",
          hi: "Hindi",
          it: "Italiano",
          nl: "Neerlandés",
          pl: "Polaco",
        },
      },
      results: {
        title: "Datos generados",
        empty: "Genera datos usando el panel izquierdo",
        instruction: "Instrucción",
        output: "Salida",
        addRow: "Agregar fila",
        deleteRow: "Eliminar",
        validRows: "{{valid}} de {{total}} filas válidas",
        generated: "{{count}} filas de datos de entrenamiento generadas",
      },
      save: {
        title: "Guardar como JSONL",
        filename: "Nombre de archivo",
        save: "Guardar",
        saving: "Guardando...",
        success: "Archivo {{filename}} guardado correctamente",
      },
      errors: {
        emptyCell: "La celda no puede estar vacía",
        invalidFilename: "Nombre de archivo inválido",
        noData: "No hay datos para guardar",
        invalidRows: "Por favor corrige primero las filas inválidas",
      },
    },
    projects: {
      title: "Proyectos",
      empty: "Aún no hay proyectos",
      emptyDescription: "Crea tu primer proyecto para comenzar.",
      createNew: "Nuevo proyecto",
      createTitle: "Crear nuevo proyecto",
      createDescription: "Ingresa un nombre para tu nuevo proyecto.",
      namePlaceholder: "Mi proyecto",
      nameLabel: "Nombre del proyecto",
      descriptionLabel: "Descripción",
      descriptionPlaceholder: "Una breve descripción de tu proyecto",
      creating: "Creando...",
      saving: "Guardando...",
      openProject: "Abrir proyecto",
      editTitle: "Editar proyecto",
      editDescription: "Actualiza el nombre y la descripción del proyecto.",
      deleteTitle: "Eliminar proyecto",
      deleteDescription:
        "¿Estás seguro de que quieres eliminar \"{{name}}\"? Esta acción no se puede deshacer.",
      deleting: "Eliminando...",
      openFolder: "Abrir carpeta",
    },
    project: {
      title: "Proyecto",
      backToProjects: "Volver a proyectos",
      selectModel: "Modelo base",
      selectModelPlaceholder: "Seleccionar un modelo...",
      targetName: "Nombre del modelo objetivo",
      targetNamePlaceholder: "Ingresa un nombre personalizado...",
      configuration: "Configuración",
      status: "Estado",
      tabs: {
        basic: "Básico",
        advanced: "Avanzado",
      },
      advancedPlaceholder: "Configuración avanzada próximamente...",
    },
    advancedConfig: {
      helpPanel: {
        title: "Acerca de la configuración avanzada",
        description: "Estas configuraciones controlan cómo se entrena tu modelo usando QLoRA (Quantized Low-Rank Adaptation). QLoRA permite el ajuste fino de modelos de lenguaje grandes en hardware de consumo usando cuantización de 4 bits y adaptadores de bajo rango. Los valores predeterminados funcionan bien para la mayoría de los casos de uso - solo cámbialos si entiendes su impacto.",
        learnMore: "Más información",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "Artículo QLoRA",
          lora: "LoRA explicado",
          transformers: "Documentación de entrenamiento",
        },
      },
      trainingParams: {
        title: "Parámetros de entrenamiento",
        numEpochs: "Épocas",
        numEpochsHelp: "Número de pasadas de entrenamiento. Más épocas pueden mejorar la calidad pero arriesgan el sobreajuste. Recomendado: 1-5.",
        batchSize: "Tamaño de lote",
        batchSizeHelp: "Muestras por paso de entrenamiento. Tamaños más grandes entrenan más rápido pero necesitan más memoria. Recomendado: 1-8.",
        gradientAccumulation: "Acumulación de gradientes",
        gradientAccumulationHelp: "Acumula gradientes sobre múltiples pasos. Simula un tamaño de lote más grande con menos memoria.",
        learningRate: "Tasa de aprendizaje",
        learningRateHelp: "Tamaño de paso para actualizaciones de pesos. Muy alto causa inestabilidad, muy bajo ralentiza el entrenamiento. Recomendado: 1e-5 a 5e-4.",
        warmupRatio: "Ratio de calentamiento",
        warmupRatioHelp: "Fracción del entrenamiento para aumentar gradualmente la tasa de aprendizaje. Ayuda a estabilizar el entrenamiento inicial.",
        maxLength: "Longitud máxima de tokens",
        maxLengthHelp: "Longitud máxima de secuencia para entrenamiento. Secuencias más largas necesitan más memoria.",
        fp16: "FP16 (Media precisión)",
        fp16Help: "Usa punto flotante de 16 bits para entrenamiento más rápido. Solo disponible en GPUs CUDA.",
        optimizer: "Optimizador",
        optimizerHelp: "Algoritmo para actualizar pesos. paged_adamw_8bit es eficiente en memoria para QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (recomendado para GPU)",
          adamw_torch: "AdamW (recomendado para CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        weightDecay: "Decaimiento de peso",
        weightDecayHelp: "Regularización L2 para prevenir sobreajuste. Valores más altos agregan más regularización. Recomendado: 0.01.",
        maxGradNorm: "Norma máxima de gradiente",
        maxGradNormHelp: "Norma máxima de gradiente para recorte de gradientes. Previene gradientes explosivos. Recomendado: 1.0.",
        lrScheduler: "Programador LR",
        lrSchedulerHelp: "Estrategia del programador de tasa de aprendizaje. Controla cómo cambia la tasa de aprendizaje durante el entrenamiento.",
        schedulers: {
          linear: "Lineal (recomendado)",
          cosine: "Coseno",
          constant: "Constante",
          polynomial: "Polinomial",
        },
        neftuneNoise: "NEFTune Noise Alpha",
        neftuneNoiseHelp: "Agrega ruido a embeddings durante el entrenamiento. Puede mejorar la generalización. 0 = deshabilitado, 5-15 recomendado cuando está habilitado.",
        seed: "Semilla aleatoria",
        seedHelp: "Semilla para reproducibilidad. Usa la misma semilla para obtener resultados idénticos entre ejecuciones de entrenamiento.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "Usa precisión bfloat16 en lugar de fp16. Solo disponible en GPUs Ampere+ (RTX 3000+). Mejor estabilidad numérica que fp16.",
        loggingSteps: "Pasos de registro",
        loggingStepsHelp: "Registra métricas de entrenamiento cada N pasos. Valores más bajos dan actualizaciones más frecuentes pero pueden ralentizar el entrenamiento.",
        saveStrategy: "Estrategia de guardado",
        saveStrategyHelp: "Cuándo guardar puntos de control del modelo durante el entrenamiento.",
        saveStrategies: {
          no: "Sin puntos de control",
          epoch: "Después de cada época (recomendado)",
          steps: "Cada N pasos",
        },
      },
      defaults: {
        showDefaults: "Usando valores predeterminados",
        cudaDefault: "Predeterminado GPU: {{value}}",
        cpuDefault: "Predeterminado CPU: {{value}}",
        resetToDefaults: "Restablecer a valores predeterminados",
        resetConfirm: "Todos los valores en esta sección se restablecerán a sus valores predeterminados.",
      },
      loraParams: {
        title: "Configuración LoRA",
        rank: "Rango (r)",
        rankHelp: "Dimensión de las matrices de bajo rango. Valores más altos capturan más información pero usan más memoria y arriesgan sobreajuste. Recomendado: 8-64.",
        alpha: "Alpha",
        alphaHelp: "Factor de escala para pesos LoRA. Típicamente establecido a 2x el rango. Valores más altos aumentan el impacto del ajuste fino.",
        dropout: "Dropout",
        dropoutHelp: "Probabilidad de dropout para capas LoRA. Ayuda a prevenir sobreajuste. Recomendado: 0.05-0.1.",
        targetModules: "Módulos objetivo",
        targetModulesHelp: "Capas del modelo a las que aplicar LoRA. Más módulos = más capacidad de ajuste fino pero más uso de memoria.",
        modules: {
          q_proj: "Proyección de consulta (q_proj)",
          k_proj: "Proyección de clave (k_proj)",
          v_proj: "Proyección de valor (v_proj)",
          o_proj: "Proyección de salida (o_proj)",
          gate_proj: "Proyección de puerta (gate_proj)",
          up_proj: "Proyección hacia arriba (up_proj)",
          down_proj: "Proyección hacia abajo (down_proj)",
        },
        bias: "Entrenamiento de sesgo",
        biasHelp: "Cómo manejar términos de sesgo durante el entrenamiento. 'none' congela sesgos, 'lora_only' entrena sesgos LoRA, 'all' entrena todos los sesgos.",
        biasOptions: {
          none: "Ninguno (congelar sesgos)",
          lora_only: "Solo LoRA",
          all: "Todos los sesgos",
        },
        useRslora: "Usar RSLoRA",
        useRsloraHelp: "Rank-Stabilized LoRA mejora la estabilidad del entrenamiento y el rendimiento para rangos más altos (r >= 64). Recomendado para rangos grandes.",
        useDora: "Usar DoRA (Experimental)",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptation puede mejorar la calidad del ajuste fino. Característica experimental, puede aumentar el tiempo de entrenamiento.",
        modulesToSave: "Módulos a guardar",
        modulesToSaveHelp: "Módulos adicionales para entrenar completamente (no con LoRA). Útil para entrenar capas de salida como lm_head.",
        saveModules: {
          lm_head: "Cabeza del modelo de lenguaje (lm_head)",
          embed_tokens: "Embeddings de tokens (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "Cuantización",
        loadIn4bit: "Cargar en 4 bits",
        loadIn4bitHelp: "Carga pesos del modelo en precisión de 4 bits para uso reducido de memoria. Requerido para QLoRA en memoria GPU limitada. Solo disponible en GPUs CUDA.",
        quantType: "Tipo de cuantización 4 bits",
        quantTypeHelp: "Algoritmo para cuantización de 4 bits. NF4 (Normal Float 4) se recomienda para mejor precisión.",
        quantTypes: {
          nf4: "NF4 (recomendado)",
          fp4: "FP4",
        },
        doubleQuant: "Doble cuantización",
        doubleQuantHelp: "Aplica cuantización secundaria para reducir más la memoria. Pequeña compensación de precisión por ahorros significativos de memoria.",
        computeDtype: "Tipo de datos de cómputo",
        computeDtypeHelp: "Tipo de datos para cálculos durante el entrenamiento. bfloat16 ofrece mejor estabilidad numérica en GPUs Ampere+ (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (recomendado)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (precisión completa)",
        },
        outputQuantization: "Cuantización de salida",
        outputQuantizationHelp: "Formato de cuantización para el modelo GGUF final. q8_0 ofrece buen equilibrio entre tamaño y calidad.",
        outputTypes: {
          f32: "F32 (precisión completa, más grande)",
          f16: "F16 (media precisión)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8 bits, recomendado)",
          auto: "Auto (dejar que llama.cpp decida)",
        },
        cudaOnly: "Estas configuraciones solo aplican cuando se entrena en una GPU CUDA.",
      },
      modelfileParams: {
        title: "Modelfile de Ollama",
        temperature: "Temperatura",
        temperatureHelp: "Controla la aleatoriedad en la salida. Valores más bajos hacen respuestas más enfocadas y deterministas, valores más altos más creativos. Recomendado: 0.7-0.9.",
        topP: "Top P (Muestreo de núcleo)",
        topPHelp: "Solo considera tokens con probabilidad acumulada hasta este valor. Valores más bajos se enfocan en tokens más probables. Recomendado: 0.9.",
        topK: "Top K",
        topKHelp: "Limita la selección de tokens a las K opciones más probables. Valores más bajos son más enfocados. Recomendado: 40.",
        system: "Prompt del sistema",
        systemHelp: "Instrucciones que definen cómo debe comportarse el modelo. Esto establece la personalidad y capacidades del modelo.",
        systemPlaceholder: "Eres un asistente útil.",
        stop: "Secuencias de parada",
        stopHelp: "Secuencias que indican al modelo que deje de generar. Se pueden agregar múltiples secuencias de parada.",
        stopPlaceholder: "Ingresa una secuencia de parada...",
        stopAdd: "Agregar",
        repeatPenalty: "Penalización de repetición",
        repeatPenaltyHelp: "Penalización por repetir tokens. Valores más altos reducen la repetición. Recomendado: 1.1.",
        repeatLastN: "Repetir últimos N",
        repeatLastNHelp: "Número de tokens a verificar para repetición. Valores más altos consideran más contexto. Recomendado: 64.",
        numCtx: "Tamaño de ventana de contexto",
        numCtxHelp: "Longitud máxima de contexto para inferencia. Ventanas más grandes permiten más contexto pero usan más memoria.",
      },
    },
    dataFiles: {
      title: "Datos de entrenamiento",
      empty: "Aún no hay archivos de datos",
      dropzone: "Arrastra archivos JSONL aquí o haz clic para subir",
      dropzoneActive: "Suelta los archivos aquí...",
      uploadButton: "Subir archivo",
      uploading: "Subiendo...",
      deleteConfirm: "¿Eliminar este archivo?",
      previewRowCount: "{{count}} filas en total",
      previewTruncated: "mostrando primeras {{count}}",
      previewEmpty: "Este archivo no contiene filas de datos.",
      previewError: "No se pudo cargar el contenido del archivo.",
      invalidRow: "Fila inválida",
      showRawContent: "Mostrar sin procesar ({{size}})",
      rawContentTitle: "Contenido sin procesar - Línea {{line}}",
      rawContentLength: "{{count}} caracteres",
      errorCount: "{{count}} fila(s) inválida(s) encontrada(s)",
      fileStatus: {
        pending: "Esperando ser procesado",
        in_progress: "Cargando...",
        completed: "Cargadas {{loaded}} filas ({{skipped}} omitidas)",
        failed: "Error al cargar",
        skipped: "Omitido",
      },
      validationErrors: {
        INVALID_JSON: "Sintaxis JSON inválida",
        NOT_OBJECT: "Debe ser un objeto JSON",
        MISSING_INSTRUCTION: "Falta el campo \"instruction\"",
        MISSING_OUTPUT: "Falta el campo \"output\"",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" debe ser una cadena",
        INVALID_OUTPUT_TYPE: "\"output\" debe ser una cadena",
      },
    },
    training: {
      title: "Entrenamiento",
      startButton: "Crear modelo",
      cancelButton: "Cancelar entrenamiento",
      noModel: "Por favor selecciona un modelo primero",
      noDataFiles: "Por favor agrega al menos un archivo de datos",
      readyDescription: "Todo está configurado. Haz clic en el botón de arriba para comenzar a crear tu modelo.",
      status: {
        idle: "Listo",
        starting: "Iniciando...",
        loading_data: "Cargando datos...",
        loading_model: "Cargando modelo...",
        training: "Entrenando...",
        exporting: "Exportando modelo...",
        converting: "Convirtiendo a GGUF...",
        completed: "Completado",
        failed: "Fallido",
        cancelled: "Cancelado",
      },
      progress: "Progreso",
      step: "Paso {{current}} de {{total}}",
      device: "Dispositivo",
      taskList: "Tareas",
      tasks: {
        detect_device: "Detectar dispositivo de cómputo",
        import_libraries: "Importar bibliotecas ML",
        load_model: "Cargar modelo base",
        setup_lora: "Configurar adaptador LoRA",
        tokenize: "Cargar y tokenizar datos",
        train: "Entrenar modelo",
        merge_lora: "Fusionar LoRA con modelo base",
        convert_gguf: "Convertir a formato GGUF",
        create_modelfile: "Crear Modelfile de Ollama",
        register_ollama: "Registrar modelo en Ollama",
      },
      taskWarnings: "{{count}} fila(s) inválida(s) omitida(s)",
      stillWorking: "Todavía trabajando...",
      errorTitle: "Entrenamiento fallido",
      completed: "Entrenamiento completado",
      completedDescription: "Tu modelo fue creado exitosamente. Revisa la carpeta de salida para el Modelfile.",
      cancelled: "El entrenamiento fue cancelado.",
    },
    ollama: {
      title: "Integración con Ollama",
      runButton: "Ejecutar en Ollama",
      modelName: "Nombre del modelo",
      running: "Abriendo terminal...",
    },
    presets: {
      title: "Preajustes de entrenamiento",
      description: "Configuraciones de inicio rápido optimizadas para diferentes casos de uso. Selecciona un preajuste para aplicar su configuración.",
      applyButton: "Aplicar",
      applyConfirmTitle: "¿Aplicar preajuste?",
      applyConfirmDescription: "Esto sobrescribirá tu configuración actual de entrenamiento, LoRA y cuantización con los valores del preajuste \"{{preset}}\". Esta acción no se puede deshacer.",
      recommended: "Recomendado",
      allModels: "Todos los modelos",
      balanced: {
        name: "Equilibrado",
        description: "Buen equilibrio entre velocidad y calidad para la mayoría de tareas",
        pros: {
          versatile: "Funciona bien con la mayoría de modelos y datos",
          stable: "Entrenamiento estable con valores predeterminados probados",
          good_defaults: "Buen punto de partida para experimentación",
        },
        cons: {
          not_specialized: "No optimizado para casos de uso específicos",
          moderate_time: "Tiempo de entrenamiento moderado",
        },
      },
      chat: {
        name: "Chat / Conversación",
        description: "Optimizado para IA conversacional y seguimiento de instrucciones",
        pros: {
          natural_responses: "Respuestas conversacionales más naturales",
          instruction_following: "Mejor seguimiento de instrucciones",
          diverse_outputs: "Salidas más diversas y creativas",
        },
        cons: {
          more_memory: "Mayor uso de memoria",
          longer_training: "Tiempo de entrenamiento más largo",
        },
      },
      code: {
        name: "Generación de código",
        description: "Optimizado para programación y completado de código",
        pros: {
          precise_syntax: "Aprendizaje preciso de sintaxis",
          low_dropout: "Bajo dropout para precisión",
          all_modules: "Apunta a todas las capas relevantes",
        },
        cons: {
          more_memory: "Mayor uso de memoria",
          slower_training: "Velocidad de entrenamiento más lenta",
        },
      },
      fast: {
        name: "Iteración rápida",
        description: "Entrenamiento rápido para experimentación rápida",
        pros: {
          quick_results: "Resultados rápidos para pruebas",
          low_memory: "Menores requisitos de memoria",
          rapid_testing: "Ideal para prototipado rápido",
        },
        cons: {
          lower_quality: "Menor calidad de salida",
          less_learning: "Aprendizaje menos profundo",
        },
      },
      high_quality: {
        name: "Alta calidad",
        description: "Máxima calidad a costa del tiempo de entrenamiento",
        pros: {
          best_results: "Mejores resultados posibles",
          thorough_learning: "Entrenamiento profundo a lo largo de más épocas",
          all_modules: "Cobertura completa de capas",
        },
        cons: {
          long_training: "Tiempo de entrenamiento largo",
          high_memory: "Altos requisitos de memoria",
          needs_gpu: "Requiere GPU potente",
        },
      },
      low_memory: {
        name: "Poca memoria",
        description: "Uso mínimo de VRAM para hardware limitado",
        pros: {
          minimal_vram: "Uso mínimo de VRAM",
          works_on_consumer: "Funciona en GPUs de consumo",
          gradient_accumulation: "Acumulación de gradientes efectiva",
        },
        cons: {
          slower_training: "Velocidad de entrenamiento más lenta",
          smaller_rank: "Rango LoRA más pequeño limita la capacidad",
        },
      },
      multilingual: {
        name: "Multilingüe",
        description: "Optimizado para modelos multilingües",
        pros: {
          language_diversity: "Preserva la diversidad lingüística",
          balanced_learning: "Aprendizaje equilibrado entre idiomas",
          longer_warmup: "Calentamiento extendido para adaptación lingüística",
        },
        cons: {
          needs_diverse_data: "Requiere datos de entrenamiento diversos",
          moderate_time: "Tiempo de entrenamiento moderado",
        },
      },
      reasoning: {
        name: "Razonamiento / Matemáticas",
        description: "Optimizado para razonamiento lógico y matemáticas",
        pros: {
          precise_learning: "Aprendizaje preciso y cuidadoso",
          low_dropout: "Bajo dropout para consistencia",
          consistent_outputs: "Salidas más consistentes",
        },
        cons: {
          more_epochs: "Se necesitan más épocas de entrenamiento",
          higher_rank: "Rango más alto aumenta la memoria",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "Ya existe un proyecto con este nombre.",
      ERR_PROJECT_1002: "Proyecto no encontrado.",
      ERR_PROJECT_1003: "Nombre de proyecto inválido.",
      ERR_PROJECT_1004: "El nombre del proyecto no puede estar vacío.",
      ERR_PROJECT_1005: "Error al crear el proyecto.",
      ERR_PROJECT_1006: "Error al eliminar el proyecto.",
      ERR_PROJECT_1007: "Error al actualizar el proyecto.",
      ERR_PROJECT_1008: "Error al abrir la carpeta del proyecto.",
      ERR_MODEL_2001: "Error al leer la configuración de modelos.",
      ERR_MODEL_2002: "Error al escribir la configuración de modelos.",
      ERR_DATA_3001: "Archivo de datos no encontrado.",
      ERR_DATA_3002: "Tipo de archivo inválido. Solo se permiten archivos JSONL.",
      ERR_DATA_3003: "Error al subir el archivo.",
      ERR_DATA_3004: "Error al eliminar el archivo.",
      ERR_DATA_3005: "Error al leer los archivos de datos.",
      ERR_TRAINING_4001: "Ya hay un trabajo de entrenamiento en ejecución.",
      ERR_TRAINING_4002: "No hay ningún trabajo de entrenamiento en ejecución.",
      ERR_TRAINING_4003: "Por favor agrega archivos de datos antes de iniciar el entrenamiento.",
      ERR_TRAINING_4004: "No se encontró un archivo de datos de entrenamiento.",
      ERR_TRAINING_4005: "Error al cargar el modelo.",
      ERR_TRAINING_4006: "El entrenamiento falló.",
      ERR_TRAINING_4007: "Error al exportar el modelo.",
      ERR_TRAINING_4008: "El entrenamiento fue cancelado.",
      ERR_TRAINING_4009: "No se encontró llama.cpp. Por favor instálalo primero.",
      ERR_HF_5001: "No has iniciado sesión en Hugging Face.",
      ERR_HF_5002: "Error de inicio de sesión en Hugging Face.",
      ERR_HF_5003: "Token de Hugging Face inválido.",
      ERR_OLLAMA_6001: "Ollama no está instalado.",
      ERR_OLLAMA_6002: "Ollama no está ejecutándose.",
      ERR_OLLAMA_6003: "Error al crear el modelo en Ollama.",
      ERR_OLLAMA_6004: "Modelo no encontrado en Ollama.",
      ERR_OLLAMA_6005: "Modelfile no encontrado. Por favor entrena el modelo primero.",
      ERR_OLLAMA_6006: "Error al abrir la terminal.",
      ERR_OLLAMA_6007: "No hay modelo base configurado. Por favor selecciona un modelo primero.",
      ERR_LLM_8001: "Formato de clave API inválido.",
      ERR_LLM_8002: "Clave API rechazada. Por favor verifica tu clave.",
      ERR_LLM_8003: "Proveedor desconocido.",
      ERR_LLM_8004: "No se pudo alcanzar la API del proveedor.",
      ERR_LLM_8005: "No se pudo guardar la clave API.",
      ERR_DATA_SOURCE_9001: "Tipo de archivo inválido para fuente de datos.",
      ERR_DATA_SOURCE_9002: "El archivo es demasiado grande.",
      ERR_DATA_SOURCE_9003: "La fuente de datos está vacía.",
      ERR_GENERATION_9101: "El proveedor LLM no está configurado.",
      ERR_GENERATION_9102: "El modelo no está disponible.",
      ERR_GENERATION_9103: "Límite de tokens excedido. Por favor usa fuentes de datos más pequeñas.",
      ERR_GENERATION_9104: "Error al comunicarse con la API LLM.",
      ERR_GENERATION_9105: "Respuesta inválida del LLM.",
      ERR_GENERATION_9106: "Límite de tasa excedido. Por favor espera e intenta de nuevo.",
      ERR_SAVE_9201: "Nombre de archivo inválido.",
      ERR_SAVE_9202: "Error al guardar el archivo.",
      unknown: "Ocurrió un error inesperado.",
    },
    validation: {
      mustBeInteger: "Debe ser un número entero",
      mustBeNumber: "Debe ser un número válido",
      mustBeString: "Debe ser texto",
      mustBeBoolean: "Debe ser verdadero o falso",
      mustBeArray: "Debe ser una lista",
      mustBeGreaterThan: "Debe ser mayor que {{min}}",
      mustBeAtLeast: "Debe ser al menos {{min}}",
      mustBeAtMost: "Debe ser como máximo {{max}}",
      maxLength: "Máximo {{maxLength}} caracteres",
    },
  },
};

export default es;
