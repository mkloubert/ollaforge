// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const en: TranslationSchema = {
  translation: {
    common: {
      loading: "Loading...",
      error: "An error occurred",
      retry: "Retry",
      cancel: "Cancel",
      save: "Save",
      delete: "Delete",
      create: "Create",
      back: "Back",
      name: "Name",
      actions: "Actions",
      optional: "optional",
      edit: "Edit",
      ok: "OK",
      dismiss: "Dismiss",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "Home",
      projects: "Projects",
    },
    theme: {
      light: "Light",
      dark: "Dark",
      system: "System",
      toggle: "Toggle theme",
    },
    language: {
      en: "English",
      de: "German",
      select: "Select language",
    },
    api: {
      status: "API Status",
      connected: "Connected",
      disconnected: "Disconnected",
      checking: "Checking...",
    },
    huggingface: {
      status: {
        loggedIn: "Logged in as {{username}}",
        loggedOut: "Not logged in",
        checking: "Checking...",
      },
      changeToken: "Change token",
      login: {
        title: "Hugging Face Login",
        description:
          "Enter your Hugging Face access token to access gated models.",
        tokenLabel: "Access Token",
        tokenPlaceholder: "hf_...",
        help: "You need a Hugging Face access token to download gated models.",
        getToken: "Get your token here",
        submit: "Login",
        submitting: "Logging in...",
        success: "Successfully logged in!",
      },
      errors: {
        loginFailed: "Login failed. Please check your token.",
        invalidToken: "Invalid token format. Token must start with 'hf_'.",
      },
    },
    llmProviders: {
      title: "LLM Providers",
      status: {
        allValid: "All providers configured",
        someInvalid: "Some providers not configured",
        noneConfigured: "No providers configured",
        checking: "Checking...",
        valid: "Valid",
        invalid: "Not configured",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "Configure {{provider}}",
        description: "Enter your {{provider}} API key to enable integration.",
        tokenLabel: "API Key",
        help: "You need an API key to use {{provider}} features.",
        getToken: "Get your API key here",
        submit: "Save",
        submitting: "Saving...",
        success: "API key saved successfully!",
      },
      changeToken: "Change API key",
      errors: {
        loginFailed: "Failed to save API key. Please check your key.",
      },
    },
    generateFromSources: {
      title: "Generate from Sources",
      button: "Generate from Sources",
      buttonDisabled: "No LLM provider configured",
      sources: {
        title: "Data Sources",
        uploadFile: "Upload File",
        uploadHint: "Drag & drop or click to upload",
        addText: "Add Text",
        textPlaceholder: "Paste your text here...",
        empty: "No sources added yet",
        estimatedTokens: "~{{tokens}} tokens",
        totalTokens: "Total: ~{{tokens}} tokens",
        sourcesCount: "{{count}} source(s)",
        acceptedFormats: "Accepted: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "Token count exceeds context window limit ({{limit}} tokens)",
      },
      llm: {
        selectModel: "Select model...",
        contextInfo: "Context: {{context}}K tokens",
        generate: "Generate",
        generating: "Generating...",
        progress: "Processing chunk {{current}} of {{total}}...",
      },
      results: {
        title: "Generated Data",
        empty: "Generate data using the left panel",
        instruction: "Instruction",
        output: "Output",
        addRow: "Add Row",
        deleteRow: "Delete",
        validRows: "{{valid}} of {{total}} rows valid",
        generated: "Generated {{count}} training data rows",
      },
      save: {
        title: "Save as JSONL",
        filename: "Filename",
        save: "Save",
        saving: "Saving...",
        success: "File {{filename}} saved successfully",
      },
      errors: {
        emptyCell: "Cell cannot be empty",
        invalidFilename: "Invalid filename",
        noData: "No data to save",
        invalidRows: "Please fix invalid rows first",
      },
    },
    projects: {
      title: "Projects",
      empty: "No projects yet",
      emptyDescription: "Create your first project to get started.",
      createNew: "New Project",
      createTitle: "Create New Project",
      createDescription: "Enter a name for your new project.",
      namePlaceholder: "My Project",
      nameLabel: "Project Name",
      descriptionLabel: "Description",
      descriptionPlaceholder: "A brief description of your project",
      creating: "Creating...",
      saving: "Saving...",
      openProject: "Open project",
      editTitle: "Edit Project",
      editDescription: "Update the project name and description.",
      deleteTitle: "Delete Project",
      deleteDescription:
        "Are you sure you want to delete \"{{name}}\"? This action cannot be undone.",
      deleting: "Deleting...",
    },
    project: {
      title: "Project",
      backToProjects: "Back to Projects",
      selectModel: "Base Model",
      selectModelPlaceholder: "Select a model...",
      targetName: "Target Model Name",
      targetNamePlaceholder: "Enter a custom name...",
      configuration: "Configuration",
      status: "Status",
      tabs: {
        basic: "Basic",
        advanced: "Advanced",
      },
      advancedPlaceholder: "Advanced settings coming soon...",
    },
    advancedConfig: {
      helpPanel: {
        title: "About Advanced Settings",
        description: "These settings control how your model is trained using QLoRA (Quantized Low-Rank Adaptation). QLoRA enables fine-tuning large language models on consumer hardware by using 4-bit quantization and low-rank adapters. The default values work well for most use cases - only change them if you understand their impact.",
        learnMore: "Learn more",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "QLoRA Paper",
          lora: "LoRA Explained",
          transformers: "Training Documentation",
        },
      },
      trainingParams: {
        title: "Training Parameters",
        numEpochs: "Epochs",
        numEpochsHelp: "Number of training passes. More epochs can improve quality but risk overfitting. Recommended: 1-5.",
        batchSize: "Batch Size",
        batchSizeHelp: "Samples per training step. Larger sizes train faster but need more memory. Recommended: 1-8.",
        gradientAccumulation: "Gradient Accumulation",
        gradientAccumulationHelp: "Accumulate gradients over multiple steps. Simulates larger batch size with less memory.",
        learningRate: "Learning Rate",
        learningRateHelp: "Step size for weight updates. Too high causes instability, too low slows training. Recommended: 1e-5 to 5e-4.",
        warmupRatio: "Warmup Ratio",
        warmupRatioHelp: "Fraction of training to gradually increase learning rate. Helps stabilize early training.",
        maxLength: "Max Token Length",
        maxLengthHelp: "Maximum sequence length for training. Longer sequences need more memory.",
        fp16: "FP16 (Half Precision)",
        fp16Help: "Use 16-bit floating point for faster training. Only available on CUDA GPUs.",
        optimizer: "Optimizer",
        optimizerHelp: "Algorithm for updating weights. paged_adamw_8bit is memory efficient for QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (recommended for GPU)",
          adamw_torch: "AdamW (recommended for CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        // Extended training parameters
        weightDecay: "Weight Decay",
        weightDecayHelp: "L2 regularization to prevent overfitting. Higher values add more regularization. Recommended: 0.01.",
        maxGradNorm: "Max Gradient Norm",
        maxGradNormHelp: "Maximum gradient norm for gradient clipping. Prevents exploding gradients. Recommended: 1.0.",
        lrScheduler: "LR Scheduler",
        lrSchedulerHelp: "Learning rate scheduler strategy. Controls how the learning rate changes during training.",
        schedulers: {
          linear: "Linear (recommended)",
          cosine: "Cosine",
          constant: "Constant",
          polynomial: "Polynomial",
        },
        neftuneNoise: "NEFTune Noise Alpha",
        neftuneNoiseHelp: "Add noise to embeddings during training. Can improve generalization. 0 = disabled, 5-15 recommended when enabled.",
        seed: "Random Seed",
        seedHelp: "Seed for reproducibility. Use the same seed to get identical results across training runs.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "Use bfloat16 precision instead of fp16. Only available on Ampere+ GPUs (RTX 3000+). Better numerical stability than fp16.",
        loggingSteps: "Logging Steps",
        loggingStepsHelp: "Log training metrics every N steps. Lower values give more frequent updates but may slow training.",
        saveStrategy: "Save Strategy",
        saveStrategyHelp: "When to save model checkpoints during training.",
        saveStrategies: {
          no: "No checkpoints",
          epoch: "After each epoch (recommended)",
          steps: "Every N steps",
        },
      },
      defaults: {
        showDefaults: "Using defaults",
        cudaDefault: "GPU default: {{value}}",
        cpuDefault: "CPU default: {{value}}",
        resetToDefaults: "Reset to defaults",
        resetConfirm: "All values in this section will be reset to their defaults.",
      },
      loraParams: {
        title: "LoRA Configuration",
        rank: "Rank (r)",
        rankHelp: "Dimension of the low-rank matrices. Higher values capture more information but use more memory and risk overfitting. Recommended: 8-64.",
        alpha: "Alpha",
        alphaHelp: "Scaling factor for LoRA weights. Typically set to 2x the rank. Higher values increase the impact of fine-tuning.",
        dropout: "Dropout",
        dropoutHelp: "Dropout probability for LoRA layers. Helps prevent overfitting. Recommended: 0.05-0.1.",
        targetModules: "Target Modules",
        targetModulesHelp: "Model layers to apply LoRA to. More modules = more fine-tuning capacity but more memory usage.",
        modules: {
          q_proj: "Query Projection (q_proj)",
          k_proj: "Key Projection (k_proj)",
          v_proj: "Value Projection (v_proj)",
          o_proj: "Output Projection (o_proj)",
          gate_proj: "Gate Projection (gate_proj)",
          up_proj: "Up Projection (up_proj)",
          down_proj: "Down Projection (down_proj)",
        },
        // Advanced LoRA parameters
        bias: "Bias Training",
        biasHelp: "How to handle bias terms during training. 'none' freezes biases, 'lora_only' trains LoRA biases, 'all' trains all biases.",
        biasOptions: {
          none: "None (freeze biases)",
          lora_only: "LoRA only",
          all: "All biases",
        },
        useRslora: "Use RSLoRA",
        useRsloraHelp: "Rank-Stabilized LoRA improves training stability and performance for higher ranks (r >= 64). Recommended for large ranks.",
        useDora: "Use DoRA (Experimental)",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptation can improve fine-tuning quality. Experimental feature, may increase training time.",
        modulesToSave: "Modules to Save",
        modulesToSaveHelp: "Additional modules to train fully (not with LoRA). Useful for training output layers like lm_head.",
        saveModules: {
          lm_head: "Language Model Head (lm_head)",
          embed_tokens: "Token Embeddings (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "Quantization",
        loadIn4bit: "Load in 4-bit",
        loadIn4bitHelp: "Load model weights in 4-bit precision for reduced memory usage. Required for QLoRA on limited GPU memory. Only available on CUDA GPUs.",
        quantType: "4-bit Quantization Type",
        quantTypeHelp: "Algorithm for 4-bit quantization. NF4 (Normal Float 4) is recommended for better accuracy.",
        quantTypes: {
          nf4: "NF4 (recommended)",
          fp4: "FP4",
        },
        doubleQuant: "Double Quantization",
        doubleQuantHelp: "Apply secondary quantization to reduce memory further. Small accuracy trade-off for significant memory savings.",
        computeDtype: "Compute Dtype",
        computeDtypeHelp: "Data type for computations during training. bfloat16 offers better numerical stability on Ampere+ GPUs (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (recommended)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (full precision)",
        },
        outputQuantization: "Output Quantization",
        outputQuantizationHelp: "Quantization format for the final GGUF model. q8_0 offers good balance between size and quality.",
        outputTypes: {
          f32: "F32 (full precision, largest)",
          f16: "F16 (half precision)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8-bit, recommended)",
          auto: "Auto (let llama.cpp decide)",
        },
        cudaOnly: "These settings only apply when training on a CUDA GPU.",
      },
      modelfileParams: {
        title: "Ollama Modelfile",
        temperature: "Temperature",
        temperatureHelp: "Controls randomness in output. Lower values make responses more focused and deterministic, higher values more creative. Recommended: 0.7-0.9.",
        topP: "Top P (Nucleus Sampling)",
        topPHelp: "Only consider tokens with cumulative probability up to this value. Lower values focus on more likely tokens. Recommended: 0.9.",
        topK: "Top K",
        topKHelp: "Limit token selection to the K most likely options. Lower values are more focused. Recommended: 40.",
        system: "System Prompt",
        systemHelp: "Instructions that define how the model should behave. This sets the model's personality and capabilities.",
        systemPlaceholder: "You are a helpful assistant.",
        stop: "Stop Sequences",
        stopHelp: "Sequences that signal the model to stop generating. Multiple stop sequences can be added.",
        stopPlaceholder: "Enter a stop sequence...",
        stopAdd: "Add",
        repeatPenalty: "Repeat Penalty",
        repeatPenaltyHelp: "Penalty for repeating tokens. Higher values reduce repetition. Recommended: 1.1.",
        repeatLastN: "Repeat Last N",
        repeatLastNHelp: "Number of tokens to check for repetition. Higher values consider more context. Recommended: 64.",
        numCtx: "Context Window Size",
        numCtxHelp: "Maximum context length for inference. Larger windows allow more context but use more memory.",
      },
    },
    dataFiles: {
      title: "Training Data",
      empty: "No data files yet",
      dropzone: "Drop JSONL files here or click to upload",
      dropzoneActive: "Drop files here...",
      uploadButton: "Upload File",
      uploading: "Uploading...",
      deleteConfirm: "Delete this file?",
      previewRowCount: "{{count}} rows total",
      previewTruncated: "showing first {{count}}",
      previewEmpty: "This file contains no data rows.",
      previewError: "Could not load file content.",
      invalidRow: "Invalid row",
      showRawContent: "Show raw ({{size}})",
      rawContentTitle: "Raw content - Line {{line}}",
      rawContentLength: "{{count}} characters",
      errorCount: "{{count}} invalid row(s) found",
      fileStatus: {
        pending: "Waiting to be processed",
        in_progress: "Loading...",
        completed: "Loaded {{loaded}} rows ({{skipped}} skipped)",
        failed: "Failed to load",
        skipped: "Skipped",
      },
      validationErrors: {
        INVALID_JSON: "Invalid JSON syntax",
        NOT_OBJECT: "Must be a JSON object",
        MISSING_INSTRUCTION: "Missing \"instruction\" field",
        MISSING_OUTPUT: "Missing \"output\" field",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" must be a string",
        INVALID_OUTPUT_TYPE: "\"output\" must be a string",
      },
    },
    training: {
      title: "Training",
      startButton: "Create Model",
      cancelButton: "Cancel Training",
      noModel: "Please select a model first",
      noDataFiles: "Please add at least one data file",
      readyDescription: "Everything is set up. Click the button above to start creating your model.",
      status: {
        idle: "Ready",
        starting: "Starting...",
        loading_data: "Loading data...",
        loading_model: "Loading model...",
        training: "Training...",
        exporting: "Exporting model...",
        converting: "Converting to GGUF...",
        completed: "Completed",
        failed: "Failed",
        cancelled: "Cancelled",
      },
      progress: "Progress",
      step: "Step {{current}} of {{total}}",
      device: "Device",
      taskList: "Tasks",
      tasks: {
        detect_device: "Detect compute device",
        import_libraries: "Import ML libraries",
        load_model: "Load base model",
        setup_lora: "Set up LoRA adapter",
        tokenize: "Load and tokenize data",
        train: "Train model",
        merge_lora: "Merge LoRA with base model",
        convert_gguf: "Convert to GGUF format",
        create_modelfile: "Create Ollama Modelfile",
        register_ollama: "Register model in Ollama",
      },
      taskWarnings: "{{count}} invalid row(s) skipped",
      stillWorking: "Still working...",
      errorTitle: "Training Failed",
      completed: "Training Completed",
      completedDescription: "Your model was created successfully. Check the output folder for the Modelfile.",
      cancelled: "Training was cancelled.",
    },
    ollama: {
      title: "Ollama Integration",
      runButton: "Run in Ollama",
      modelName: "Model name",
      running: "Opening terminal...",
    },
    presets: {
      title: "Training Presets",
      description: "Quick-start configurations optimized for different use cases. Select a preset to apply its settings.",
      applyButton: "Apply",
      applyConfirmTitle: "Apply Preset?",
      applyConfirmDescription: "This will overwrite your current training, LoRA, and quantization settings with the \"{{preset}}\" preset values. This action cannot be undone.",
      recommended: "Recommended",
      allModels: "All models",
      balanced: {
        name: "Balanced",
        description: "Good balance of speed and quality for most tasks",
        pros: {
          versatile: "Works well with most models and data",
          stable: "Stable training with proven defaults",
          good_defaults: "Good starting point for experimentation",
        },
        cons: {
          not_specialized: "Not optimized for specific use cases",
          moderate_time: "Moderate training time",
        },
      },
      chat: {
        name: "Chat / Conversation",
        description: "Optimized for conversational AI and instruction following",
        pros: {
          natural_responses: "More natural conversational responses",
          instruction_following: "Better instruction following",
          diverse_outputs: "More diverse and creative outputs",
        },
        cons: {
          more_memory: "Higher memory usage",
          longer_training: "Longer training time",
        },
      },
      code: {
        name: "Code Generation",
        description: "Optimized for programming and code completion",
        pros: {
          precise_syntax: "Precise syntax learning",
          low_dropout: "Low dropout for accuracy",
          all_modules: "Targets all relevant layers",
        },
        cons: {
          more_memory: "Higher memory usage",
          slower_training: "Slower training speed",
        },
      },
      fast: {
        name: "Fast Iteration",
        description: "Quick training for rapid experimentation",
        pros: {
          quick_results: "Fast results for testing",
          low_memory: "Lower memory requirements",
          rapid_testing: "Ideal for rapid prototyping",
        },
        cons: {
          lower_quality: "Lower quality output",
          less_learning: "Less thorough learning",
        },
      },
      high_quality: {
        name: "High Quality",
        description: "Maximum quality at the cost of training time",
        pros: {
          best_results: "Best possible results",
          thorough_learning: "Thorough training over more epochs",
          all_modules: "Comprehensive layer coverage",
        },
        cons: {
          long_training: "Long training time",
          high_memory: "High memory requirements",
          needs_gpu: "Requires powerful GPU",
        },
      },
      low_memory: {
        name: "Low Memory",
        description: "Minimized VRAM usage for limited hardware",
        pros: {
          minimal_vram: "Minimal VRAM usage",
          works_on_consumer: "Works on consumer GPUs",
          gradient_accumulation: "Effective gradient accumulation",
        },
        cons: {
          slower_training: "Slower training speed",
          smaller_rank: "Smaller LoRA rank limits capacity",
        },
      },
      multilingual: {
        name: "Multilingual",
        description: "Optimized for multilingual models",
        pros: {
          language_diversity: "Preserves language diversity",
          balanced_learning: "Balanced cross-lingual learning",
          longer_warmup: "Extended warmup for language adaptation",
        },
        cons: {
          needs_diverse_data: "Requires diverse training data",
          moderate_time: "Moderate training time",
        },
      },
      reasoning: {
        name: "Reasoning / Math",
        description: "Optimized for logical reasoning and mathematics",
        pros: {
          precise_learning: "Precise and careful learning",
          low_dropout: "Low dropout for consistency",
          consistent_outputs: "More consistent outputs",
        },
        cons: {
          more_epochs: "More training epochs needed",
          higher_rank: "Higher rank increases memory",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "A project with this name already exists.",
      ERR_PROJECT_1002: "Project not found.",
      ERR_PROJECT_1003: "Invalid project name.",
      ERR_PROJECT_1004: "Project name cannot be empty.",
      ERR_PROJECT_1005: "Failed to create project.",
      ERR_PROJECT_1006: "Failed to delete project.",
      ERR_PROJECT_1007: "Failed to update project.",
      ERR_MODEL_2001: "Failed to read models configuration.",
      ERR_MODEL_2002: "Failed to write models configuration.",
      ERR_DATA_3001: "Data file not found.",
      ERR_DATA_3002: "Invalid file type. Only JSONL files are allowed.",
      ERR_DATA_3003: "Failed to upload file.",
      ERR_DATA_3004: "Failed to delete file.",
      ERR_DATA_3005: "Failed to read data files.",
      ERR_TRAINING_4001: "A training job is already running.",
      ERR_TRAINING_4002: "No training job is running.",
      ERR_TRAINING_4003: "Please add data files before starting training.",
      ERR_TRAINING_4004: "A training data file was not found.",
      ERR_TRAINING_4005: "Failed to load the model.",
      ERR_TRAINING_4006: "Training failed.",
      ERR_TRAINING_4007: "Failed to export the model.",
      ERR_TRAINING_4008: "Training was cancelled.",
      ERR_TRAINING_4009: "llama.cpp was not found. Please install it first.",
      ERR_HF_5001: "Not logged in to Hugging Face.",
      ERR_HF_5002: "Hugging Face login failed.",
      ERR_HF_5003: "Invalid Hugging Face token.",
      ERR_OLLAMA_6001: "Ollama is not installed.",
      ERR_OLLAMA_6002: "Ollama is not running.",
      ERR_OLLAMA_6003: "Failed to create model in Ollama.",
      ERR_OLLAMA_6004: "Model not found in Ollama.",
      ERR_OLLAMA_6005: "Modelfile not found. Please train the model first.",
      ERR_OLLAMA_6006: "Failed to open terminal.",
      ERR_OLLAMA_6007: "No base model configured. Please select a model first.",
      ERR_LLM_8001: "Invalid API key format.",
      ERR_LLM_8002: "API key rejected. Please check your key.",
      ERR_LLM_8003: "Unknown provider.",
      ERR_LLM_8004: "Could not reach provider API.",
      ERR_LLM_8005: "Could not save API key.",
      ERR_DATA_SOURCE_9001: "Invalid file type for data source.",
      ERR_DATA_SOURCE_9002: "File is too large.",
      ERR_DATA_SOURCE_9003: "Data source is empty.",
      ERR_GENERATION_9101: "LLM provider is not configured.",
      ERR_GENERATION_9102: "Model is not available.",
      ERR_GENERATION_9103: "Token limit exceeded. Please use smaller data sources.",
      ERR_GENERATION_9104: "Error communicating with LLM API.",
      ERR_GENERATION_9105: "Invalid response from LLM.",
      ERR_GENERATION_9106: "Rate limit exceeded. Please wait and try again.",
      ERR_SAVE_9201: "Invalid filename.",
      ERR_SAVE_9202: "Failed to save file.",
      unknown: "An unexpected error occurred.",
    },
    validation: {
      mustBeInteger: "Must be a whole number",
      mustBeNumber: "Must be a valid number",
      mustBeString: "Must be text",
      mustBeBoolean: "Must be true or false",
      mustBeArray: "Must be a list",
      mustBeGreaterThan: "Must be greater than {{min}}",
      mustBeAtLeast: "Must be at least {{min}}",
      mustBeAtMost: "Must be at most {{max}}",
      maxLength: "Maximum {{maxLength}} characters",
    },
  },
};

export default en;
