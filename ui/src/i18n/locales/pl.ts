// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const pl: TranslationSchema = {
  translation: {
    common: {
      loading: "Ładowanie...",
      error: "Wystąpił błąd",
      retry: "Ponów",
      cancel: "Anuluj",
      save: "Zapisz",
      delete: "Usuń",
      create: "Utwórz",
      back: "Wstecz",
      name: "Nazwa",
      actions: "Akcje",
      optional: "opcjonalne",
      edit: "Edytuj",
      ok: "OK",
      dismiss: "Zamknij",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "Strona główna",
      projects: "Projekty",
    },
    theme: {
      light: "Jasny",
      dark: "Ciemny",
      system: "Systemowy",
      toggle: "Zmień motyw",
    },
    language: {
      en: "Angielski",
      de: "Niemiecki",
      es: "Hiszpański",
      fr: "Francuski",
      pt: "Portugalski",
      uk: "Ukraiński",
      zh: "Chiński",
      ja: "Japoński",
      ko: "Koreański",
      ar: "Arabski",
      hi: "Hindi",
      it: "Włoski",
      nl: "Holenderski",
      pl: "Polski",
      select: "Wybierz język",
    },
    api: {
      status: "Status API",
      connected: "Połączony",
      disconnected: "Rozłączony",
      checking: "Sprawdzanie...",
    },
    huggingface: {
      status: {
        loggedIn: "Zalogowany jako {{username}}",
        loggedOut: "Niezalogowany",
        checking: "Sprawdzanie...",
      },
      changeToken: "Zmień token",
      login: {
        title: "Logowanie Hugging Face",
        description:
          "Wprowadź swój token dostępu Hugging Face, aby uzyskać dostęp do chronionych modeli.",
        tokenLabel: "Token dostępu",
        tokenPlaceholder: "hf_...",
        help: "Potrzebujesz tokena dostępu Hugging Face, aby pobierać chronione modele.",
        getToken: "Pobierz swój token tutaj",
        submit: "Zaloguj",
        submitting: "Logowanie...",
        success: "Zalogowano pomyślnie!",
      },
      errors: {
        loginFailed: "Logowanie nie powiodło się. Sprawdź swój token.",
        invalidToken: "Nieprawidłowy format tokena. Token musi zaczynać się od 'hf_'.",
      },
    },
    llmProviders: {
      title: "Dostawcy LLM",
      status: {
        allValid: "Wszyscy dostawcy skonfigurowani",
        someInvalid: "Niektórzy dostawcy nieskonfigurowani",
        noneConfigured: "Brak skonfigurowanych dostawców",
        checking: "Sprawdzanie...",
        valid: "Prawidłowy",
        invalid: "Nieskonfigurowany",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "Konfiguruj {{provider}}",
        description: "Wprowadź klucz API {{provider}}, aby włączyć integrację.",
        tokenLabel: "Klucz API",
        help: "Potrzebujesz klucza API, aby korzystać z funkcji {{provider}}.",
        getToken: "Pobierz swój klucz API tutaj",
        submit: "Zapisz",
        submitting: "Zapisywanie...",
        success: "Klucz API zapisany pomyślnie!",
      },
      changeToken: "Zmień klucz API",
      errors: {
        loginFailed: "Nie udało się zapisać klucza API. Sprawdź swój klucz.",
      },
    },
    generateFromSources: {
      title: "Generuj ze źródeł",
      button: "Generuj ze źródeł",
      buttonDisabled: "Brak skonfigurowanego dostawcy LLM",
      sources: {
        title: "Źródła danych",
        uploadFile: "Prześlij plik",
        uploadHint: "Przeciągnij i upuść lub kliknij, aby przesłać",
        addText: "Dodaj tekst",
        textPlaceholder: "Wklej tutaj swój tekst...",
        empty: "Nie dodano jeszcze źródeł",
        estimatedTokens: "~{{tokens}} tokenów",
        totalTokens: "Łącznie: ~{{tokens}} tokenów",
        sourcesCount: "{{count}} źródło(a)",
        acceptedFormats: "Akceptowane: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "Liczba tokenów przekracza limit okna kontekstu ({{limit}} tokenów)",
      },
      llm: {
        selectModel: "Wybierz model...",
        contextInfo: "Kontekst: {{context}}K tokenów",
        generate: "Generuj",
        generating: "Generowanie...",
        progress: "Przetwarzanie fragmentu {{current}} z {{total}}...",
        targetLanguage: "Język wyjściowy",
        languages: {
          auto: "Taki sam jak wejście",
          en: "Angielski",
          de: "Niemiecki",
          es: "Hiszpański",
          fr: "Francuski",
          pt: "Portugalski",
          uk: "Ukraiński",
          zh: "Chiński (uproszczony)",
          ja: "Japoński",
          ko: "Koreański",
          ar: "Arabski",
          hi: "Hindi",
          it: "Włoski",
          nl: "Holenderski",
          pl: "Polski",
        },
      },
      results: {
        title: "Wygenerowane dane",
        empty: "Wygeneruj dane za pomocą lewego panelu",
        instruction: "Instrukcja",
        output: "Wynik",
        addRow: "Dodaj wiersz",
        deleteRow: "Usuń",
        validRows: "{{valid}} z {{total}} wierszy poprawnych",
        generated: "Wygenerowano {{count}} wierszy danych treningowych",
      },
      save: {
        title: "Zapisz jako JSONL",
        filename: "Nazwa pliku",
        save: "Zapisz",
        saving: "Zapisywanie...",
        success: "Plik {{filename}} zapisany pomyślnie",
      },
      errors: {
        emptyCell: "Komórka nie może być pusta",
        invalidFilename: "Nieprawidłowa nazwa pliku",
        noData: "Brak danych do zapisania",
        invalidRows: "Najpierw popraw nieprawidłowe wiersze",
      },
    },
    projects: {
      title: "Projekty",
      empty: "Brak projektów",
      emptyDescription: "Utwórz swój pierwszy projekt, aby rozpocząć.",
      createNew: "Nowy projekt",
      createTitle: "Utwórz nowy projekt",
      createDescription: "Wprowadź nazwę dla swojego nowego projektu.",
      namePlaceholder: "Mój projekt",
      nameLabel: "Nazwa projektu",
      descriptionLabel: "Opis",
      descriptionPlaceholder: "Krótki opis twojego projektu",
      creating: "Tworzenie...",
      saving: "Zapisywanie...",
      openProject: "Otwórz projekt",
      editTitle: "Edytuj projekt",
      editDescription: "Zaktualizuj nazwę i opis projektu.",
      deleteTitle: "Usuń projekt",
      deleteDescription:
        "Czy na pewno chcesz usunąć \"{{name}}\"? Tej akcji nie można cofnąć.",
      deleting: "Usuwanie...",
      openFolder: "Otwórz folder",
    },
    project: {
      title: "Projekt",
      backToProjects: "Powrót do projektów",
      selectModel: "Model bazowy",
      selectModelPlaceholder: "Wybierz model...",
      targetName: "Nazwa modelu docelowego",
      targetNamePlaceholder: "Wprowadź niestandardową nazwę...",
      configuration: "Konfiguracja",
      status: "Status",
      tabs: {
        basic: "Podstawowe",
        advanced: "Zaawansowane",
      },
      advancedPlaceholder: "Ustawienia zaawansowane wkrótce...",
    },
    advancedConfig: {
      helpPanel: {
        title: "O ustawieniach zaawansowanych",
        description: "Te ustawienia kontrolują sposób trenowania modelu przy użyciu QLoRA (Quantized Low-Rank Adaptation). QLoRA umożliwia dostrajanie dużych modeli językowych na sprzęcie konsumenckim przy użyciu kwantyzacji 4-bitowej i adapterów niskiego rzędu. Wartości domyślne działają dobrze w większości przypadków - zmieniaj je tylko jeśli rozumiesz ich wpływ.",
        learnMore: "Dowiedz się więcej",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "Artykuł QLoRA",
          lora: "LoRA wyjaśnione",
          transformers: "Dokumentacja treningu",
        },
      },
      trainingParams: {
        title: "Parametry treningu",
        numEpochs: "Epoki",
        numEpochsHelp: "Liczba przejść treningowych. Więcej epok może poprawić jakość, ale ryzykuje przeuczenie. Zalecane: 1-5.",
        batchSize: "Rozmiar partii",
        batchSizeHelp: "Próbki na krok treningowy. Większe rozmiary trenują szybciej, ale wymagają więcej pamięci. Zalecane: 1-8.",
        gradientAccumulation: "Akumulacja gradientu",
        gradientAccumulationHelp: "Akumuluj gradienty przez wiele kroków. Symuluje większy rozmiar partii przy mniejszej pamięci.",
        learningRate: "Współczynnik uczenia",
        learningRateHelp: "Rozmiar kroku dla aktualizacji wag. Zbyt wysoki powoduje niestabilność, zbyt niski spowalnia trening. Zalecane: 1e-5 do 5e-4.",
        warmupRatio: "Współczynnik rozgrzewki",
        warmupRatioHelp: "Część treningu do stopniowego zwiększania współczynnika uczenia. Pomaga ustabilizować wczesny trening.",
        maxLength: "Maksymalna długość tokenów",
        maxLengthHelp: "Maksymalna długość sekwencji dla treningu. Dłuższe sekwencje wymagają więcej pamięci.",
        fp16: "FP16 (połowa precyzji)",
        fp16Help: "Użyj zmiennoprzecinkowej 16-bitowej dla szybszego treningu. Dostępne tylko na GPU CUDA.",
        optimizer: "Optymalizator",
        optimizerHelp: "Algorytm do aktualizacji wag. paged_adamw_8bit jest wydajny pamięciowo dla QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (zalecane dla GPU)",
          adamw_torch: "AdamW (zalecane dla CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        weightDecay: "Zanik wag",
        weightDecayHelp: "Regularyzacja L2 zapobiegająca przeuczeniu. Wyższe wartości dodają więcej regularyzacji. Zalecane: 0.01.",
        maxGradNorm: "Maksymalna norma gradientu",
        maxGradNormHelp: "Maksymalna norma gradientu dla przycinania gradientu. Zapobiega eksplodującym gradientom. Zalecane: 1.0.",
        lrScheduler: "Harmonogram LR",
        lrSchedulerHelp: "Strategia harmonogramu współczynnika uczenia. Kontroluje jak współczynnik uczenia zmienia się podczas treningu.",
        schedulers: {
          linear: "Liniowy (zalecane)",
          cosine: "Cosinusowy",
          constant: "Stały",
          polynomial: "Wielomianowy",
        },
        neftuneNoise: "NEFTune Noise Alpha",
        neftuneNoiseHelp: "Dodaj szum do osadzeń podczas treningu. Może poprawić generalizację. 0 = wyłączone, 5-15 zalecane gdy włączone.",
        seed: "Ziarno losowości",
        seedHelp: "Ziarno dla powtarzalności. Użyj tego samego ziarna, aby uzyskać identyczne wyniki między przebiegami treningowymi.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "Użyj precyzji bfloat16 zamiast fp16. Dostępne tylko na GPU Ampere+ (RTX 3000+). Lepsza stabilność numeryczna niż fp16.",
        loggingSteps: "Kroki logowania",
        loggingStepsHelp: "Loguj metryki treningu co N kroków. Niższe wartości dają częstsze aktualizacje, ale mogą spowolnić trening.",
        saveStrategy: "Strategia zapisu",
        saveStrategyHelp: "Kiedy zapisywać punkty kontrolne modelu podczas treningu.",
        saveStrategies: {
          no: "Bez punktów kontrolnych",
          epoch: "Po każdej epoce (zalecane)",
          steps: "Co N kroków",
        },
      },
      defaults: {
        showDefaults: "Używanie domyślnych",
        cudaDefault: "Domyślne GPU: {{value}}",
        cpuDefault: "Domyślne CPU: {{value}}",
        resetToDefaults: "Przywróć domyślne",
        resetConfirm: "Wszystkie wartości w tej sekcji zostaną przywrócone do domyślnych.",
      },
      loraParams: {
        title: "Konfiguracja LoRA",
        rank: "Rząd (r)",
        rankHelp: "Wymiar macierzy niskiego rzędu. Wyższe wartości przechwytują więcej informacji, ale zużywają więcej pamięci i ryzykują przeuczenie. Zalecane: 8-64.",
        alpha: "Alpha",
        alphaHelp: "Współczynnik skalowania dla wag LoRA. Zwykle ustawiany na 2x rząd. Wyższe wartości zwiększają wpływ dostrajania.",
        dropout: "Dropout",
        dropoutHelp: "Prawdopodobieństwo dropout dla warstw LoRA. Pomaga zapobiegać przeuczeniu. Zalecane: 0.05-0.1.",
        targetModules: "Moduły docelowe",
        targetModulesHelp: "Warstwy modelu, do których zastosować LoRA. Więcej modułów = większa pojemność dostrajania, ale większe zużycie pamięci.",
        modules: {
          q_proj: "Query Projection (q_proj)",
          k_proj: "Key Projection (k_proj)",
          v_proj: "Value Projection (v_proj)",
          o_proj: "Output Projection (o_proj)",
          gate_proj: "Gate Projection (gate_proj)",
          up_proj: "Up Projection (up_proj)",
          down_proj: "Down Projection (down_proj)",
        },
        bias: "Trening biasu",
        biasHelp: "Jak obsługiwać terminy biasu podczas treningu. 'none' zamraża biasy, 'lora_only' trenuje biasy LoRA, 'all' trenuje wszystkie biasy.",
        biasOptions: {
          none: "Brak (zamroź biasy)",
          lora_only: "Tylko LoRA",
          all: "Wszystkie biasy",
        },
        useRslora: "Użyj RSLoRA",
        useRsloraHelp: "Rank-Stabilized LoRA poprawia stabilność treningu i wydajność dla wyższych rzędów (r >= 64). Zalecane dla dużych rzędów.",
        useDora: "Użyj DoRA (eksperymentalne)",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptation może poprawić jakość dostrajania. Funkcja eksperymentalna, może wydłużyć czas treningu.",
        modulesToSave: "Moduły do zapisania",
        modulesToSaveHelp: "Dodatkowe moduły do pełnego treningu (nie z LoRA). Przydatne do trenowania warstw wyjściowych jak lm_head.",
        saveModules: {
          lm_head: "Language Model Head (lm_head)",
          embed_tokens: "Token Embeddings (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "Kwantyzacja",
        loadIn4bit: "Załaduj w 4-bit",
        loadIn4bitHelp: "Załaduj wagi modelu w precyzji 4-bitowej dla zmniejszonego zużycia pamięci. Wymagane dla QLoRA na ograniczonej pamięci GPU. Dostępne tylko na GPU CUDA.",
        quantType: "Typ kwantyzacji 4-bit",
        quantTypeHelp: "Algorytm kwantyzacji 4-bitowej. NF4 (Normal Float 4) jest zalecany dla lepszej dokładności.",
        quantTypes: {
          nf4: "NF4 (zalecane)",
          fp4: "FP4",
        },
        doubleQuant: "Podwójna kwantyzacja",
        doubleQuantHelp: "Zastosuj wtórną kwantyzację, aby jeszcze bardziej zmniejszyć pamięć. Mały kompromis dokładności dla znacznych oszczędności pamięci.",
        computeDtype: "Typ danych obliczeń",
        computeDtypeHelp: "Typ danych dla obliczeń podczas treningu. bfloat16 oferuje lepszą stabilność numeryczną na GPU Ampere+ (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (zalecane)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (pełna precyzja)",
        },
        outputQuantization: "Kwantyzacja wyjściowa",
        outputQuantizationHelp: "Format kwantyzacji dla końcowego modelu GGUF. q8_0 oferuje dobrą równowagę między rozmiarem a jakością.",
        outputTypes: {
          f32: "F32 (pełna precyzja, największy)",
          f16: "F16 (połowa precyzji)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8-bit, zalecane)",
          auto: "Auto (pozwól llama.cpp zdecydować)",
        },
        cudaOnly: "Te ustawienia dotyczą tylko treningu na GPU CUDA.",
      },
      modelfileParams: {
        title: "Plik modelu Ollama",
        temperature: "Temperatura",
        temperatureHelp: "Kontroluje losowość w wyjściu. Niższe wartości sprawiają, że odpowiedzi są bardziej skoncentrowane i deterministyczne, wyższe wartości bardziej kreatywne. Zalecane: 0.7-0.9.",
        topP: "Top P (próbkowanie jądra)",
        topPHelp: "Rozważ tylko tokeny z łącznym prawdopodobieństwem do tej wartości. Niższe wartości koncentrują się na bardziej prawdopodobnych tokenach. Zalecane: 0.9.",
        topK: "Top K",
        topKHelp: "Ogranicz wybór tokenów do K najbardziej prawdopodobnych opcji. Niższe wartości są bardziej skoncentrowane. Zalecane: 40.",
        system: "Prompt systemowy",
        systemHelp: "Instrukcje definiujące jak model powinien się zachowywać. Ustawia osobowość i możliwości modelu.",
        systemPlaceholder: "Jesteś pomocnym asystentem.",
        stop: "Sekwencje stopu",
        stopHelp: "Sekwencje sygnalizujące modelowi, aby przestał generować. Można dodać wiele sekwencji stopu.",
        stopPlaceholder: "Wprowadź sekwencję stopu...",
        stopAdd: "Dodaj",
        repeatPenalty: "Kara za powtórzenie",
        repeatPenaltyHelp: "Kara za powtarzanie tokenów. Wyższe wartości zmniejszają powtórzenia. Zalecane: 1.1.",
        repeatLastN: "Powtórz ostatnie N",
        repeatLastNHelp: "Liczba tokenów do sprawdzenia pod kątem powtórzeń. Wyższe wartości uwzględniają więcej kontekstu. Zalecane: 64.",
        numCtx: "Rozmiar okna kontekstu",
        numCtxHelp: "Maksymalna długość kontekstu dla wnioskowania. Większe okna pozwalają na więcej kontekstu, ale zużywają więcej pamięci.",
      },
    },
    dataFiles: {
      title: "Dane treningowe",
      empty: "Brak plików danych",
      dropzone: "Upuść pliki JSONL tutaj lub kliknij, aby przesłać",
      dropzoneActive: "Upuść pliki tutaj...",
      uploadButton: "Prześlij plik",
      uploading: "Przesyłanie...",
      deleteConfirm: "Usunąć ten plik?",
      previewRowCount: "{{count}} wierszy łącznie",
      previewTruncated: "pokazuję pierwsze {{count}}",
      previewEmpty: "Ten plik nie zawiera wierszy danych.",
      previewError: "Nie można załadować zawartości pliku.",
      invalidRow: "Nieprawidłowy wiersz",
      showRawContent: "Pokaż surowe ({{size}})",
      rawContentTitle: "Surowa zawartość - Linia {{line}}",
      rawContentLength: "{{count}} znaków",
      errorCount: "Znaleziono {{count}} nieprawidłowych wierszy",
      fileStatus: {
        pending: "Oczekuje na przetworzenie",
        in_progress: "Ładowanie...",
        completed: "Załadowano {{loaded}} wierszy ({{skipped}} pominięto)",
        failed: "Ładowanie nie powiodło się",
        skipped: "Pominięto",
      },
      validationErrors: {
        INVALID_JSON: "Nieprawidłowa składnia JSON",
        NOT_OBJECT: "Musi być obiektem JSON",
        MISSING_INSTRUCTION: "Brak pola \"instruction\"",
        MISSING_OUTPUT: "Brak pola \"output\"",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" musi być ciągiem znaków",
        INVALID_OUTPUT_TYPE: "\"output\" musi być ciągiem znaków",
      },
    },
    training: {
      title: "Trening",
      startButton: "Utwórz model",
      cancelButton: "Anuluj trening",
      noModel: "Najpierw wybierz model",
      noDataFiles: "Najpierw dodaj co najmniej jeden plik danych",
      readyDescription: "Wszystko jest ustawione. Kliknij przycisk powyżej, aby rozpocząć tworzenie modelu.",
      status: {
        idle: "Gotowy",
        starting: "Uruchamianie...",
        loading_data: "Ładowanie danych...",
        loading_model: "Ładowanie modelu...",
        training: "Trening...",
        exporting: "Eksportowanie modelu...",
        converting: "Konwertowanie do GGUF...",
        completed: "Zakończono",
        failed: "Niepowodzenie",
        cancelled: "Anulowano",
      },
      progress: "Postęp",
      step: "Krok {{current}} z {{total}}",
      device: "Urządzenie",
      taskList: "Zadania",
      tasks: {
        detect_device: "Wykryj urządzenie obliczeniowe",
        import_libraries: "Importuj biblioteki ML",
        load_model: "Załaduj model bazowy",
        setup_lora: "Skonfiguruj adapter LoRA",
        tokenize: "Załaduj i tokenizuj dane",
        train: "Trenuj model",
        merge_lora: "Połącz LoRA z modelem bazowym",
        convert_gguf: "Konwertuj do formatu GGUF",
        create_modelfile: "Utwórz plik modelu Ollama",
        register_ollama: "Zarejestruj model w Ollama",
      },
      taskWarnings: "{{count}} nieprawidłowych wierszy pominięto",
      stillWorking: "Wciąż pracuję...",
      errorTitle: "Trening nie powiódł się",
      completed: "Trening zakończony",
      completedDescription: "Twój model został pomyślnie utworzony. Sprawdź folder wyjściowy dla pliku modelu.",
      cancelled: "Trening został anulowany.",
    },
    ollama: {
      title: "Integracja Ollama",
      runButton: "Uruchom w Ollama",
      modelName: "Nazwa modelu",
      running: "Otwieranie terminala...",
    },
    presets: {
      title: "Presety treningu",
      description: "Konfiguracje szybkiego startu zoptymalizowane dla różnych przypadków użycia. Wybierz preset, aby zastosować jego ustawienia.",
      applyButton: "Zastosuj",
      applyConfirmTitle: "Zastosować preset?",
      applyConfirmDescription: "To nadpisze twoje obecne ustawienia treningu, LoRA i kwantyzacji wartościami presetu \"{{preset}}\". Tej akcji nie można cofnąć.",
      recommended: "Zalecane",
      allModels: "Wszystkie modele",
      balanced: {
        name: "Zbalansowany",
        description: "Dobra równowaga między szybkością a jakością dla większości zadań",
        pros: {
          versatile: "Działa dobrze z większością modeli i danych",
          stable: "Stabilny trening ze sprawdzonymi wartościami domyślnymi",
          good_defaults: "Dobry punkt wyjścia do eksperymentów",
        },
        cons: {
          not_specialized: "Niezoptymalizowany dla konkretnych przypadków użycia",
          moderate_time: "Umiarkowany czas treningu",
        },
      },
      chat: {
        name: "Czat / Konwersacja",
        description: "Zoptymalizowany dla konwersacyjnej AI i wykonywania instrukcji",
        pros: {
          natural_responses: "Bardziej naturalne odpowiedzi konwersacyjne",
          instruction_following: "Lepsze wykonywanie instrukcji",
          diverse_outputs: "Bardziej różnorodne i kreatywne wyniki",
        },
        cons: {
          more_memory: "Większe zużycie pamięci",
          longer_training: "Dłuższy czas treningu",
        },
      },
      code: {
        name: "Generowanie kodu",
        description: "Zoptymalizowany dla programowania i uzupełniania kodu",
        pros: {
          precise_syntax: "Precyzyjne uczenie się składni",
          low_dropout: "Niski dropout dla dokładności",
          all_modules: "Celuje we wszystkie odpowiednie warstwy",
        },
        cons: {
          more_memory: "Większe zużycie pamięci",
          slower_training: "Wolniejsza prędkość treningu",
        },
      },
      fast: {
        name: "Szybka iteracja",
        description: "Szybki trening dla szybkiego eksperymentowania",
        pros: {
          quick_results: "Szybkie wyniki do testowania",
          low_memory: "Niższe wymagania pamięciowe",
          rapid_testing: "Idealny do szybkiego prototypowania",
        },
        cons: {
          lower_quality: "Niższa jakość wyników",
          less_learning: "Mniej dokładne uczenie",
        },
      },
      high_quality: {
        name: "Wysoka jakość",
        description: "Maksymalna jakość kosztem czasu treningu",
        pros: {
          best_results: "Najlepsze możliwe wyniki",
          thorough_learning: "Dokładny trening przez więcej epok",
          all_modules: "Kompleksowe pokrycie warstw",
        },
        cons: {
          long_training: "Długi czas treningu",
          high_memory: "Wysokie wymagania pamięciowe",
          needs_gpu: "Wymaga wydajnego GPU",
        },
      },
      low_memory: {
        name: "Niska pamięć",
        description: "Zminimalizowane użycie VRAM dla ograniczonego sprzętu",
        pros: {
          minimal_vram: "Minimalne użycie VRAM",
          works_on_consumer: "Działa na GPU konsumenckich",
          gradient_accumulation: "Efektywna akumulacja gradientu",
        },
        cons: {
          slower_training: "Wolniejsza prędkość treningu",
          smaller_rank: "Mniejszy rząd LoRA ogranicza pojemność",
        },
      },
      multilingual: {
        name: "Wielojęzyczny",
        description: "Zoptymalizowany dla modeli wielojęzycznych",
        pros: {
          language_diversity: "Zachowuje różnorodność językową",
          balanced_learning: "Zbalansowane uczenie międzyjęzykowe",
          longer_warmup: "Rozszerzona rozgrzewka dla adaptacji językowej",
        },
        cons: {
          needs_diverse_data: "Wymaga różnorodnych danych treningowych",
          moderate_time: "Umiarkowany czas treningu",
        },
      },
      reasoning: {
        name: "Rozumowanie / Matematyka",
        description: "Zoptymalizowany dla rozumowania logicznego i matematyki",
        pros: {
          precise_learning: "Precyzyjne i ostrożne uczenie",
          low_dropout: "Niski dropout dla spójności",
          consistent_outputs: "Bardziej spójne wyniki",
        },
        cons: {
          more_epochs: "Więcej epok treningu potrzebne",
          higher_rank: "Wyższy rząd zwiększa pamięć",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "Projekt o tej nazwie już istnieje.",
      ERR_PROJECT_1002: "Projekt nie znaleziony.",
      ERR_PROJECT_1003: "Nieprawidłowa nazwa projektu.",
      ERR_PROJECT_1004: "Nazwa projektu nie może być pusta.",
      ERR_PROJECT_1005: "Tworzenie projektu nie powiodło się.",
      ERR_PROJECT_1006: "Usuwanie projektu nie powiodło się.",
      ERR_PROJECT_1007: "Aktualizacja projektu nie powiodła się.",
      ERR_PROJECT_1008: "Otwieranie folderu projektu nie powiodło się.",
      ERR_MODEL_2001: "Odczyt konfiguracji modeli nie powiódł się.",
      ERR_MODEL_2002: "Zapis konfiguracji modeli nie powiódł się.",
      ERR_DATA_3001: "Plik danych nie znaleziony.",
      ERR_DATA_3002: "Nieprawidłowy typ pliku. Dozwolone są tylko pliki JSONL.",
      ERR_DATA_3003: "Przesyłanie pliku nie powiodło się.",
      ERR_DATA_3004: "Usuwanie pliku nie powiodło się.",
      ERR_DATA_3005: "Odczyt plików danych nie powiódł się.",
      ERR_TRAINING_4001: "Zadanie treningowe już działa.",
      ERR_TRAINING_4002: "Brak działającego zadania treningowego.",
      ERR_TRAINING_4003: "Dodaj pliki danych przed rozpoczęciem treningu.",
      ERR_TRAINING_4004: "Nie znaleziono pliku danych treningowych.",
      ERR_TRAINING_4005: "Ładowanie modelu nie powiodło się.",
      ERR_TRAINING_4006: "Trening nie powiódł się.",
      ERR_TRAINING_4007: "Eksportowanie modelu nie powiodło się.",
      ERR_TRAINING_4008: "Trening został anulowany.",
      ERR_TRAINING_4009: "llama.cpp nie znaleziony. Najpierw go zainstaluj.",
      ERR_HF_5001: "Niezalogowany do Hugging Face.",
      ERR_HF_5002: "Logowanie do Hugging Face nie powiodło się.",
      ERR_HF_5003: "Nieprawidłowy token Hugging Face.",
      ERR_OLLAMA_6001: "Ollama nie jest zainstalowana.",
      ERR_OLLAMA_6002: "Ollama nie działa.",
      ERR_OLLAMA_6003: "Tworzenie modelu w Ollama nie powiodło się.",
      ERR_OLLAMA_6004: "Model nie znaleziony w Ollama.",
      ERR_OLLAMA_6005: "Plik modelu nie znaleziony. Najpierw wytrenuj model.",
      ERR_OLLAMA_6006: "Otwieranie terminala nie powiodło się.",
      ERR_OLLAMA_6007: "Brak skonfigurowanego modelu bazowego. Najpierw wybierz model.",
      ERR_LLM_8001: "Nieprawidłowy format klucza API.",
      ERR_LLM_8002: "Klucz API odrzucony. Sprawdź swój klucz.",
      ERR_LLM_8003: "Nieznany dostawca.",
      ERR_LLM_8004: "Nie można osiągnąć API dostawcy.",
      ERR_LLM_8005: "Nie można zapisać klucza API.",
      ERR_DATA_SOURCE_9001: "Nieprawidłowy typ pliku dla źródła danych.",
      ERR_DATA_SOURCE_9002: "Plik jest zbyt duży.",
      ERR_DATA_SOURCE_9003: "Źródło danych jest puste.",
      ERR_GENERATION_9101: "Dostawca LLM nie jest skonfigurowany.",
      ERR_GENERATION_9102: "Model nie jest dostępny.",
      ERR_GENERATION_9103: "Przekroczono limit tokenów. Użyj mniejszych źródeł danych.",
      ERR_GENERATION_9104: "Błąd komunikacji z API LLM.",
      ERR_GENERATION_9105: "Nieprawidłowa odpowiedź z LLM.",
      ERR_GENERATION_9106: "Przekroczono limit szybkości. Poczekaj i spróbuj ponownie.",
      ERR_SAVE_9201: "Nieprawidłowa nazwa pliku.",
      ERR_SAVE_9202: "Zapisywanie pliku nie powiodło się.",
      unknown: "Wystąpił nieoczekiwany błąd.",
    },
    validation: {
      mustBeInteger: "Musi być liczbą całkowitą",
      mustBeNumber: "Musi być prawidłową liczbą",
      mustBeString: "Musi być tekstem",
      mustBeBoolean: "Musi być prawda lub fałsz",
      mustBeArray: "Musi być listą",
      mustBeGreaterThan: "Musi być większe niż {{min}}",
      mustBeAtLeast: "Musi być co najmniej {{min}}",
      mustBeAtMost: "Musi być co najwyżej {{max}}",
      maxLength: "Maksymalnie {{maxLength}} znaków",
    },
  },
};

export default pl;
