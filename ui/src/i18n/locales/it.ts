// OllaForge - A web application that simplifies training LLMs with your own data for use in Ollama.
// Copyright (C) 2026  Marcel Joachim Kloubert (marcel@kloubert.dev)
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.

import type { TranslationSchema } from "../types";

const it: TranslationSchema = {
  translation: {
    common: {
      loading: "Caricamento...",
      error: "Si è verificato un errore",
      retry: "Riprova",
      cancel: "Annulla",
      save: "Salva",
      delete: "Elimina",
      create: "Crea",
      back: "Indietro",
      name: "Nome",
      actions: "Azioni",
      optional: "opzionale",
      edit: "Modifica",
      ok: "OK",
      dismiss: "Chiudi",
    },
    app: {
      title: "OllaForge",
    },
    nav: {
      home: "Home",
      projects: "Progetti",
    },
    theme: {
      light: "Chiaro",
      dark: "Scuro",
      system: "Sistema",
      toggle: "Cambia tema",
    },
    language: {
      en: "Inglese",
      de: "Tedesco",
      es: "Spagnolo",
      fr: "Francese",
      pt: "Portoghese",
      uk: "Ucraino",
      zh: "Cinese",
      ja: "Giapponese",
      ko: "Coreano",
      ar: "Arabo",
      hi: "Hindi",
      it: "Italiano",
      nl: "Olandese",
      pl: "Polacco",
      select: "Seleziona lingua",
    },
    api: {
      status: "Stato API",
      connected: "Connesso",
      disconnected: "Disconnesso",
      checking: "Verifica...",
    },
    huggingface: {
      status: {
        loggedIn: "Connesso come {{username}}",
        loggedOut: "Non connesso",
        checking: "Verifica...",
      },
      changeToken: "Cambia token",
      login: {
        title: "Login Hugging Face",
        description:
          "Inserisci il tuo token di accesso Hugging Face per accedere ai modelli protetti.",
        tokenLabel: "Token di accesso",
        tokenPlaceholder: "hf_...",
        help: "Hai bisogno di un token di accesso Hugging Face per scaricare modelli protetti.",
        getToken: "Ottieni il tuo token qui",
        submit: "Accedi",
        submitting: "Accesso in corso...",
        success: "Accesso effettuato con successo!",
      },
      errors: {
        loginFailed: "Accesso fallito. Controlla il tuo token.",
        invalidToken: "Formato token non valido. Il token deve iniziare con 'hf_'.",
      },
    },
    llmProviders: {
      title: "Provider LLM",
      status: {
        allValid: "Tutti i provider configurati",
        someInvalid: "Alcuni provider non configurati",
        noneConfigured: "Nessun provider configurato",
        checking: "Verifica...",
        valid: "Valido",
        invalid: "Non configurato",
      },
      providers: {
        openai: "OpenAI",
        anthropic: "Anthropic (Claude)",
        mistral: "Mistral",
      },
      login: {
        title: "Configura {{provider}}",
        description: "Inserisci la tua chiave API {{provider}} per abilitare l'integrazione.",
        tokenLabel: "Chiave API",
        help: "Hai bisogno di una chiave API per utilizzare le funzionalità di {{provider}}.",
        getToken: "Ottieni la tua chiave API qui",
        submit: "Salva",
        submitting: "Salvataggio...",
        success: "Chiave API salvata con successo!",
      },
      changeToken: "Cambia chiave API",
      errors: {
        loginFailed: "Impossibile salvare la chiave API. Controlla la tua chiave.",
      },
    },
    generateFromSources: {
      title: "Genera da Sorgenti",
      button: "Genera da Sorgenti",
      buttonDisabled: "Nessun provider LLM configurato",
      sources: {
        title: "Sorgenti Dati",
        uploadFile: "Carica File",
        uploadHint: "Trascina e rilascia o clicca per caricare",
        addText: "Aggiungi Testo",
        textPlaceholder: "Incolla il tuo testo qui...",
        empty: "Nessuna sorgente aggiunta",
        estimatedTokens: "~{{tokens}} token",
        totalTokens: "Totale: ~{{tokens}} token",
        sourcesCount: "{{count}} sorgente/i",
        acceptedFormats: "Accettati: .txt, .md, .html, .json, .csv, .xml",
        tokenLimitWarning: "Il conteggio token supera il limite della finestra di contesto ({{limit}} token)",
      },
      llm: {
        selectModel: "Seleziona modello...",
        contextInfo: "Contesto: {{context}}K token",
        generate: "Genera",
        generating: "Generazione...",
        progress: "Elaborazione blocco {{current}} di {{total}}...",
        targetLanguage: "Lingua di Output",
        languages: {
          auto: "Come l'input",
          en: "Inglese",
          de: "Tedesco",
          es: "Spagnolo",
          fr: "Francese",
          pt: "Portoghese",
          uk: "Ucraino",
          zh: "Cinese (Semplificato)",
          ja: "Giapponese",
          ko: "Coreano",
          ar: "Arabo",
          hi: "Hindi",
          it: "Italiano",
          nl: "Olandese",
          pl: "Polacco",
        },
      },
      results: {
        title: "Dati Generati",
        empty: "Genera dati usando il pannello a sinistra",
        instruction: "Istruzione",
        output: "Output",
        addRow: "Aggiungi Riga",
        deleteRow: "Elimina",
        validRows: "{{valid}} di {{total}} righe valide",
        generated: "Generate {{count}} righe di dati di training",
      },
      save: {
        title: "Salva come JSONL",
        filename: "Nome file",
        save: "Salva",
        saving: "Salvataggio...",
        success: "File {{filename}} salvato con successo",
      },
      errors: {
        emptyCell: "La cella non può essere vuota",
        invalidFilename: "Nome file non valido",
        noData: "Nessun dato da salvare",
        invalidRows: "Correggi prima le righe non valide",
      },
    },
    projects: {
      title: "Progetti",
      empty: "Nessun progetto",
      emptyDescription: "Crea il tuo primo progetto per iniziare.",
      createNew: "Nuovo Progetto",
      createTitle: "Crea Nuovo Progetto",
      createDescription: "Inserisci un nome per il tuo nuovo progetto.",
      namePlaceholder: "Il Mio Progetto",
      nameLabel: "Nome Progetto",
      descriptionLabel: "Descrizione",
      descriptionPlaceholder: "Una breve descrizione del tuo progetto",
      creating: "Creazione...",
      saving: "Salvataggio...",
      openProject: "Apri progetto",
      editTitle: "Modifica Progetto",
      editDescription: "Aggiorna il nome e la descrizione del progetto.",
      deleteTitle: "Elimina Progetto",
      deleteDescription:
        "Sei sicuro di voler eliminare \"{{name}}\"? Questa azione non può essere annullata.",
      deleting: "Eliminazione...",
      openFolder: "Apri cartella",
    },
    project: {
      title: "Progetto",
      backToProjects: "Torna ai Progetti",
      selectModel: "Modello Base",
      selectModelPlaceholder: "Seleziona un modello...",
      targetName: "Nome Modello Target",
      targetNamePlaceholder: "Inserisci un nome personalizzato...",
      configuration: "Configurazione",
      status: "Stato",
      tabs: {
        basic: "Base",
        advanced: "Avanzato",
      },
      advancedPlaceholder: "Impostazioni avanzate in arrivo...",
    },
    advancedConfig: {
      helpPanel: {
        title: "Informazioni Impostazioni Avanzate",
        description: "Queste impostazioni controllano come il tuo modello viene addestrato usando QLoRA (Quantized Low-Rank Adaptation). QLoRA permette il fine-tuning di grandi modelli linguistici su hardware consumer usando quantizzazione a 4-bit e adattatori a basso rango. I valori predefiniti funzionano bene per la maggior parte dei casi - cambiali solo se comprendi il loro impatto.",
        learnMore: "Scopri di più",
        links: {
          huggingface: "Hugging Face Transformers",
          qlora: "Paper QLoRA",
          lora: "LoRA Spiegato",
          transformers: "Documentazione Training",
        },
      },
      trainingParams: {
        title: "Parametri di Training",
        numEpochs: "Epoche",
        numEpochsHelp: "Numero di passaggi di training. Più epoche possono migliorare la qualità ma rischiano l'overfitting. Raccomandato: 1-5.",
        batchSize: "Dimensione Batch",
        batchSizeHelp: "Campioni per step di training. Dimensioni maggiori addestrano più velocemente ma richiedono più memoria. Raccomandato: 1-8.",
        gradientAccumulation: "Accumulo Gradienti",
        gradientAccumulationHelp: "Accumula gradienti su più step. Simula batch più grandi con meno memoria.",
        learningRate: "Learning Rate",
        learningRateHelp: "Dimensione del passo per gli aggiornamenti dei pesi. Troppo alto causa instabilità, troppo basso rallenta il training. Raccomandato: 1e-5 a 5e-4.",
        warmupRatio: "Rapporto Warmup",
        warmupRatioHelp: "Frazione del training per aumentare gradualmente il learning rate. Aiuta a stabilizzare il training iniziale.",
        maxLength: "Lunghezza Max Token",
        maxLengthHelp: "Lunghezza massima della sequenza per il training. Sequenze più lunghe richiedono più memoria.",
        fp16: "FP16 (Mezza Precisione)",
        fp16Help: "Usa floating point a 16-bit per training più veloce. Disponibile solo su GPU CUDA.",
        optimizer: "Ottimizzatore",
        optimizerHelp: "Algoritmo per aggiornare i pesi. paged_adamw_8bit è efficiente in memoria per QLoRA.",
        optimizers: {
          paged_adamw_8bit: "Paged AdamW 8-bit (raccomandato per GPU)",
          adamw_torch: "AdamW (raccomandato per CPU)",
          adamw_hf: "AdamW (Hugging Face)",
          sgd: "SGD",
        },
        weightDecay: "Weight Decay",
        weightDecayHelp: "Regolarizzazione L2 per prevenire l'overfitting. Valori più alti aggiungono più regolarizzazione. Raccomandato: 0.01.",
        maxGradNorm: "Max Gradient Norm",
        maxGradNormHelp: "Norma massima del gradiente per il gradient clipping. Previene gradienti esplosivi. Raccomandato: 1.0.",
        lrScheduler: "Scheduler LR",
        lrSchedulerHelp: "Strategia dello scheduler del learning rate. Controlla come il learning rate cambia durante il training.",
        schedulers: {
          linear: "Lineare (raccomandato)",
          cosine: "Coseno",
          constant: "Costante",
          polynomial: "Polinomiale",
        },
        neftuneNoise: "Alpha Rumore NEFTune",
        neftuneNoiseHelp: "Aggiungi rumore agli embeddings durante il training. Può migliorare la generalizzazione. 0 = disabilitato, 5-15 raccomandato quando abilitato.",
        seed: "Seed Casuale",
        seedHelp: "Seed per la riproducibilità. Usa lo stesso seed per ottenere risultati identici tra le sessioni di training.",
        bf16: "BF16 (Brain Float 16)",
        bf16Help: "Usa precisione bfloat16 invece di fp16. Disponibile solo su GPU Ampere+ (RTX 3000+). Migliore stabilità numerica di fp16.",
        loggingSteps: "Step di Logging",
        loggingStepsHelp: "Registra metriche di training ogni N step. Valori più bassi danno aggiornamenti più frequenti ma possono rallentare il training.",
        saveStrategy: "Strategia di Salvataggio",
        saveStrategyHelp: "Quando salvare i checkpoint del modello durante il training.",
        saveStrategies: {
          no: "Nessun checkpoint",
          epoch: "Dopo ogni epoca (raccomandato)",
          steps: "Ogni N step",
        },
      },
      defaults: {
        showDefaults: "Usando predefiniti",
        cudaDefault: "Predefinito GPU: {{value}}",
        cpuDefault: "Predefinito CPU: {{value}}",
        resetToDefaults: "Ripristina predefiniti",
        resetConfirm: "Tutti i valori in questa sezione verranno ripristinati ai predefiniti.",
      },
      loraParams: {
        title: "Configurazione LoRA",
        rank: "Rango (r)",
        rankHelp: "Dimensione delle matrici a basso rango. Valori più alti catturano più informazioni ma usano più memoria e rischiano l'overfitting. Raccomandato: 8-64.",
        alpha: "Alpha",
        alphaHelp: "Fattore di scala per i pesi LoRA. Tipicamente impostato a 2x il rango. Valori più alti aumentano l'impatto del fine-tuning.",
        dropout: "Dropout",
        dropoutHelp: "Probabilità di dropout per i layer LoRA. Aiuta a prevenire l'overfitting. Raccomandato: 0.05-0.1.",
        targetModules: "Moduli Target",
        targetModulesHelp: "Layer del modello a cui applicare LoRA. Più moduli = più capacità di fine-tuning ma più uso di memoria.",
        modules: {
          q_proj: "Query Projection (q_proj)",
          k_proj: "Key Projection (k_proj)",
          v_proj: "Value Projection (v_proj)",
          o_proj: "Output Projection (o_proj)",
          gate_proj: "Gate Projection (gate_proj)",
          up_proj: "Up Projection (up_proj)",
          down_proj: "Down Projection (down_proj)",
        },
        bias: "Training Bias",
        biasHelp: "Come gestire i termini di bias durante il training. 'none' congela i bias, 'lora_only' addestra i bias LoRA, 'all' addestra tutti i bias.",
        biasOptions: {
          none: "Nessuno (congela bias)",
          lora_only: "Solo LoRA",
          all: "Tutti i bias",
        },
        useRslora: "Usa RSLoRA",
        useRsloraHelp: "Rank-Stabilized LoRA migliora la stabilità del training e le prestazioni per ranghi alti (r >= 64). Raccomandato per ranghi grandi.",
        useDora: "Usa DoRA (Sperimentale)",
        useDoraHelp: "Weight-Decomposed Low-Rank Adaptation può migliorare la qualità del fine-tuning. Funzionalità sperimentale, può aumentare il tempo di training.",
        modulesToSave: "Moduli da Salvare",
        modulesToSaveHelp: "Moduli aggiuntivi da addestrare completamente (non con LoRA). Utile per addestrare layer di output come lm_head.",
        saveModules: {
          lm_head: "Language Model Head (lm_head)",
          embed_tokens: "Token Embeddings (embed_tokens)",
        },
      },
      quantizationParams: {
        title: "Quantizzazione",
        loadIn4bit: "Carica in 4-bit",
        loadIn4bitHelp: "Carica i pesi del modello in precisione 4-bit per ridurre l'uso di memoria. Richiesto per QLoRA su memoria GPU limitata. Disponibile solo su GPU CUDA.",
        quantType: "Tipo Quantizzazione 4-bit",
        quantTypeHelp: "Algoritmo per la quantizzazione 4-bit. NF4 (Normal Float 4) è raccomandato per migliore accuratezza.",
        quantTypes: {
          nf4: "NF4 (raccomandato)",
          fp4: "FP4",
        },
        doubleQuant: "Doppia Quantizzazione",
        doubleQuantHelp: "Applica quantizzazione secondaria per ridurre ulteriormente la memoria. Piccolo compromesso di accuratezza per significativo risparmio di memoria.",
        computeDtype: "Dtype di Calcolo",
        computeDtypeHelp: "Tipo di dati per i calcoli durante il training. bfloat16 offre migliore stabilità numerica su GPU Ampere+ (RTX 3000+).",
        computeDtypes: {
          float16: "Float16 (raccomandato)",
          bfloat16: "BFloat16 (RTX 3000+)",
          float32: "Float32 (precisione piena)",
        },
        outputQuantization: "Quantizzazione Output",
        outputQuantizationHelp: "Formato di quantizzazione per il modello GGUF finale. q8_0 offre buon equilibrio tra dimensione e qualità.",
        outputTypes: {
          f32: "F32 (precisione piena, più grande)",
          f16: "F16 (mezza precisione)",
          bf16: "BF16 (brain float 16)",
          q8_0: "Q8_0 (8-bit, raccomandato)",
          auto: "Auto (lascia decidere a llama.cpp)",
        },
        cudaOnly: "Queste impostazioni si applicano solo quando si addestra su GPU CUDA.",
      },
      modelfileParams: {
        title: "Modelfile Ollama",
        temperature: "Temperatura",
        temperatureHelp: "Controlla la casualità nell'output. Valori più bassi rendono le risposte più focalizzate e deterministiche, valori più alti più creative. Raccomandato: 0.7-0.9.",
        topP: "Top P (Nucleus Sampling)",
        topPHelp: "Considera solo token con probabilità cumulativa fino a questo valore. Valori più bassi si concentrano su token più probabili. Raccomandato: 0.9.",
        topK: "Top K",
        topKHelp: "Limita la selezione dei token alle K opzioni più probabili. Valori più bassi sono più focalizzati. Raccomandato: 40.",
        system: "Prompt di Sistema",
        systemHelp: "Istruzioni che definiscono come il modello dovrebbe comportarsi. Imposta la personalità e le capacità del modello.",
        systemPlaceholder: "Sei un assistente utile.",
        stop: "Sequenze di Stop",
        stopHelp: "Sequenze che segnalano al modello di smettere di generare. Si possono aggiungere più sequenze di stop.",
        stopPlaceholder: "Inserisci una sequenza di stop...",
        stopAdd: "Aggiungi",
        repeatPenalty: "Penalità Ripetizione",
        repeatPenaltyHelp: "Penalità per ripetere token. Valori più alti riducono la ripetizione. Raccomandato: 1.1.",
        repeatLastN: "Ripeti Ultimi N",
        repeatLastNHelp: "Numero di token da controllare per ripetizione. Valori più alti considerano più contesto. Raccomandato: 64.",
        numCtx: "Dimensione Finestra Contesto",
        numCtxHelp: "Lunghezza massima del contesto per l'inferenza. Finestre più grandi permettono più contesto ma usano più memoria.",
      },
    },
    dataFiles: {
      title: "Dati di Training",
      empty: "Nessun file di dati",
      dropzone: "Rilascia file JSONL qui o clicca per caricare",
      dropzoneActive: "Rilascia i file qui...",
      uploadButton: "Carica File",
      uploading: "Caricamento...",
      deleteConfirm: "Eliminare questo file?",
      previewRowCount: "{{count}} righe totali",
      previewTruncated: "mostrando le prime {{count}}",
      previewEmpty: "Questo file non contiene righe di dati.",
      previewError: "Impossibile caricare il contenuto del file.",
      invalidRow: "Riga non valida",
      showRawContent: "Mostra raw ({{size}})",
      rawContentTitle: "Contenuto raw - Riga {{line}}",
      rawContentLength: "{{count}} caratteri",
      errorCount: "Trovate {{count}} righe non valide",
      fileStatus: {
        pending: "In attesa di elaborazione",
        in_progress: "Caricamento...",
        completed: "Caricate {{loaded}} righe ({{skipped}} saltate)",
        failed: "Caricamento fallito",
        skipped: "Saltato",
      },
      validationErrors: {
        INVALID_JSON: "Sintassi JSON non valida",
        NOT_OBJECT: "Deve essere un oggetto JSON",
        MISSING_INSTRUCTION: "Campo \"instruction\" mancante",
        MISSING_OUTPUT: "Campo \"output\" mancante",
        INVALID_INSTRUCTION_TYPE: "\"instruction\" deve essere una stringa",
        INVALID_OUTPUT_TYPE: "\"output\" deve essere una stringa",
      },
    },
    training: {
      title: "Training",
      startButton: "Crea Modello",
      cancelButton: "Annulla Training",
      noModel: "Seleziona prima un modello",
      noDataFiles: "Aggiungi almeno un file di dati",
      readyDescription: "Tutto pronto. Clicca il pulsante sopra per iniziare a creare il tuo modello.",
      status: {
        idle: "Pronto",
        starting: "Avvio...",
        loading_data: "Caricamento dati...",
        loading_model: "Caricamento modello...",
        training: "Training...",
        exporting: "Esportazione modello...",
        converting: "Conversione in GGUF...",
        completed: "Completato",
        failed: "Fallito",
        cancelled: "Annullato",
      },
      progress: "Progresso",
      step: "Step {{current}} di {{total}}",
      device: "Dispositivo",
      taskList: "Attività",
      tasks: {
        detect_device: "Rileva dispositivo di calcolo",
        import_libraries: "Importa librerie ML",
        load_model: "Carica modello base",
        setup_lora: "Configura adattatore LoRA",
        tokenize: "Carica e tokenizza dati",
        train: "Addestra modello",
        merge_lora: "Unisci LoRA con modello base",
        convert_gguf: "Converti in formato GGUF",
        create_modelfile: "Crea Modelfile Ollama",
        register_ollama: "Registra modello in Ollama",
      },
      taskWarnings: "{{count}} righe non valide saltate",
      stillWorking: "Ancora in elaborazione...",
      errorTitle: "Training Fallito",
      completed: "Training Completato",
      completedDescription: "Il tuo modello è stato creato con successo. Controlla la cartella di output per il Modelfile.",
      cancelled: "Il training è stato annullato.",
    },
    ollama: {
      title: "Integrazione Ollama",
      runButton: "Esegui in Ollama",
      modelName: "Nome modello",
      running: "Apertura terminale...",
    },
    presets: {
      title: "Preset di Training",
      description: "Configurazioni quick-start ottimizzate per diversi casi d'uso. Seleziona un preset per applicare le sue impostazioni.",
      applyButton: "Applica",
      applyConfirmTitle: "Applicare Preset?",
      applyConfirmDescription: "Questo sovrascriverà le tue attuali impostazioni di training, LoRA e quantizzazione con i valori del preset \"{{preset}}\". Questa azione non può essere annullata.",
      recommended: "Raccomandato",
      allModels: "Tutti i modelli",
      balanced: {
        name: "Bilanciato",
        description: "Buon equilibrio tra velocità e qualità per la maggior parte delle attività",
        pros: {
          versatile: "Funziona bene con la maggior parte dei modelli e dati",
          stable: "Training stabile con predefiniti collaudati",
          good_defaults: "Buon punto di partenza per la sperimentazione",
        },
        cons: {
          not_specialized: "Non ottimizzato per casi d'uso specifici",
          moderate_time: "Tempo di training moderato",
        },
      },
      chat: {
        name: "Chat / Conversazione",
        description: "Ottimizzato per IA conversazionale e seguire istruzioni",
        pros: {
          natural_responses: "Risposte conversazionali più naturali",
          instruction_following: "Migliore nel seguire istruzioni",
          diverse_outputs: "Output più diversificati e creativi",
        },
        cons: {
          more_memory: "Maggiore uso di memoria",
          longer_training: "Tempo di training più lungo",
        },
      },
      code: {
        name: "Generazione Codice",
        description: "Ottimizzato per programmazione e completamento codice",
        pros: {
          precise_syntax: "Apprendimento preciso della sintassi",
          low_dropout: "Dropout basso per accuratezza",
          all_modules: "Punta a tutti i layer rilevanti",
        },
        cons: {
          more_memory: "Maggiore uso di memoria",
          slower_training: "Velocità di training più lenta",
        },
      },
      fast: {
        name: "Iterazione Veloce",
        description: "Training veloce per sperimentazione rapida",
        pros: {
          quick_results: "Risultati veloci per test",
          low_memory: "Requisiti di memoria inferiori",
          rapid_testing: "Ideale per prototipazione rapida",
        },
        cons: {
          lower_quality: "Qualità output inferiore",
          less_learning: "Apprendimento meno completo",
        },
      },
      high_quality: {
        name: "Alta Qualità",
        description: "Massima qualità a scapito del tempo di training",
        pros: {
          best_results: "Migliori risultati possibili",
          thorough_learning: "Training completo su più epoche",
          all_modules: "Copertura completa dei layer",
        },
        cons: {
          long_training: "Tempo di training lungo",
          high_memory: "Requisiti di memoria alti",
          needs_gpu: "Richiede GPU potente",
        },
      },
      low_memory: {
        name: "Bassa Memoria",
        description: "Uso VRAM minimizzato per hardware limitato",
        pros: {
          minimal_vram: "Uso VRAM minimo",
          works_on_consumer: "Funziona su GPU consumer",
          gradient_accumulation: "Accumulo gradienti efficace",
        },
        cons: {
          slower_training: "Velocità di training più lenta",
          smaller_rank: "Rango LoRA più piccolo limita la capacità",
        },
      },
      multilingual: {
        name: "Multilingue",
        description: "Ottimizzato per modelli multilingue",
        pros: {
          language_diversity: "Preserva la diversità linguistica",
          balanced_learning: "Apprendimento cross-linguistico bilanciato",
          longer_warmup: "Warmup esteso per adattamento linguistico",
        },
        cons: {
          needs_diverse_data: "Richiede dati di training diversificati",
          moderate_time: "Tempo di training moderato",
        },
      },
      reasoning: {
        name: "Ragionamento / Matematica",
        description: "Ottimizzato per ragionamento logico e matematica",
        pros: {
          precise_learning: "Apprendimento preciso e attento",
          low_dropout: "Dropout basso per consistenza",
          consistent_outputs: "Output più consistenti",
        },
        cons: {
          more_epochs: "Più epoche di training necessarie",
          higher_rank: "Rango più alto aumenta la memoria",
        },
      },
    },
    errors: {
      ERR_PROJECT_1001: "Esiste già un progetto con questo nome.",
      ERR_PROJECT_1002: "Progetto non trovato.",
      ERR_PROJECT_1003: "Nome progetto non valido.",
      ERR_PROJECT_1004: "Il nome del progetto non può essere vuoto.",
      ERR_PROJECT_1005: "Creazione progetto fallita.",
      ERR_PROJECT_1006: "Eliminazione progetto fallita.",
      ERR_PROJECT_1007: "Aggiornamento progetto fallito.",
      ERR_PROJECT_1008: "Apertura cartella progetto fallita.",
      ERR_MODEL_2001: "Lettura configurazione modelli fallita.",
      ERR_MODEL_2002: "Scrittura configurazione modelli fallita.",
      ERR_DATA_3001: "File di dati non trovato.",
      ERR_DATA_3002: "Tipo di file non valido. Solo file JSONL sono permessi.",
      ERR_DATA_3003: "Caricamento file fallito.",
      ERR_DATA_3004: "Eliminazione file fallita.",
      ERR_DATA_3005: "Lettura file di dati fallita.",
      ERR_TRAINING_4001: "Un job di training è già in esecuzione.",
      ERR_TRAINING_4002: "Nessun job di training in esecuzione.",
      ERR_TRAINING_4003: "Aggiungi file di dati prima di iniziare il training.",
      ERR_TRAINING_4004: "Un file di dati di training non è stato trovato.",
      ERR_TRAINING_4005: "Caricamento modello fallito.",
      ERR_TRAINING_4006: "Training fallito.",
      ERR_TRAINING_4007: "Esportazione modello fallita.",
      ERR_TRAINING_4008: "Il training è stato annullato.",
      ERR_TRAINING_4009: "llama.cpp non trovato. Installalo prima.",
      ERR_HF_5001: "Non connesso a Hugging Face.",
      ERR_HF_5002: "Login Hugging Face fallito.",
      ERR_HF_5003: "Token Hugging Face non valido.",
      ERR_OLLAMA_6001: "Ollama non è installato.",
      ERR_OLLAMA_6002: "Ollama non è in esecuzione.",
      ERR_OLLAMA_6003: "Creazione modello in Ollama fallita.",
      ERR_OLLAMA_6004: "Modello non trovato in Ollama.",
      ERR_OLLAMA_6005: "Modelfile non trovato. Addestra prima il modello.",
      ERR_OLLAMA_6006: "Apertura terminale fallita.",
      ERR_OLLAMA_6007: "Nessun modello base configurato. Seleziona prima un modello.",
      ERR_LLM_8001: "Formato chiave API non valido.",
      ERR_LLM_8002: "Chiave API rifiutata. Controlla la tua chiave.",
      ERR_LLM_8003: "Provider sconosciuto.",
      ERR_LLM_8004: "Impossibile raggiungere l'API del provider.",
      ERR_LLM_8005: "Impossibile salvare la chiave API.",
      ERR_DATA_SOURCE_9001: "Tipo di file non valido per sorgente dati.",
      ERR_DATA_SOURCE_9002: "File troppo grande.",
      ERR_DATA_SOURCE_9003: "Sorgente dati vuota.",
      ERR_GENERATION_9101: "Provider LLM non configurato.",
      ERR_GENERATION_9102: "Modello non disponibile.",
      ERR_GENERATION_9103: "Limite token superato. Usa sorgenti dati più piccole.",
      ERR_GENERATION_9104: "Errore di comunicazione con API LLM.",
      ERR_GENERATION_9105: "Risposta non valida da LLM.",
      ERR_GENERATION_9106: "Limite di richieste superato. Attendi e riprova.",
      ERR_SAVE_9201: "Nome file non valido.",
      ERR_SAVE_9202: "Salvataggio file fallito.",
      unknown: "Si è verificato un errore imprevisto.",
    },
    validation: {
      mustBeInteger: "Deve essere un numero intero",
      mustBeNumber: "Deve essere un numero valido",
      mustBeString: "Deve essere testo",
      mustBeBoolean: "Deve essere vero o falso",
      mustBeArray: "Deve essere una lista",
      mustBeGreaterThan: "Deve essere maggiore di {{min}}",
      mustBeAtLeast: "Deve essere almeno {{min}}",
      mustBeAtMost: "Deve essere al massimo {{max}}",
      maxLength: "Massimo {{maxLength}} caratteri",
    },
  },
};

export default it;
